<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2019-plan-and-learn</title>
    <url>/2019-plan-and-learn.html</url>
    <content><![CDATA[<h1 id="2019计划"><a href="#2019计划" class="headerlink" title="2019计划"></a>2019计划</h1><p>激励<a href="http://www.ituring.com.cn/article/9174">左耳朵耗子</a></p>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ol>
<li>掌握tensorflow的使用</li>
<li>掌握Python以及常用库(numpy,matplotlib,pandas)的使用</li>
<li>掌握常用机器学习算法(SVM,AdaBoost,LightGBM)的使用以及理论</li>
<li>掌握深度学习常用算法应用和理论</li>
<li>掌握英语单词5000个,提高自己的英语发音</li>
<li>spark大数据分析技术</li>
<li>linux相关技术</li>
<li>Java相关技术</li>
</ol>
<h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p>今天看了一篇虎扑上面&lt;非CS专业转行机器学习/人工智能阶段性成功，分享一点个人经验吧&gt;的帖子，感触比较多，摘一点帖子里面的内容，为之后的学习提供一定的建议。<br>楼主的情况是没有人工智能基础的，为了找到人工智能的工作准备了两年时间。</p>
<p>编程：掌握一门语言，要达到非常熟悉的阶段。<br>数据结构：掌握常用的数据结构，多做leetcode上面的编程题目，至少要刷一下easy和medium模式的题目，写的时候考虑test case<br>机器学习：</p>
<pre><code>1. andrew ng的machine learning，仔细看课件和习题
2. hands on machine learning with scikit-learn and tensorflow，并且在pythhon中实践还有课后习题
3. bishop的pattern recognition and machine learning
4. 李彦宏的机器学习和深度学习(自己加的)
5. 李航的统计机器学习（自己加的）
</code></pre><h2 id="Java相关技术"><a href="#Java相关技术" class="headerlink" title="Java相关技术"></a>Java相关技术</h2><p>参考了<a href="https://www.v2ex.com/t/546203">v2ex</a> 或者<a href="https://github.com/farmerjohngit/myblog">github</a><br>这里做了一个思维导图<br><img src="/2019-plan-and-learn/Java%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.PNG" class="" title="Java相关知识学习思维导图"><br>下面进行思维导图的一些解释。<strong>同时对这些技能点进行查漏补缺，同时也会在之后的过程中添加更多的技能点</strong></p>
<h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><p>集合主要是java.util包下的非线程安全和线程安全集合</p>
<h4 id="非线程安全"><a href="#非线程安全" class="headerlink" title="非线程安全"></a>非线程安全</h4><ol>
<li>List： ArrayList与LinkedList的实现和区别</li>
<li>Map：<ul>
<li>HashMap:了解其数据结构，源码，hash冲突如何解决(链表和红黑树)，扩容时机，扩容时避免rehash优化</li>
<li>LinkedHashMap:了解基本原理，哪两种有序，如何实现LRU</li>
<li>TreeMap：了解数据结构，了解其key对象为什么必须要实现Compare接口，如何用它实现一致性哈希</li>
</ul>
</li>
<li>Set：基本上是由map实现，简单看看就好</li>
</ol>
<p><strong>常见问题</strong></p>
<ul>
<li>hashmap 如何解决 hash 冲突，为什么 hashmap 中的链表需要转成红黑树？</li>
<li>hashmap 什么时候会触发扩容？</li>
<li>jdk1.8 之前并发操作 hashmap 时为什么会有死循环的问题？</li>
<li>hashmap 扩容时每个 entry 需要再计算一次 hash 吗？</li>
<li>hashmap 的数组长度为什么要保证是 2 的幂？</li>
<li>如何用 LinkedHashMap 实现 LRU ？</li>
<li>如何用 TreeMap 实现一致性 hash ？</li>
</ul>
<h4 id="线程安全的集合"><a href="#线程安全的集合" class="headerlink" title="线程安全的集合"></a>线程安全的集合</h4><ol>
<li>Collection.synchronized:了解其实现原理</li>
<li>CopyOnWriteArrayList：了解写时复制机制，了解其适用场景，思考为什么没有ConcurrentArrayList</li>
<li>ConcurrentHashMap：了解实现原理，扩容时做的优化，与HashTable的对比</li>
<li>BlockingQueue：了解 LinkedBlockingQueue、ArrayBlockingQueue、DelayQueue、SynchronousQueue</li>
</ol>
<p><strong>常见问题</strong></p>
<ul>
<li>ConcurrentHashMap 是如何在保证并发安全的同时提高性能？</li>
<li>ConcurrentHashMap 是如何让多线程同时参与扩容？</li>
<li>LinkedBlockingQueue、DelayQueue 是如何实现的？</li>
<li>CopyOnWriteArrayList 是如何保证线程安全的？</li>
</ul>
<h3 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h3><ol>
<li>synchronized：了解偏向锁、轻量级锁、重量级锁的概念以及升级机制、以及和 ReentrantLock 的区别</li>
<li>CAS：了解 AtomicInteger 实现原理、CAS 适用场景、如何实现乐观锁</li>
<li>AQS：了解 AQS 内部实现、及依靠 AQS 的同步类比如 ReentrantLock、Semaphore、CountDownLatch、CyclicBarrier 等的实现</li>
<li>ThreadLocal：了解 ThreadLocal 使用场景和内部实现</li>
<li>ThreadPoolExecutor：了解线程池的工作原理以及几个重要参数的设置</li>
</ol>
<p><strong>常见问题</strong></p>
<ul>
<li>synchronized 与 ReentrantLock 的区别？</li>
<li>乐观锁和悲观锁的区别？</li>
<li>如何实现一个乐观锁？</li>
<li>AQS 是如何唤醒下一个线程的？</li>
<li>ReentrantLock 如何实现公平和非公平锁是如何实现？</li>
<li>CountDownLatch 和 CyclicBarrier 的区别？各自适用于什么场景？</li>
<li>适用 ThreadLocal 时要注意什么？比如说内存泄漏?</li>
<li>说一说往线程池里提交一个任务会发生什么？</li>
<li>线程池的几个参数如何设置？</li>
<li>线程池的非核心线程什么时候会被释放？</li>
<li>如何排查死锁？</li>
</ul>
<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>了解 Java 中的软引用、弱引用、虚引用的适用场景以及释放机制</p>
<p><strong>常见问题</strong></p>
<ul>
<li>软引用什么时候会被释放</li>
<li>弱引用什么时候会被释放</li>
</ul>
<h3 id="类加载"><a href="#类加载" class="headerlink" title="类加载"></a>类加载</h3><p>了解双亲委派机制</p>
<p><strong>常见问题</strong></p>
<ul>
<li>双亲委派机制的作用？</li>
<li>Tomcat 的 classloader 结构</li>
<li>如何自己实现一个 classloader 打破双亲委派</li>
</ul>
<h3 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h3><p>了解 BIO 和 NIO 的区别、了解多路复用机制</p>
<p><strong>常见问题</strong></p>
<ul>
<li>同步阻塞、同步非阻塞、异步的区别？</li>
<li>select、poll、eopll 的区别？</li>
<li>java NIO 与 BIO 的区别？</li>
<li>refactor 线程模型是什么?</li>
</ul>
<h3 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h3><p>了解GC和内存区域</p>
<ol>
<li>垃圾回收基本原理、几种常见的垃圾回收器的特性、重点了解 CMS （或 G1 ）以及一些重要的参数</li>
<li>能说清 jvm 的内存划分</li>
</ol>
<p><strong>常见问题</strong></p>
<ul>
<li>CMS GC 回收分为哪几个阶段？分别做了什么事情？</li>
<li>CMS 有哪些重要参数？</li>
<li>Concurrent Model Failure 和 ParNew promotion failed 什么情况下会发生？</li>
<li>CMS 的优缺点？</li>
<li>有做过哪些 GC 调优？</li>
<li>为什么要划分成年轻代和老年代？</li>
<li>年轻代为什么被划分成 eden、survivor 区域？</li>
<li>年轻代为什么采用的是复制算法？</li>
<li>老年代为什么采用的是标记清除、标记整理算法</li>
<li>什么情况下使用堆外内存？要注意些什么？</li>
<li>堆外内存如何被回收？</li>
<li>jvm 内存区域划分是怎样的？</li>
</ul>
<h3 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h3><p>bean 的生命周期、循环依赖问题、spring cloud （如项目中有用过）、AOP 的实现、spring 事务传播</p>
<p><strong>常见问题</strong></p>
<ul>
<li>java 动态代理和 cglib 动态代理的区别（经常结合 spring 一起问所以就放这里了）</li>
<li>spring 中 bean 的生命周期是怎样的？</li>
<li>属性注入和构造器注入哪种会有循环依赖的问题？</li>
</ul>
<h3 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h3><p>事务隔离级别、锁、索引的数据结构、聚簇索引和非聚簇索引、最左匹配原则、查询优化（ explain 等命令）</p>
<p><strong>常见问题</strong></p>
<ul>
<li>Mysql(innondb 下同) 有哪几种事务隔离级别？</li>
<li>不同事务隔离级别分别会加哪些锁？</li>
<li>mysql 的行锁、表锁、间隙锁、意向锁分别是做什么的？</li>
<li>说说什么是最左匹配？</li>
<li>如何优化慢查询？</li>
<li>mysql 索引为什么用的是 b+ tree 而不是 b tree、红黑树</li>
<li>分库分表如何选择分表键</li>
<li>分库分表的情况下，查询时一般是如何做排序的？</li>
</ul>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>准备一下leetcode上的算法（easy，medium）</p>
]]></content>
      <categories>
        <category>plan</category>
      </categories>
      <tags>
        <tag>2019</tag>
      </tags>
  </entry>
  <entry>
    <title>BIO NIO AIO详解</title>
    <url>/BIO-NIO-AIO%E8%AF%A6%E8%A7%A3.html</url>
    <content><![CDATA[<h1 id="Java-BIO-NIO-AIO详解"><a href="#Java-BIO-NIO-AIO详解" class="headerlink" title="Java BIO NIO AIO详解"></a>Java BIO NIO AIO详解</h1><h2 id="同步，异步，阻塞，非阻塞"><a href="#同步，异步，阻塞，非阻塞" class="headerlink" title="同步，异步，阻塞，非阻塞"></a>同步，异步，阻塞，非阻塞</h2><p>这几个概念理解起来确实比较困难，特别是同步和阻塞，异步和非阻塞。首先要明确的一个概念是同步和异步主要是关注的是消息通信机制，所以同步和异步主要是关注客户端和服务端两个方面的消息如何通信。而阻塞和非阻塞主要是等待调用结果时的状态，所以关注的主要是当前线程在等待结果时能够做什么，如果在等待结果时当前线程能够做其他的事，则线程是非阻塞的；如果只能等待返回结果，则当前线程是阻塞的。下面举个例子来具体说明一下：<br>比如你跟书店老板打电话，确认是否书店中有哈利波特这本书。书店老板电话没有挂断，说你等一下，我现在查一下，你一直在等待，此时就是一种同步通信。而如果老板说我晚点电话通知你，然后挂断电话，此时就是异步通信。<br>让我们在换一个视角，还是打电话确定是否有哈利波特这本书这件事情。在打电话的过程中，你什么都没有干，只是一直在等待，那么此时你就是处于阻塞状态。而如果此时你正在看电视，此时你就是非阻塞状态，但是需要不定时的检查一下电话那边有没有回复。</p>
<blockquote>
<p>所谓同步，就是在发出一个<strong>调用</strong>时，在没有得到结果之前，该<strong>调用</strong>就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由<strong>调用者</strong>主动等待这个<strong>调用</strong>的结果.<br>而异步则是相反，<strong>调用</strong>在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在<strong>调用</strong>发出后，<strong>被调用者</strong>通过状态、通知来通知调用者，或通过回调函数处理这个调用。<br>阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。<br>在IO操作中，有以下四种组合：</p>
</blockquote>
<ol>
<li>同步阻塞IO：调用者发起IO操作请求，等待IO操作完成(阻塞)。IO操作的过程需要等待，等待服务端返回结果，操作执行完成后返回结果(同步)</li>
<li>同步非阻塞：调用者发起IO操作请求，询问IO操作的的状态，如果未完成，则立即返回；如果完成，则返回结果(非阻塞)。IO操作的过程需要等待执行完成才返回结果(同步)</li>
<li>异步阻塞：调用者发起IO操作请求，等待IO操作完成在返回(阻塞)。IO操作的过程不需要等待，操作完成后通过通知或者回调获取结果(异步)</li>
<li>异步非阻塞：调用者发起IO操作请求，询问IO操作的状态，如果未完成，则立即返回；如果完成，则返回结果(非阻塞)。IO操作的过程不需要等待，操作完成后通过通知或回调获得结果(异步)<br>在下面的具体介绍中，我会进行具体的说明。</li>
</ol>
<h2 id="Java-IO-操作类"><a href="#Java-IO-操作类" class="headerlink" title="Java IO 操作类"></a>Java IO 操作类</h2><p>Java中进行IO操作的类一般分为以下四类：</p>
<ol>
<li>字节流的输入和输出：InputStream和OutputStream</li>
<li>字符流的输入和输出</li>
<li>网络编程Socket</li>
<li></li>
</ol>
<h2 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h2><p>首先BIO是同步阻塞调用。阻塞是因为服务端在调用accept方法时，服务端会一直阻塞在accept方法上，直到在对应的端口上接收到数据；同步是因为客户端会一直等待服务端执行完成才返回结果。可以想一下JavaScript中的Ajax请求，在异步Ajax请求发出后，浏览器会执行接下来的JS代码，直到服务端发回处理结果，然后执行对应的回调函数。这是典型的异步请求。</p>
<h2 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h2><p>NIO(New IO or Non-Block IO)是一种同步非阻塞的通信模式。NIO客户端和服务器之间通过Channel通信。NIO可以在Channel进行读写操作。这些Channel都会被注册在Selector多路复用器上。Selector通过一个线程不停的轮询这些Channel。找出已经准备就绪的Channel执行IO操作。说是非阻塞是因为NIO通过一个线程轮询，实现千万个客户端的请求。说是同步是因为客户端一直在等待服务端执行完成才返回结果。</p>
<h2 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2>]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>BIO</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title>Gaussian Discriminant Analysis and Logistic Regression</title>
    <url>/Gaussian-Discriminant-Analysis-and-Logistic-Regression.html</url>
    <content><![CDATA[<h1 id="高斯判别分析和逻辑回归算法的关系"><a href="#高斯判别分析和逻辑回归算法的关系" class="headerlink" title="高斯判别分析和逻辑回归算法的关系"></a>高斯判别分析和逻辑回归算法的关系</h1><p>最近一直在看Andrew Ng的cs229那门课的讲义，看到高斯判别分析模型和逻辑回归算法的关系那一部分，自己采用贝叶斯后验概率也证明了两者之间的关系，证明不难，本来打算记录一下的。在网上看到有个外国人写的更好，那我就把他写的直接翻译过来了。当然文章中也加入了在网上看到的其他资料和自己的一些思考。<br><a href="https://duphan.wordpress.com/2016/10/27/gaussian-discriminant-analysis-and-logistic-regression/">原文</a></p>
<h2 id="判别模型和生成模型"><a href="#判别模型和生成模型" class="headerlink" title="判别模型和生成模型"></a>判别模型和生成模型</h2><p>有很多方式可以对机器学习算法进行分类，比如：监督/非监督，回归/分类,等等。还有一种方式用判别模型(<strong>Discriminative model</strong>)和生成模型(<strong>Generative model</strong>)进行区分.本篇文章，我们将会讨论高斯判别分析(Gaussian Discriminant Analysis )模型和逻辑回归(Logistic Regression)之间的关系,这也体现了判别模型和生成模型之间的关系。<br>判别模型是求$p(y|x)$.在分类问题中，判别模型是直接寻找能够将不同类的数据分开的超平面或者称之为决策边界。有很多常用的机器学习算法属于判别模型，比如：逻辑回归，SVM，神经网络等等。另一方面，生成模型是求取$p(x|y)$和$p(y)$.这意味着，在分类问题中，生成模型给出了每个类的概率分布，给出了数据是如何生成的。也即生成(generative)这个词的意思.生成模型依赖贝叶斯公式计算后验概率$p(y|x)$.像朴素贝叶斯，高斯判别分析等都属于生成模型。<br><img src="/Gaussian-Discriminant-Analysis-and-Logistic-Regression/discriminative_vs_generative.png" class="" title="Discriminative vs Generative"><br>在实际使用中，判别模型要比生成模型用的更多，原因很多。比如：判别模型更加灵活，更加鲁棒，当对模型做出错误的假设时，模型表现的也不是很敏感。而生成模型需要我们定义数据的先验概率，即数据分布，在很多时候这是非常有困难和挑战的。然后，生成模型也有它的优势，比如：相比于判别模型，生成模型对于数据有更多的先验信息。这导致如果我们对于数据的假设是正确的，那么生成模型在少量数据下也能够表现的更好。</p>
<h2 id="GDA和逻辑回归"><a href="#GDA和逻辑回归" class="headerlink" title="GDA和逻辑回归"></a>GDA和逻辑回归</h2><p>接下来我将要证明，GDA(Gaussian Discriminant Analysis)如何最终推导出逻辑回归，从这个推导中也可以看出采用逻辑回归的道理。<br>对于二分类问题，GDA假设类别服从伯努利分布，数据服从多元高斯分布，如下：<br><img src="/Gaussian-Discriminant-Analysis-and-Logistic-Regression/%E5%85%88%E9%AA%8C%E5%88%86%E5%B8%83.PNG" class="" title="先验分布"><br>具体的数学公式如下：<br><img src="/Gaussian-Discriminant-Analysis-and-Logistic-Regression/%E5%88%86%E5%B8%83%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F.PNG" class="" title="分布的数学公式"><br>而采用GDA就是求取后验概率，我们可以证明如下等式成立：</p>
<script type="math/tex; mode=display">p(y=1|x) = \frac{1}{1+exp(-\theta^Tx)}</script><p>在公式中可以看到，GDA关于类别1的后验概率就是逻辑回归的sigmoid函数，这里$\theta$就是关于参数$\phi,\mu_0,\mu_1,\sum$的函数<br>接下来进行证明：</p>
<script type="math/tex; mode=display">
p(y=1|x)
=\frac{p(x|y=1)\times{p(y=1)}}{p(x)}
=\frac{p(x|y=1)\times{p(y=1)}}{p(x|y=1)\times{p(y=1)} + p(x|y=1)\times{p(y=0)}}
=\frac{1}{1 + \frac{p(x|y=0)\times{p(y=0)}}{p(x|y=1)\times{p(y=1)}}}</script><p>我们接下来带入概率公式，计算$\frac{1}{1 + \frac{p(x|y=0)\times{p(y=0)}}{p(x|y=1)\times{p(y=1)}}}$,计算过程如下，主要是涉及一些log和exp的转换：<br><img src="/Gaussian-Discriminant-Analysis-and-Logistic-Regression/%E8%AF%81%E6%98%8E.PNG" class="" title="证明"><br>在公式的最后，我们令$x_0=1$,至此我们得到了$\theta^Tx$,即如下式：<br><img src="/Gaussian-Discriminant-Analysis-and-Logistic-Regression/%E8%AF%81%E6%98%8E%E7%BB%93%E6%9E%9C.PNG" class="" title="证明结果"><br>$\theta$向量的值如下：</p>
<script type="math/tex; mode=display">\theta=\left[
 \begin{matrix}
   log(\frac{1-\phi}{\phi}) - \frac{\mu_0^2 + \mu_1^2}{2\sum} \\
   \frac{\mu_0 - \mu_1}{\sum}
  \end{matrix}
  \right]</script><h2 id="关系说明"><a href="#关系说明" class="headerlink" title="关系说明"></a>关系说明</h2><p>可以看出，从GDA可以推导出逻辑回归，但是反过来是不成立的。即如果$p(y|x)$是一个逻辑回归函数并不能推导出$p(x|y)$是一个多元的高斯分布。这说明GDA模型比逻辑回归模型具有更强的假设。事实上，如果$p(x|y)$是指数分布族(<strong>Exponential Family</strong>，比如高斯分布，泊松分布)中的一种，那么其后验概率就是逻辑回归。由此我们也得到一个为什么逻辑回归使用的更加广泛的原因，因为逻辑回归是一种非常通用，健壮的算法，适用于许多基本假设。另一方面，GDA以及一般的生成模型做出了更强的假设，因此对于非高斯或某些未定义分布数据来说并不理想。<br>特别的，当$p(x|y)$是高斯分布(类别之间具有相同的协方差)时，则GDA是渐进有效的(首先搞清楚什么叫有效性，有效性是指在所有的无偏估计方法里，某种方法的估计量的方差是最小的，则该种估计方法就是有效的，比如古典假定的OLS(最小二乘算法)估计。渐近有效是指该种估计方法在中小样本时可能不是最有效的，但随着样本数的增加，慢慢变得有效（没有其它无偏估计方法可以得到更小的方差），这就称为渐近有效，比如正态分布下线性模型的最大似然估计)。非正式地说，当训练集数目很大时，没有模型能显著地比GDA更好(即模型准确估计$p(y|x)$的程度).如果数据服从正态分布，则GDA要比逻辑回归表现的更好，更近一步，即使对于比较小的训练集，我们也总是认为GDA要表现的更好。<br>假设有一个一维训练集，包含一些正样本和负样本，如下图x轴的叉和圈，设叉为0，圈为1，用GDA对两类样本分别拟合高斯概率密度函数p(x|y=0)和p(x|y=1)，如下图的两个钟形曲线。沿x轴遍历样本，在x轴上方画出相应的p(y=1|x)。如选x轴靠左的点，那么它属于1的概率几乎为0，p(y=1|x)=0，两条钟形曲线交点处，属于0或1的概率相同，p(y=1|x)=0.5，x轴靠右的点，输出1的概率几乎为1，p(y=1|x)=1。最终发现，得到的曲线和sigmoid函数曲线很相似。<br><img src="/Gaussian-Discriminant-Analysis-and-Logistic-Regression/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E5%92%8C%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.png" class="" title="高斯分布和逻辑回归"><br>也就是说，当使用GDA模型时，p(x|y)属于高斯分布，计算p(y|x)时，几乎能得到和logistic回归中使用的sigmiod函数一样的函数，但实际上还是存在本质区别。</p>
<p>在Andrew Ng的cs229采用两种方法可以推导出逻辑回归</p>
<ol>
<li>通过指数分布族来推导。</li>
<li>通过生成学习假设先验概率分布的方式进行推导。</li>
</ol>
<h2 id="如何选择两种模型"><a href="#如何选择两种模型" class="headerlink" title="如何选择两种模型"></a>如何选择两种模型</h2><p>由上面的分析可以知道，GDA比逻辑回归有更多的前置假设。当数据服从或大致服从正态分布时，GDA会具有更高的拟合度，因为GDA利用了更多的信息构建模型。但是当数据不服从正态分布时，那么逻辑回归更有效，因为它做出更少的假设，构建的模型更加强壮，更加具有鲁棒性。生成学习还有另外的一个好处，就是可以使用比判别学习模型使用更少的数据构建出强壮的模型。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过推导，我们可以看到很多算法内在都是存在某种联系的，理解算法之间的关系对于我们理解算法以及选择什么算法都是有很多的帮助的。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ol>
<li><a href="https://duphan.wordpress.com/2016/10/27/gaussian-discriminant-analysis-and-logistic-regression/">Gaussian Discriminant Analysis and Logistic Regression</a></li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Logistic Regression</tag>
        <tag>Gaussian Discriminant Analysis</tag>
        <tag>Discriminative model</tag>
        <tag>Machine Learning</tag>
        <tag>Generative model</tag>
        <tag>Statistics</tag>
      </tags>
  </entry>
  <entry>
    <title>Quartz与Spring结合使用及集群配置</title>
    <url>/Quartz%E4%B8%8ESpring%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8%E5%8F%8A%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE.html</url>
    <content><![CDATA[<h1 id="Quartz与Spring结合使用及集群配置"><a href="#Quartz与Spring结合使用及集群配置" class="headerlink" title="Quartz与Spring结合使用及集群配置"></a>Quartz与Spring结合使用及集群配置</h1><p>本文的原文在我个人的<a href="https://blog.csdn.net/benjaminlee1/article/details/72993879">CSDN</a>上。是在2017年的时候由于工作上面需要用到在集群环境中使用调度，采用了Quartz实现，当时进行了记录。不过现在我写博客主要是在个人站点上，所以就把之前的博客部分搬移过来了。<br>本文代码<a href="https://github.com/lightnine/spring-quartz">github地址</a></p>
<h2 id="quartz介绍"><a href="#quartz介绍" class="headerlink" title="quartz介绍"></a>quartz介绍</h2><p>quartz是进行任务调度执行的框架，相对于Java中线程池调度以及Spring自带注解的调度方法，有以下几个有点：</p>
<ol>
<li>能够支持上千上万个调度任务的执行 </li>
<li>任务调度方式较为灵活 </li>
<li>支持集群</li>
</ol>
<h2 id="运行环境"><a href="#运行环境" class="headerlink" title="运行环境"></a>运行环境</h2><ol>
<li>quartz版本：2.2.1，这是quartz最新的版本，其他版本可能跟此版本有一定差异</li>
<li>操作系统centos7,我在vmware中搭建了三台独立的虚拟机</li>
<li>JDK8</li>
<li>数据库：mysql 5.7.18</li>
<li>tomcat8</li>
</ol>
<h2 id="工程目录结构"><a href="#工程目录结构" class="headerlink" title="工程目录结构"></a>工程目录结构</h2><p>工程目录结构如下，采用Idea IDE<br><img src="/Quartz%E4%B8%8ESpring%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8%E5%8F%8A%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/%E5%B7%A5%E7%A8%8B%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84.png" class="" title="工程目录结构"></p>
<p>文件说明:<br>resources下是各种配置资源，create-schema.sql用于创建任务表，tables_mysql_innodb.sql用于创建quartz集群运行需要的表，共有十一张表。quartz_properties是quartz的配置</p>
<h2 id="主要配置文件内容"><a href="#主要配置文件内容" class="headerlink" title="主要配置文件内容"></a>主要配置文件内容</h2><p>配置文件中都有每个配置项详细的说明，我这里就只给出具体的配置内容<br>spring配置文件有两个，分别为applicationContext.xml和spring-mvc.xml<br><strong>applicationContext.xml文件如下</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://www.springframework.org/schema/beans&quot;</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:context</span>=<span class="string">&quot;http://www.springframework.org/schema/context&quot;</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xmlns:aop</span>=<span class="string">&quot;http://www.springframework.org/schema/aop&quot;</span></span></span><br><span class="line"><span class="tag">       <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd</span></span></span><br><span class="line"><span class="string"><span class="tag">    http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd</span></span></span><br><span class="line"><span class="string"><span class="tag">    http://www.springframework.org/schema/context</span></span></span><br><span class="line"><span class="string"><span class="tag">    http://www.springframework.org/schema/context/spring-context-3.0.xsd&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">&quot;com.ll.*&quot;</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 启用@Aspect支持 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">aop:aspectj-autoproxy</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 加载数据库配置 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">context:property-placeholder</span> <span class="attr">location</span>=<span class="string">&quot;classpath:jdbc.properties&quot;</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据源 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;dataSource&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.apache.commons.dbcp.BasicDataSource&quot;</span></span></span><br><span class="line"><span class="tag">          <span class="attr">destroy-method</span>=<span class="string">&quot;close&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;driverClassName&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;jdbc.driver&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;url&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;jdbc.url&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;jdbc.username&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;jdbc.password&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;initialSize&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;jdbc.initialSize&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;maxActive&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;jdbc.maxActive&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;maxIdle&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;jdbc.minIdle&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;maxWait&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;jdbc.maxWait&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;jdbcTemplate&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.springframework.jdbc.core.JdbcTemplate&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;dataSource&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">ref</span> <span class="attr">bean</span>=<span class="string">&quot;dataSource&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;fetchSize&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;jdbc.jdbcTemplate.fetchSize&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 访问数据库方式 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;jdbcDao&quot;</span> <span class="attr">class</span>=<span class="string">&quot;com.dexcoder.dal.spring.JdbcDaoImpl&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;jdbcTemplate&quot;</span> <span class="attr">ref</span>=<span class="string">&quot;jdbcTemplate&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 配置quartz调度器 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;scheduler&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.springframework.scheduling.quartz.SchedulerFactoryBean&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;dataSource&quot;</span> <span class="attr">ref</span>=<span class="string">&quot;dataSource&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--可选，QuartzScheduler 启动时更新己存在的Job，这样就不用每次修改targetObject后删除qrtz_job_details表对应记录了 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;overwriteExistingJobs&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--必须的，QuartzScheduler 延时启动，应用启动完后 QuartzScheduler 再启动 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;startupDelay&quot;</span> <span class="attr">value</span>=<span class="string">&quot;3&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 设置自动启动 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;autoStartup&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 把spring上下 文以key/value的方式存放在了quartz的上下文中了 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;applicationContextSchedulerContextKey&quot;</span> <span class="attr">value</span>=<span class="string">&quot;applicationContext&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- scheduler的名称 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;schedulerName&quot;</span> <span class="attr">value</span>=<span class="string">&quot;ClusterScheduler&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;configLocation&quot;</span> <span class="attr">value</span>=<span class="string">&quot;classpath:quartz.properties&quot;</span> /&gt;</span></span><br><span class="line"><span class="comment">&lt;!--         &lt;property name=&quot;quartzProperties&quot;&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--             &lt;props&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.scheduler.instanceName&quot;&gt;ClusterScheduler&lt;/prop&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.scheduler.instanceId&quot;&gt;AUTO&lt;/prop&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 线程池配置 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.threadPool.class&quot;&gt;org.quartz.simpl.SimpleThreadPool&lt;/prop&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.threadPool.threadCount&quot;&gt;20&lt;/prop&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.threadPool.threadPriority&quot;&gt;5&lt;/prop&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 JobStore 配置 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.jobStore.class&quot;&gt;org.quartz.impl.jdbcjobstore.JobStoreTX&lt;/prop&gt; --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--                 集群配置 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.jobStore.isClustered&quot;&gt;true&lt;/prop&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.jobStore.clusterCheckinInterval&quot;&gt;15000&lt;/prop&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.jobStore.maxMisfiresToHandleAtATime&quot;&gt;1&lt;/prop&gt; --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.jobStore.misfireThreshold&quot;&gt;120000&lt;/prop&gt; --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--                 &lt;prop key=&quot;org.quartz.jobStore.tablePrefix&quot;&gt;QRTZ_&lt;/prop&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--             &lt;/props&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--         &lt;/property&gt; --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>spring-mvc.xml内容如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://www.springframework.org/schema/beans&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span> <span class="attr">xmlns:context</span>=<span class="string">&quot;http://www.springframework.org/schema/context&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.springframework.org/schema/beans</span></span></span><br><span class="line"><span class="string"><span class="tag">         http://www.springframework.org/schema/beans/spring-beans-3.0.xsd</span></span></span><br><span class="line"><span class="string"><span class="tag">        http://www.springframework.org/schema/context</span></span></span><br><span class="line"><span class="string"><span class="tag">        http://www.springframework.org/schema/context/spring-context-3.0.xsd&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">&quot;com.ll.*&quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span></span></span><br><span class="line"><span class="tag">        <span class="attr">class</span>=<span class="string">&quot;org.springframework.web.servlet.view.ContentNegotiatingViewResolver&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;order&quot;</span> <span class="attr">value</span>=<span class="string">&quot;1&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;ignoreAcceptHeader&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;mediaTypes&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">map</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">&quot;json&quot;</span> <span class="attr">value</span>=<span class="string">&quot;application/json;charset=UTF-8&quot;</span> /&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">&quot;xml&quot;</span> <span class="attr">value</span>=<span class="string">&quot;application/xml;charset=UTF-8&quot;</span> /&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">&quot;rss&quot;</span> <span class="attr">value</span>=<span class="string">&quot;application/rss+xml;charset=UTF-8&quot;</span> /&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">map</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;defaultViews&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">list</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">list</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;velocityConfig&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">class</span>=<span class="string">&quot;org.springframework.web.servlet.view.velocity.VelocityConfigurer&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;resourceLoaderPath&quot;</span> <span class="attr">value</span>=<span class="string">&quot;/WEB-INF&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;configLocation&quot;</span> <span class="attr">value</span>=<span class="string">&quot;classpath:velocity.properties&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;viewResolver&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">class</span>=<span class="string">&quot;org.springframework.web.servlet.view.velocity.VelocityViewResolver&quot;</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- &lt;property name=&quot;order&quot; value=&quot;2&quot;/&gt; --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;suffix&quot;</span> <span class="attr">value</span>=<span class="string">&quot;.vm&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;prefix&quot;</span> <span class="attr">value</span>=<span class="string">&quot;/&quot;</span>/&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- &lt;property name=&quot;exposeSpringMacroHelpers&quot; value=&quot;true&quot;/&gt; --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- &lt;property name=&quot;requestContextAttribute&quot; value=&quot;rc&quot;/&gt; --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;contentType&quot;</span> <span class="attr">value</span>=<span class="string">&quot;text/html;charset=UTF-8&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Quartz配置文件为quartz.properties,内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#配置参数详解，查看http://haiziwoainixx.iteye.com/blog/1838055</span><br><span class="line">#============================================================================</span><br><span class="line"># Configure Main Scheduler Properties  </span><br><span class="line">#============================================================================</span><br><span class="line"># 可为任何值,用在jdbc jobstrore中来唯一标识实例，但是在所有集群中必须相同</span><br><span class="line">org.quartz.scheduler.instanceName: MyClusteredScheduler</span><br><span class="line">#AUTO即可，基于主机名和时间戳来产生实例ID</span><br><span class="line">#集群中的每一个实例都必须有一个唯一的&quot;instance id&quot;,应该有相同的&quot;scheduler instance name&quot;</span><br><span class="line">org.quartz.scheduler.instanceId: AUTO</span><br><span class="line">#禁用quartz软件更新</span><br><span class="line">org.quartz.scheduler.skipUpdateCheck: true</span><br><span class="line"></span><br><span class="line">#============================================================================</span><br><span class="line"># Configure ThreadPool  执行任务线程池配置</span><br><span class="line">#============================================================================</span><br><span class="line">#线程池类型，执行任务的线程</span><br><span class="line">org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool</span><br><span class="line">#线程数量</span><br><span class="line">org.quartz.threadPool.threadCount: 10</span><br><span class="line">#线程优先级</span><br><span class="line">org.quartz.threadPool.threadPriority: 5</span><br><span class="line">org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true </span><br><span class="line"></span><br><span class="line">#============================================================================</span><br><span class="line"># Configure JobStore  任务存储方式</span><br><span class="line">#============================================================================</span><br><span class="line"></span><br><span class="line">org.quartz.jobStore.misfireThreshold: 60000</span><br><span class="line">#可以设置两种属性，存储在内存的RAMJobStore和存储在数据库的JobStoreSupport</span><br><span class="line">#(包括JobStoreTX和JobStoreCMT两种实现JobStoreCMT是依赖于容器来进行事务的管理，而JobStoreTX是自己管理事务)</span><br><span class="line">#这里的属性为 JobStoreTX，将任务持久化到数据中。</span><br><span class="line">#因为集群中节点依赖于数据库来传播 Scheduler 实例的状态，你只能在使用 JDBC JobStore 时应用Quartz 集群。    </span><br><span class="line">#这意味着你必须使用 JobStoreTX 或是 JobStoreCMT 作为 Job 存储；你不能在集群中使用 RAMJobStore。</span><br><span class="line">org.quartz.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreTX</span><br><span class="line"></span><br><span class="line">#JobStoreSupport 使用一个驱动代理来操作 trigger 和 job 的数据存储</span><br><span class="line">org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.StdJDBCDelegate</span><br><span class="line">#若要设置为true，则将JobDataMaps中的值当作string</span><br><span class="line">org.quartz.jobStore.useProperties=false</span><br><span class="line">#对应下方的数据源配置，与spring结合不需要这个配置</span><br><span class="line">#org.quartz.jobStore.dataSource=myDS</span><br><span class="line">#org.quartz.jobStore.tablePrefix=QRTZ_</span><br><span class="line"></span><br><span class="line">#你就告诉了Scheduler实例要它参与到一个集群当中。这一属性会贯穿于调度框架的始终，用于修改集群环境中操作的默认行为。</span><br><span class="line">org.quartz.jobStore.isClustered=true</span><br><span class="line">#属性定义了Scheduler实例检入到数据库中的频率(单位：毫秒)。默认值是 15000 (即15 秒)。</span><br><span class="line">org.quartz.jobStore.clusterCheckinInterval = 20000</span><br><span class="line"></span><br><span class="line">#这是 JobStore 能处理的错过触发的 Trigger 的最大数量。</span><br><span class="line">#处理太多(超过两打) 很快会导致数据库表被锁定够长的时间，这样就妨碍了触发别的(还未错过触发) trigger 执行的性能。</span><br><span class="line">org.quartz.jobStore.maxMisfiresToHandleAtATime = 1</span><br><span class="line">org.quartz.jobStore.misfireThreshold = 120000</span><br><span class="line">org.quartz.jobStore.txIsolationLevelSerializable = false</span><br><span class="line"></span><br><span class="line">#============================================================================</span><br><span class="line"># Other Example Delegates 其他的数据库驱动管理委托类</span><br><span class="line">#============================================================================</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.DB2v6Delegate</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.DB2v7Delegate</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.DriverDelegate</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.HSQLDBDelegate</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.MSSQLDelegate</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.PointbaseDelegate</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.PostgreSQLDelegate</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.StdJDBCDelegate</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.WebLogicDelegate</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.oracle.OracleDelegate</span><br><span class="line">#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.oracle.WebLogicOracleDelegate</span><br><span class="line"></span><br><span class="line">#============================================================================</span><br><span class="line"># Configure Datasources  数据源配置，与spring结合不需要这个配置</span><br><span class="line">#============================================================================</span><br><span class="line"></span><br><span class="line">#org.quartz.dataSource.myDS.driver: com.mysql.jdbc.Driver</span><br><span class="line">#org.quartz.dataSource.myDS.URL: jdbc:mysql://localhost:3306/quartz</span><br><span class="line">#org.quartz.dataSource.myDS.user: root</span><br><span class="line">#org.quartz.dataSource.myDS.password: 123</span><br><span class="line">#org.quartz.dataSource.myDS.maxConnections: 5</span><br><span class="line">#org.quartz.dataSource.myDS.validationQuery: select 0</span><br><span class="line"></span><br><span class="line">#============================================================================</span><br><span class="line"># Configure Plugins</span><br><span class="line">#============================================================================</span><br><span class="line">#当事件的JVM终止后，在调度器上也将此事件终止</span><br><span class="line">#the shutdown-hook plugin catches the event of the JVM terminating, and calls shutdown on the scheduler.</span><br><span class="line">org.quartz.plugin.shutdownHook.class: org.quartz.plugins.management.ShutdownHookPlugin</span><br><span class="line">org.quartz.plugin.shutdownHook.cleanShutdown: true</span><br><span class="line"></span><br><span class="line">#记录trigger历史的日志插件</span><br><span class="line">#org.quartz.plugin.triggHistory.class: org.quartz.plugins.history.LoggingJobHistoryPlugin</span><br></pre></td></tr></table></figure>
<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>当按照此项目配置完成之后，将项目打包成war包，然后在一台centos下启动项目，添加任务，之后再另一台centos下也运行此war包。为了简单起见，这里添加的任务仅仅是输出任务的详细信息，并没有其他动作。在两台机器的catalina.out中可以看到输出的结果，可以看到任务可以负载均衡的运行在不同的机器上。</p>
<blockquote>
<p>如何动态的查看catalina.out中的内容，可以用tail -f来查看，能够实时看到文件的变化</p>
</blockquote>
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Quartz</tag>
        <tag>调度</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Memory Model</title>
    <url>/Java-Memory-Model.html</url>
    <content><![CDATA[<p>Java内存模型规定了Java虚拟机如何跟计算机的内存协同工作。因为Java虚拟机模拟了计算机，所以自然Java虚拟机包括内存模型。</p>
<p>正确理解Java内存模型对于编写正确的并发程序非常重要。Java内存模型规定了线程何时以及怎么读取其他线程写的值，还有就是在获取共享变量时如何进行同步操作。</p>
<p>最初的Java内存模型是有缺陷的，因此在Java5中进行了修改，并且这个版本的Java内存模型一直到Java8都在使用。</p>
<h1 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h1><p>JVM中的内存模型将内存分为线程栈内存和堆内存。下面的图从逻辑上展示了Java内存模型:<br><img src="/Java-Memory-Model/java-memory-model-1.png" class="" title="java-memory-model"></p>
<p>每个在JVM中运行的线程都有它自己栈空间。线程的栈空间中包含了线程调用方法执行到那一刻的数据。随着线程执行它的代码，调用栈也随之改变。</p>
<p>线程的栈空间同样也包含每个执行的方法的局部变量。线程只能获取它自己的栈空间，其中包含的局部变量对于其他线程是不可见的。即使两个线程执行相同的代码，这两个线程也是在各自的线程栈空间中创建各自的局部变量。</p>
<p>所有的原型类型(boolean,byte,short,char,int,long,float,double)的局部变量都是存储在线程的栈空间中。一个线程可能传递一个原型变量的副本给另一个线程，但是另一个线程并不能共享这个原型变量。</p>
<p>不管哪个线程创建了对象，这些对象都是存储在堆空间中。这也包括原型类型的包装器类型(e.g. Byte, Integer)。不管对象是被分配给局部变量还是作为另一个对象的成员变量，这个对象都是存储在堆空间中。</p>
<p>下面的图中说明了调用栈和局部变量存储在线程的栈空间中，而对象存储在堆空间中:</p>
<img src="/Java-Memory-Model/java-memory-model-2.png" class="" title="java-memory-model">
<p>如果局部变量是原型类型，那么这个变量在线程的栈空间中。</p>
<p>如果局部变量是一个指向对象的引用类型，那么这个引用是在线程的栈空间，但是对象本身是在堆空间中。</p>
<p>如果一个对象包含方法，同时这些方法包含局部变量。那么这些局部变量(原型类型或者引用)是保存在线程栈空间中，即使这些方法所在的对象是存储在堆空间中。</p>
<p>一个对象的成员变量是跟对象一起存储在堆内存中，不管这个成员变量是原型还是指向一个对象的引用。</p>
<p>类的静态变量也是跟类的定义一起存在堆内存中。</p>
<p>堆空间中对象能够被所有拥有指向此对象的引用的线程访问到。当一个线程能够访问一个对象时，那么这个线程也能够访问此对象的成员变量(这里要看这个对象的封装性)。如果两个线程同时调用了同一个对象的一个方法，那么这两个线程将能够访问这个对象的成员变量，但是每个线程都会获得局部变量的一份拷贝。</p>
<p>下面的图说明了上面描述的内容：</p>
<img src="/Java-Memory-Model/java-memory-model-3.png" class="" title="java-memory-model">
<p>在上图中，两个线程有一系列的局部变量。其中一个局部变量(Local Variable 2)指向了堆内存上的共享对象(Object3)。这两个线程分别拥有一个指向同一个对像的引用，这两个引用是不同的。这些引用是局部变量，所以存储在各自线程的栈空间中。而这两个不同的引用指向了堆上的同一个对象。</p>
<p>注意到共享对象(Object3)有两个引用指向了Object2和Object4,如图中箭头所示。通过Object3中的成员变量引用，这两个线程能够获取Object2和Object4。</p>
<blockquote>
<p>The diagram also shows a local variable which point to two different objects on the heap. In this case the references point to two different objects (Object 1 and Object 5), not the same object. In theory both threads could access both Object 1 and Object 5, if both threads had references to both objects. But in the diagram above each thread only has a reference to one of the two objects.</p>
</blockquote>
<p>上图中同样了展示了一个局部变量指向堆上两个不同的对象。指向不同对象(Object1, Object5)的引用不是同一个对象。理论上，如果这两个线程有指向这两个对象的引用，那么这两个线程都能够访问Object1和Object5。但是在上图中每个线程只有指向其中一个对象的引用。</p>
<p>那么，在Java代码中如何反应上面的内存图呢？代码很简单，如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyRunnable</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        methodOne();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">methodOne</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">localVariable1</span> <span class="operator">=</span> <span class="number">45</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">MySharedObject</span> <span class="variable">localVariable2</span> <span class="operator">=</span></span><br><span class="line">            MySharedObject.sharedInstance;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//... do more with local variables.</span></span><br><span class="line"></span><br><span class="line">        methodTwo();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">methodTwo</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">Integer</span> <span class="variable">localVariable1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Integer</span>(<span class="number">99</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//... do more with local variable.</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySharedObject</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//static variable pointing to instance of MySharedObject</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">MySharedObject</span> <span class="variable">sharedInstance</span> <span class="operator">=</span></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">MySharedObject</span>();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//member variables pointing to two objects on the heap</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">Integer</span> <span class="variable">object2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Integer</span>(<span class="number">22</span>);</span><br><span class="line">    <span class="keyword">public</span> <span class="type">Integer</span> <span class="variable">object4</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Integer</span>(<span class="number">44</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="variable">member1</span> <span class="operator">=</span> <span class="number">12345</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="variable">member1</span> <span class="operator">=</span> <span class="number">67890</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果两个线程执行run()方法,那么此代码就表明了上图所示的内存分布。run方法首先调用methodOne方法，然后methodOne方法调用methodTwo方法。</p>
<p>在methodOne方法中定义了一个原型的局部变量localVariable1,同时定义了一个指向对象的引用localVariable2.</p>
<p>每个执行methodOne方法的线程都会在各自的线程栈空间中创建localVariable1和localVariable2的副本。localVariable1在两个线程中是完全独立的，仅仅存在于对应线程的栈空间中。一个线程不能看到其他线程对于localVariable1变量的修改。</p>
<p>执行methodOne方法的线程同样会创建localVariable2的副本。但是，这两个localVariable2的副本是指向在堆上的同一个对象。而localVariable2引用指向的对象是一个类的静态成员变量。而类的静态变量在堆中只存在一份。所以两个localVariable2指向同一个MySharedObject对象的实例，MySharedObject实例存储在堆内存上，对应图中的Object3对象。</p>
<p>我们在来看看methodTwo方法是如何创建localVariable1局部变量的。这个局部变量是指向一个Integer对象的引用。methodTwo方法每次都重新创建一个Integer实例。局部变量localVariable2引用是存储在对应的栈空间中，而对应的Integer对象是在堆内存中，因为每次执行methodTwo方法都会创建Integer对象，所以在堆内存中会有两个Integer对象。即对应于图中的Object1和Object5对象。</p>
<p>在MySharedObject中有两个long类型的局部变量，因为这些变量是类的成员变量，所以它们跟具体的对象一起保存在堆内存中。仅仅局部变量是保存在栈内存中的。</p>
<h1 id="硬件内存架构"><a href="#硬件内存架构" class="headerlink" title="硬件内存架构"></a>硬件内存架构</h1><p>硬件内存跟Java内存模型是有些不一样的。为了更好地理解Java内存模型，我们需要了解硬件内存架构。下面的图简单描述了现代计算机的硬件架构：</p>
<img src="/Java-Memory-Model/java-memory-model-4.png" class="" title="java-memory-model">
<p>现代的计算机通常会有两个以上的CPU，同时这些CPU可能有多个核。这也意味着我们可以将多个线程同时运行在多个CPU上。在给定的时间点，每个CPU都能运行一个线程。即如果你的Java程序是多线程的，那么能够在多个CPU上同时运行(并行)。</p>
<p>在上图中我们可以看到每个CPU内部都有一系列的寄存器。CPU在寄存器上执行的操作要比在主存中的操作快。这是因为CPU能够更快的获取寄存器上的内容。</p>
<p>每个CPU都有一个对应的缓存内存。获取缓存中的内容要快于获取主存中的内容，但是没有获取寄存器中的内容快。CPU缓存的速度要介于寄存器和主存之间。有些CPU可能会有多级的缓存。</p>
<p>一个计算机包含一个主存(RAM),所有的CPU都能够获取主存中的内容。主存的容量要远远大于缓存的容量。</p>
<p>如果一个CPU要读取主存的内容，通常只会读取主存中部分区域的内容到CPU缓存中，然后在从缓存读取到寄存器中，之后进行计算。当CPU需要写结果到主存中，它会将寄存机中的值刷新到缓存中，然后在之后的某个时间点，在将缓存中的内容刷新到主存中。</p>
<p>当CPU需要存储缓存中的值时，会将缓存中的值刷新到主存中。同时CPU缓存也可以局部的刷新缓存值以及写出缓存值。</p>
<h1 id="Java内存模型和硬件内存架构之间的桥接"><a href="#Java内存模型和硬件内存架构之间的桥接" class="headerlink" title="Java内存模型和硬件内存架构之间的桥接"></a>Java内存模型和硬件内存架构之间的桥接</h1><p>像前面说明的，Java内存模型和硬件内存架构是不同的。硬件内存架构不会区分线程栈和堆空间。在硬件中，线程栈和堆空间都是在主存中的。同时，部分线程栈和堆内存会出现在CPU缓存或者CPU寄存器中。下面的图进行了说明：</p>
<img src="/Java-Memory-Model/java-memory-model-5.png" class="" title="java-memory-model">
<p>当对象和变量存储在不同的内存区域时，会出现一些问题。主要的两个问题如下：</p>
<ol>
<li>共享变量的可见性(可见性，即一个线程能够及时的看到另一个线程对于共享变量的修改)</li>
<li>竞态条件(即读取，检查，写入共享变量)</li>
</ol>
<p>下面会依次介绍这两个问题。</p>
<h2 id="共享变量的可见性"><a href="#共享变量的可见性" class="headerlink" title="共享变量的可见性"></a>共享变量的可见性</h2><p>如果两个线程共享一个对象，但是没有采用合适的volatile关键字或者同步操作，那么当一个线程更新共享对象时，可能另一个线程并不能看到更新后的值。</p>
<p>想象一下，一个共享对象最初是在主存中，一个CPU上的线程读取了此对象到CPU缓存中，之后对于这个共享对象进行了修改。只要CPU缓存没有刷新到主存中，那么运行在其他CPU上的线程是不能读取到修改后的共享变量的值的。这会造成其他CPU只能看到修改之间的值。</p>
<p>下面的图说明了这种情况。在左边的CPU上运行的线程将共享对象读取到CPU缓存中，然后将它的count变量修改为2.由于没有将count的修改刷新到主存中，所以在右侧CPU上运行的线程不能看到这个修改。</p>
<img src="/Java-Memory-Model/java-memory-model-6.png" class="" title="java-memory-model">
<p>为了解决这个问题，我们可以使用Java中的<a href="http://tutorials.jenkov.com/java-concurrency/volatile.html">volatile</a>关键字.volatile关键字的作用是保证每次都是从主存中读取变量的值，同时如果修改了此变量，那么此变量会立刻写回到主存中。</p>
<h2 id="竞态条件"><a href="#竞态条件" class="headerlink" title="竞态条件"></a>竞态条件</h2><p>如果两个线程或多个线程共享一个对象，那么当多余一个线程修改此变量时，竞态条件就可能会出现。</p>
<p>想象一下，线程A将一个共享对象的count变量读取进CPU缓存，线程B也将count读取到另一个CPU缓存。现在线程A在count加上1，同时线程B也在count上加上1.现在变量被增加了两次，在每个CPU缓存中各一次。</p>
<p>如果加1操作是顺序进行的，那么count的值会加上2，然后写回到主存中。</p>
<p>但是，这两个操作是在没有正确同步的情况下同时进行的。尽管线程A或者B会将count修改后的值写回到主存，但是更新后的值始终比原来的值大1.</p>
<p>下面的图说明了上面描述的竞态条件：</p>
<img src="/Java-Memory-Model/java-memory-model-7.png" class="" title="java-memory-model">
<p>为了解决这个问题，可以使用Java的同步块，即<a href="http://tutorials.jenkov.com/java-concurrency/synchronized.html">synchronized</a>关键字。同步块保证了在同步块中获取到的变量都是从主存中读取的，并且当线程离开同步块时，所有修改的变量会被刷新到主存中，而不管这个变量是否被volatile声明。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title>Refactor-improving the Design of Existing Code</title>
    <url>/Refactor-improving-the-Design-of-Existing-Code.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Refactor-improving the Design of Existing Code(重构-改善既有代码的设计),这是Martin Fowler的一本书.主要是针对Java语言.书已经出版多年了,买这本书也有一年多了,但是一直只看了第一章.最近因为工作不是很忙,就拾起来读了.这里主要是记录下读这本书的一些感想以及收获.<br>读这本书有个收获,重构不单单只是修改函数名称,重命名变量名称那么简单.比如进行类的分解,将合适的函数放置在合适的类中.而这些都需要我们在平常的编程活动中去实践.<br>什么时候进行重构呢?当遇到几个方面时,可以考虑进行重构.发现当为函数添加新功能时,并不能很好的添加进去,这时候我们可以进行重构;当写完功能时,我们也可以考虑重构.总之,重构并不是开发过程中必须要通过的一个过程,就像编译-链接等.你可以随时进行重构.</p>
<h2 id="重构"><a href="#重构" class="headerlink" title="重构"></a>重构</h2><p>我们在平时编程的时候,不可能一次性的就把问题或者程序写的完美无缺,除非我们已经非常熟知某个问题或者某个领域,即使非常熟悉,可能还有我们没有发现的提升之处.那么当我们的程序写的不完美的时候,我们怎么办呢?这时候就可以采用重构的方法来小步快跑的提升我们程序的易读性,优化程序的结构.而这本书给我们提供了如何进行重构的一系列方法.<br>整个开发流程:<br>开发—-&gt; 测试 —-&gt; 重构 —-&gt; 测试</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>在我们重构之前,一定要有合适的测试.在Java中,我们经常用的就是Junit和TestNG了.其中Junit主要是用来做单元测试,而TestNG主要是功能测试或者集成测试.如果我们是开发人员,可能使用Junit比较多,不过TestNG一般也会用到.在我们重构完成之后,一定要跑测试用例,跑通了所有的测试用例,这项重构才算是完成.</p>
<h3 id="代码的坏味道"><a href="#代码的坏味道" class="headerlink" title="代码的坏味道"></a>代码的坏味道</h3><ol>
<li>重复代码<br> 遇到相同的程序结构,应该想办法将它们合二为一,这样程序会变得更好</li>
<li>过长函数<br>函数的代码行数不宜过长,并且函数的命名应该体现出函数做了什么而不是表明怎么做</li>
<li>过大的类<br>当类过大时,我们可以采取Extract class 或者Extract Subclass来减小类的大小</li>
<li>过长的参数列<br>将函数的参数可以用对象来进行传递</li>
<li>发散式变化<br>如果某个类经常因为不同的原因在不同的方向上发生变化,那么这个类就产生了发散式变化.理想情况是针对外界的某一个变化产生的所有相应修改,都应该发生在单一类中.采用 <strong>Extract Class</strong>将因为特定原因造成的所有变化提炼到另一个类中</li>
<li>霰弹式修改<br>如果遇到某种变化,都必须在许多不同的类内做出许多小修改,那么就产生了霰弹式修改.遇到这种情况,应该使用<strong>Move Method</strong>和<strong>Move Field</strong>将所有的修改集中在一个类中.<br>发散式修改是指”一个类受多种变化的影响”,而霰弹式修改是指”一种变化引发多个类的相应修改”.理想情况是外界变化与需要修改的类趋于一一对应.</li>
<li>依恋情结<br>函数对某个类的兴趣高过对自己所处类的兴趣.这时候我们应该将此函数移动到此函数对应的类中.</li>
<li>数据泥团<br>两个类中相同的字段,许多函数签名中相同的参数.这些总是绑定在一起出现的数据应该拥有属于它们的对象</li>
<li>基本类型偏执<br>我们有时候可以用对象来替代基本类型,比如当表示由一个起始值和一个结束值组成的range类,一个币种的money类.我们可以创建对应的小对象.</li>
<li>switch惊悚现身<br>在面向对象程序中尽量少用switch语句,因为switch容易造成重复.而且修改switch条件时,需要找到所有的switch来进行修改</li>
<li>平行继承体系</li>
<li>冗余类<br>消除没有用的类</li>
<li>夸夸其谈未来性</li>
<li>令人迷惑的暂时字段</li>
<li>过度耦合的消息链</li>
<li>中间人<br>不要过度使用委托</li>
<li>狎昵关系</li>
<li>异曲同工的类</li>
<li>不完美的类库</li>
<li>过多的注释</li>
</ol>
<h3 id="重构方法"><a href="#重构方法" class="headerlink" title="重构方法"></a>重构方法</h3><blockquote>
<p>这里仅仅记录了部分的重构方法</p>
</blockquote>
<ol>
<li>提取方法<br>在重构中有一个很核心的动作就是将代码提取为一个单独的方法.这种方式其实也杜绝了重复代码的出现,能够在我们修改代码的时候只需要修改一处就可以.并且能够在多个地方使用</li>
<li>将注释提取为方法<br>理想的程序就是代码完全能够表达自己,当我们在程序中看到注释或者添加注释的时候,我们可以先思考下能否将注释下的代码提取为一个方法,并且方法的函数名称能够体现注释的内容,方法名称要体现程序做了什么而不是怎么做.</li>
<li>明确类的职责<br>类的职责不宜过于多,不宜过于复杂.如果看到一个类承担的职责很多,我们可以考虑是否可以将此类拆分,将不属于其应该承担的责任提取到一个新的类中.然后在源类中通过引用来使用新类中的字段或方法</li>
<li>用查询来代替变量<br>就是在我们使用变量时,我们应该采用计算变量的方法来替代此变量.其实对于这一做法,我是抱有怀疑态度的,因为这造成了函数运行多次.会造成性能下降,但是书中说性能优化属于优化阶段的工作,而且这样重构会为优化阶段带来很好的铺垫.这个我觉得还是主要看平时我们的工作中需要具体情况具体分析.不能尽信书,什么东西都需要我们自己的独立思考</li>
<li>以卫语句取代嵌套条件表达式<br>条件表达式的两种形式:1.所有分支都属于正常分支;2.只有一种是正常行为,其他都是不正常行为.针对情况1,建议使用if…else结构;针对情况2,使用if进行判断,然后直接返回结果.这样子处理能够提高程序清晰度</li>
<li>封装集合<br>当我们在类中有个字段是集合时,我们的返回函数不应该直接返回集合自身,而是应该返回集合的只读副本.另外,不应该为这整个集合提供一个设值函数,应该提供为集合添加,删除元素的函数.</li>
<li>分解条件表达式<br>将复杂的条件表达式分解为较简单的表达式,可是试着尝试将if段落以及else then等提炼为单独的函数</li>
<li>合并条件表达式<br>如果发现检查条件各不相同,但是最终的行为一致.应该使用逻辑与和逻辑或合并为一个条件表示式</li>
<li>引入参数对象<br>可以使用对象来替换函数中的众多参数.比如,遇到数据范围的,参数是一个开始时间,结束时间,那么可以新建一个日期范围类,其中的开始时间和结束时间不能修改.用此类来替换开始时间和结束时间.这样做的好处是可以缩短参数列表.</li>
<li>移除设置函数<br>如果类中的某个字段在对象创建之后不能修改,那么就不提供设置函数,并且将此字段设为<strong>final</strong></li>
</ol>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>Read/Write locks in java(java中的读写锁)</title>
    <url>/Read-Write-locks-in-java-java%E4%B8%AD%E7%9A%84%E8%AF%BB%E5%86%99%E9%94%81.html</url>
    <content><![CDATA[<p>本篇文章主要介绍读写锁的一些原理及实现。翻译原文<a href="http://tutorials.jenkov.com/java-concurrency/read-write-locks.html">地址</a></p>
<h1 id="Java中的读写锁"><a href="#Java中的读写锁" class="headerlink" title="Java中的读写锁"></a>Java中的读写锁</h1><p>假设一个java应用程序需要读以及写一些资源，但是写的频率要远远低于读。多个读线程读取资源不会有什么问题。但是如果一个线程想要写资源，那么同时就不能有其他线程读或写这个资源。为了能够允许多个读线程和一个写线程，我们需要读写锁。<br>虽然Java中提供了读写锁的实现，但是我们还是要知道读写锁背后的原理，这样才能在实际使用中处理具体的问题。</p>
<h2 id="Java中实现读写锁"><a href="#Java中实现读写锁" class="headerlink" title="Java中实现读写锁"></a>Java中实现读写锁</h2><p>总结一下对于获取资源的读权限和写权限可以如下：<br>读权限：当没有其他线程写当前资源或者没有其他线程请求当前资源的写权限，那么当前线程就能够获取资源的读权限<br>写权限：如果没有其他线程读或者写当前资源，当前线程就能获取资源的写权限<br>只要没有其他线程正在写资源或者没有其他线程请求写资源，那么当前线程就能够读取资源。如果读线程发生的很多，但是又没有提升写线程的优先级，那么就可能发生”饥饿”现象。</p>
<h2 id="可重入读写锁"><a href="#可重入读写锁" class="headerlink" title="可重入读写锁"></a>可重入读写锁</h2><h2 id="可重入读锁"><a href="#可重入读锁" class="headerlink" title="可重入读锁"></a>可重入读锁</h2><h2 id="可重入写锁"><a href="#可重入写锁" class="headerlink" title="可重入写锁"></a>可重入写锁</h2><h2 id="读锁升级到写锁"><a href="#读锁升级到写锁" class="headerlink" title="读锁升级到写锁"></a>读锁升级到写锁</h2><h2 id="写锁降级到读锁"><a href="#写锁降级到读锁" class="headerlink" title="写锁降级到读锁"></a>写锁降级到读锁</h2><h2 id="可重入读写锁的完整实现"><a href="#可重入读写锁的完整实现" class="headerlink" title="可重入读写锁的完整实现"></a>可重入读写锁的完整实现</h2><h2 id="在finally中调用unlock"><a href="#在finally中调用unlock" class="headerlink" title="在finally中调用unlock"></a>在finally中调用unlock</h2>]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>Thread Signaling</title>
    <url>/Thread-Signaling.html</url>
    <content><![CDATA[<h1 id="线程信号量及wait，notify方法"><a href="#线程信号量及wait，notify方法" class="headerlink" title="线程信号量及wait，notify方法"></a>线程信号量及wait，notify方法</h1><p>本篇主要介绍线程之间如何进行信号的通知。同时介绍wait，notify底层的一些实现。</p>
<h2 id="通过共享对象进行信号通知"><a href="#通过共享对象进行信号通知" class="headerlink" title="通过共享对象进行信号通知"></a>通过共享对象进行信号通知</h2><p>最简单的进行线程之间通知的方式就是采用共享变量的方式。比如下面的代码<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySignal</span>&#123;</span><br><span class="line">  <span class="keyword">protected</span> <span class="type">boolean</span> <span class="variable">hasDataToProcess</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="type">boolean</span> <span class="title function_">hasDataToProcess</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.hasDataToProcess;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">setHasDataToProcess</span><span class="params">(<span class="type">boolean</span> hasData)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.hasDataToProcess = hasData;  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>线程A和线程B共享同一个MySingal实例，当线程A处理好数据后，可以设置hasDataToProcess属性为true，然后线程B获取到此属性。从而完成线程之间的信号通知。当然，如果线程A和线程B不是在同一个MySingal实例上进行的，则不能进行信号的传递。</p>
<h2 id="忙等待"><a href="#忙等待" class="headerlink" title="忙等待"></a>忙等待</h2><p>在采用MySingal的例子中，一般会采用下面的代码来判断一个线程是否可以进行处理了。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="type">MySignal</span> <span class="variable">sharedSignal</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MySingal</span>()</span><br><span class="line"><span class="keyword">while</span>(!sharedSignal.hasDataToProcess())&#123;</span><br><span class="line">  <span class="comment">//do nothing... busy waiting</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>从代码中可以看到，检测hasDataToProcess属性是在一个while循环中，如果hasDataToProcess为false，这就会造成线程一直在执行while语句，造成忙等待。这会造成CPU资源的浪费。</p>
<h2 id="wait，notify，notifyAll使用"><a href="#wait，notify，notifyAll使用" class="headerlink" title="wait，notify，notifyAll使用"></a>wait，notify，notifyAll使用</h2><p>一般在Java中，我们一般会采用wait，notify或notifyAll进行线程之间信号的传递。线程调用某一个对象上的wait方法前，必须首先获取该对象上的锁，才能执行此对象上的wait方法。在调用notify或者notifyAll之前，也是要获取对应对象上的锁。调用wait方法时，会释放此对象上的锁，线程进入阻塞状态，等待信号。而调用notify后，会随机唤醒一个同对象上的线程，但是必须是退出了notify对应的synchronized块后，被唤醒的线程才能继续执行，因为被唤醒的线程还要获取对象上的锁。如下面的代码所示：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MonitorObject</span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyWaitNotify</span>&#123;</span><br><span class="line">  <span class="type">MonitorObject</span> <span class="variable">myMonitorObject</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MonitorObject</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doWait</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(myMonitorObject)&#123;</span><br><span class="line">      <span class="keyword">try</span>&#123;</span><br><span class="line">        myMonitorObject.wait();</span><br><span class="line">      &#125; <span class="keyword">catch</span>(InterruptedException e)&#123;...&#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doNotify</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(myMonitorObject)&#123;</span><br><span class="line">      myMonitorObject.notify();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>从代码中，可以看到在myMonitorObject上调用wait方法之前，会先获取myMonitorObject上的锁。在调用notify方法之前，也是要先获取myMonitorObject上的锁。在下面的内容中我会简单介绍wait和notify的底层原理。</p>
<h3 id="wait-notify-notifyAll在Object源码中的介绍"><a href="#wait-notify-notifyAll在Object源码中的介绍" class="headerlink" title="wait notify notifyAll在Object源码中的介绍"></a>wait notify notifyAll在Object源码中的介绍</h3><p>在JDK1.8中，Object对象中有三个wait(),wait(long timeout),wait(long timeout, int nanos)这三个方法，它们的主要区别是后两个方法增加了等待的时间。<br>下面是JDK1.8中关于wait(long timeout)方法的描述：</p>
<blockquote>
<p>/**</p>
<pre><code> * Causes the current thread to wait until either another thread invokes the
 * &#123;@link java.lang.Object#notify()&#125; method or the
 * &#123;@link java.lang.Object#notifyAll()&#125; method for this object, or a
 * specified amount of time has elapsed.
 * &lt;p&gt;
 * The current thread must own this object&#39;s monitor.
 * &lt;p&gt;
 * This method causes the current thread (call it &lt;var&gt;T&lt;/var&gt;) to
 * place itself in the wait set for this object and then to relinquish
 * any and all synchronization claims on this object. Thread &lt;var&gt;T&lt;/var&gt;
 * becomes disabled for thread scheduling purposes and lies dormant
 * until one of four things happens:
 * &lt;ul&gt;
 * &lt;li&gt;Some other thread invokes the &#123;@code notify&#125; method for this
 * object and thread &lt;var&gt;T&lt;/var&gt; happens to be arbitrarily chosen as
 * the thread to be awakened.
 * &lt;li&gt;Some other thread invokes the &#123;@code notifyAll&#125; method for this
 * object.
 * &lt;li&gt;Some other thread &#123;@linkplain Thread#interrupt() interrupts&#125;
 * thread &lt;var&gt;T&lt;/var&gt;.
 * &lt;li&gt;The specified amount of real time has elapsed, more or less.  If
 * &#123;@code timeout&#125; is zero, however, then real time is not taken into
 * consideration and the thread simply waits until notified.
 * &lt;/ul&gt;
 * The thread &lt;var&gt;T&lt;/var&gt; is then removed from the wait set for this
 * object and re-enabled for thread scheduling. It then competes in the
 * usual manner with other threads for the right to synchronize on the
 * object; once it has gained control of the object, all its
 * synchronization claims on the object are restored to the status quo
 * ante - that is, to the situation as of the time that the &#123;@code wait&#125;
 * method was invoked. Thread &lt;var&gt;T&lt;/var&gt; then returns from the
 * invocation of the &#123;@code wait&#125; method. Thus, on return from the
 * &#123;@code wait&#125; method, the synchronization state of the object and of
 * thread &#123;@code T&#125; is exactly as it was when the &#123;@code wait&#125; method
 * was invoked.
 * &lt;p&gt;
 * A thread can also wake up without being notified, interrupted, or
 * timing out, a so-called &lt;i&gt;spurious wakeup&lt;/i&gt;.  While this will rarely
 * occur in practice, applications must guard against it by testing for
 * the condition that should have caused the thread to be awakened, and
 * continuing to wait if the condition is not satisfied.  In other words,
 * waits should always occur in loops, like this one:
 * &lt;pre&gt;
 *     synchronized (obj) &#123;
 *         while (&amp;lt;condition does not hold&amp;gt;)
 *             obj.wait(timeout);
 *         ... // Perform action appropriate to condition
 *     &#125;
 * &lt;/pre&gt;
 * (For more information on this topic, see Section 3.2.3 in Doug Lea&#39;s
 * &quot;Concurrent Programming in Java (Second Edition)&quot; (Addison-Wesley,
 * 2000), or Item 50 in Joshua Bloch&#39;s &quot;Effective Java Programming
 * Language Guide&quot; (Addison-Wesley, 2001).
 *
 * &lt;p&gt;If the current thread is &#123;@linkplain java.lang.Thread#interrupt()
 * interrupted&#125; by any thread before or while it is waiting, then an
 * &#123;@code InterruptedException&#125; is thrown.  This exception is not
 * thrown until the lock status of this object has been restored as
 * described above.
 *
 * &lt;p&gt;
 * Note that the &#123;@code wait&#125; method, as it places the current thread
 * into the wait set for this object, unlocks only this object; any
 * other objects on which the current thread may be synchronized remain
 * locked while the thread waits.
 * &lt;p&gt;
 * This method should only be called by a thread that is the owner
 * of this object&#39;s monitor. See the &#123;@code notify&#125; method for a
 * description of the ways in which a thread can become the owner of
 * a monitor.
 *
 * @param      timeout   the maximum time to wait in milliseconds.
 * @throws  IllegalArgumentException      if the value of timeout is
 *               negative.
 * @throws  IllegalMonitorStateException  if the current thread is not
 *               the owner of the object&#39;s monitor.
 * @throws  InterruptedException if any thread interrupted the
 *             current thread before or while the current thread
 *             was waiting for a notification.  The &lt;i&gt;interrupted
 *             status&lt;/i&gt; of the current thread is cleared when
 *             this exception is thrown.
 * @see        java.lang.Object#notify()
 * @see        java.lang.Object#notifyAll()
 */
public final native void wait(long timeout) throws InterruptedException;
</code></pre></blockquote>
<p>从代码的注释中，我们可以获得以下一些内容：</p>
<ol>
<li>调用wait的线程一定要获取对象上的monitor，在调用wait后，会释放该对象上的锁。</li>
<li>发生以下四种情况线程会被唤醒：<ul>
<li>其他的线程在相同的对象上调用了notify</li>
<li>其他的线程在相同的对象上调用了notifyAll</li>
<li>其他的线程终止了当前线程(interrupt方法)，会扔出InterruptedException异常</li>
<li>指定的最大等待时间到了</li>
</ul>
</li>
<li>当线程被唤醒时，当前的线程会从对象的等待集合中移除，重新进入线程调度阶段。之后会跟其他线程竞争获取对象上的锁。</li>
<li>线程可能在没有上述四种情况发生的时候，被唤醒。这被称为伪唤醒，下面会有详细介绍。</li>
</ol>
<h3 id="浅析Object-monitor的底层原理"><a href="#浅析Object-monitor的底层原理" class="headerlink" title="浅析Object monitor的底层原理"></a>浅析Object monitor的底层原理</h3><p>在JVM实现获取对象上的锁，是通过monitor进行实现的。图示如下：<br><img src="/Thread-Signaling/monitor.png" class="" title="java-memory-model"><br>当一个线程需要获取 Object 的锁时，会被放入 EntrySet 中进行等待，如果该线程获取到了锁，成为当前锁的 owner。如果根据程序逻辑，一个已经获得了锁的线程缺少某些外部条件，而无法继续进行下去（例如生产者发现队列已满或者消费者发现队列为空），那么该线程可以通过调用 wait 方法将锁释放，进入 wait set 中阻塞进行等待，其它线程在这个时候有机会获得锁，去干其它的事情，从而使得之前不成立的外部条件成立，这样先前被阻塞的线程就可以重新进入 EntrySet 去竞争锁。</p>
<h3 id="notify和notifyAll区别"><a href="#notify和notifyAll区别" class="headerlink" title="notify和notifyAll区别"></a>notify和notifyAll区别</h3><p>乍一看，notify和notifyAll的区别很简单，就是notify只能随机选择一个处于等待状态的线程进行唤醒；而notifyAll可以唤醒所有处于等待状态下的线程，但是也是只有一个线程能够继续执行。<br>如果结合上面的图片，我们就能更好地进行理解。当线程在对象上调用notify方法时，随机选择一个处于等待状态的线程，并且把该线程放置在该对象的EntrySet列表中。而如果调用的是notifyAll方法时，所有的处于等待状态下的线程都会进入到EntrySet中，从而多个线程进行对象上的锁。notify有点类似于网络中的单播，而notifyAll类似于多播。</p>
<h2 id="丢失信号"><a href="#丢失信号" class="headerlink" title="丢失信号"></a>丢失信号</h2><p>设想一下这种情况，有一个线程首先调用了notify方法，然后其他的线程调用了wait方法。那么处于wait下的线程将不会接受到之前线程发送的notify信号。如下面代码所示，<a href="https://github.com/lightnine/daydayup/blob/master/src/main/java/com/leon/concurrent/waitNotify/WaitNotifyMissSingal.java">代码地址</a>：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WaitNotifyMissSingal</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">Object</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;thread B is waiting to get lock&quot;</span>);</span><br><span class="line">                <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;thread B get lock&quot;</span>);</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        TimeUnit.SECONDS.sleep(<span class="number">5</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                    lock.notify();</span><br><span class="line">                    System.out.println(<span class="string">&quot;thread B do notify method&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;thread A is waiting to get lock&quot;</span>);</span><br><span class="line">                <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;thread A get lock&quot;</span>);</span><br><span class="line">                        TimeUnit.SECONDS.sleep(<span class="number">1</span>);</span><br><span class="line">                        System.out.println(<span class="string">&quot;thread A do wait method&quot;</span>);</span><br><span class="line">                        lock.wait();</span><br><span class="line">                        System.out.println(<span class="string">&quot;wait end&quot;</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>运行上面的代码，程序会一直运行下去。那么如何解决这个问题呢，其实在Object的wait的方法注释中也有对应的说明。我们可以把通知信号保存在信号类的成员变量中。<a href="https://github.com/lightnine/daydayup/blob/master/src/main/java/com/leon/concurrent/waitNotify/MyWaitNotify2.java">代码地址</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyWaitNotify2</span>&#123;</span><br><span class="line">  <span class="type">MonitorObject</span> <span class="variable">myMonitorObject</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MonitorObject</span>();</span><br><span class="line">  <span class="type">boolean</span> <span class="variable">wasSignalled</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doWait</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(myMonitorObject)&#123;</span><br><span class="line">      <span class="keyword">if</span>(!wasSignalled)&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">          myMonitorObject.wait();</span><br><span class="line">         &#125; <span class="keyword">catch</span>(InterruptedException e)&#123;...&#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//clear signal and continue running.</span></span><br><span class="line">      wasSignalled = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doNotify</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(myMonitorObject)&#123;</span><br><span class="line">      wasSignalled = <span class="literal">true</span>;</span><br><span class="line">      myMonitorObject.notify();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>在上面的代码中，将信号保存在了wasSingalled变量中，只要调用了notify方法，就是将wasSignalled设置为true，表示有线程执行了notify。在doWait方法中，如果wasSignalled为false，则当前的线程会执行wait方法，进入等待状态；而当wasSignalled为true时，不会执行wait方法，只会将wasSignalled设置为false。</p>
<h2 id="伪唤醒"><a href="#伪唤醒" class="headerlink" title="伪唤醒"></a>伪唤醒</h2><p>因为一些底层操作系统的原因，具体的可以查看unix操作系统相关内容。简单理解，就是当线程没有接受到唤醒信号时，而线程被错误的唤醒。为了防止伪唤醒，一定要在while循环中检查信号变量的值。这样的循环也叫自旋锁。代码如下：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyWaitNotify3</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="type">MonitorObject</span> <span class="variable">myMonitorObject</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MonitorObject</span>();</span><br><span class="line">  <span class="type">boolean</span> <span class="variable">wasSignalled</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doWait</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(myMonitorObject)&#123;</span><br><span class="line">      <span class="keyword">while</span>(!wasSignalled)&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">          myMonitorObject.wait();</span><br><span class="line">         &#125; <span class="keyword">catch</span>(InterruptedException e)&#123;...&#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//clear signal and continue running.</span></span><br><span class="line">      wasSignalled = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doNotify</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(myMonitorObject)&#123;</span><br><span class="line">      wasSignalled = <span class="literal">true</span>;</span><br><span class="line">      myMonitorObject.notify();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="不要在常量字符串或全局对象上调用wait方法"><a href="#不要在常量字符串或全局对象上调用wait方法" class="headerlink" title="不要在常量字符串或全局对象上调用wait方法"></a>不要在常量字符串或全局对象上调用wait方法</h2><p>请看下面的例子<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyWaitNotify</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="type">String</span> <span class="variable">myMonitorObject</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">  <span class="type">boolean</span> <span class="variable">wasSignalled</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doWait</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(myMonitorObject)&#123;</span><br><span class="line">      <span class="keyword">while</span>(!wasSignalled)&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">          myMonitorObject.wait();</span><br><span class="line">         &#125; <span class="keyword">catch</span>(InterruptedException e)&#123;...&#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//clear signal and continue running.</span></span><br><span class="line">      wasSignalled = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doNotify</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(myMonitorObject)&#123;</span><br><span class="line">      wasSignalled = <span class="literal">true</span>;</span><br><span class="line">      myMonitorObject.notify();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>从代码中我们可以看到，在上锁时是对myMonitorObject对象上锁，也是在myMonitorObject上调用wait方法，而myMonitorObject是一个空的字符串。我们知道，JVM会将相同的字符串看成同一个对象。也就说说，如果有两个MyWaitNotify实例，则这两个实例中的myMonitorObject是指向同一个对象的。那么一个在实例MyWaitNotify上调用wait的线程会被在另一个实例MyWaitNotify上调用doNotify方法的线程唤醒。下面的图表示了实例的成员指向了相同的对象。<br><img src="/Thread-Signaling/strings-wait-notify.png" class="" title="strings-wait-notify"><br>在上图中，4个线程是在相同的String常量上调用wait和notify方法，但是信号wasSignalled仍然是单独存放在对应的实例对象上。即一个在MyWaitNotify1实例上调用doNotify方法的线程可能会唤醒在MyWaitNotify2实例上等待的线程，但是唤醒信号仍然是单独保存在MyWaitNotify1实例中。<br>如果仔细看上面的程序，发现当在第二个MyWaitNotify2实例上调用doNotify方法时，会唤醒线程A或者B，但是由于在while循环中的wasSignalled变量，对于MyWaitNotify1实例仍然是false。所以被唤醒的线程A或者B从wait启动，但是会再次进入while循环调用wait，再次进入阻塞状态。这跟伪唤醒很像。<br>由于在doNotify方法中调用的notify方法，此方法不像notifyAll方法，notify方法只会唤醒一个线程，如果是线程C调用的doNotify，本来想唤醒的是线程D。但是有可能会错误的唤醒线程A或B，并且线程A或B会修改对应实例上的wasSignalled变量。而发给D的信号就丢失了，就有点像信号丢失的情况。如果将doNotify方法中的notify替换成notifyAll就不会有这个问题。但是这是一个坏主意，当应用仅仅只需要唤醒一个线程时，没有任何理由要把所有的线程都唤醒。<br>注意，对于wait/notify的情况，永远不要使用全局的对象例如string常量。在wait和notify上使用的对象针对对应的实例必须是独一的。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="http://tutorials.jenkov.com/java-concurrency/thread-signaling.html">http://tutorials.jenkov.com/java-concurrency/thread-signaling.html</a></li>
<li><a href="http://www.php.cn/java-article-410323.html">http://www.php.cn/java-article-410323.html</a></li>
</ol>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>Top 5 things every apache kafka developer should know</title>
    <url>/Top-5-things-every-apache-kafka-developer-should-know.html</url>
    <content><![CDATA[<h1 id="top-5-things-every-apache-kafka-developer-should-know"><a href="#top-5-things-every-apache-kafka-developer-should-know" class="headerlink" title="top 5 things every apache kafka developer should know"></a>top 5 things every apache kafka developer should know</h1><blockquote>
<p>翻译自：<a href="https://www.confluent.io/blog/top-5-things-every-apache-kafka-developer-should-know">https://www.confluent.io/blog/top-5-things-every-apache-kafka-developer-should-know</a><br>介绍下面5个内容</p>
<ul>
<li>理解消息传递和持久化保证</li>
<li>学习producer api中的新的粘性分区(learn about the new sticky partitioner in the producer API)</li>
<li>利用cooperative rebalancing(协同重平衡)来避免消费者组执行rebalance时的stop the world</li>
<li>掌握常用命令行工具<ul>
<li>kafka console producer</li>
<li>kafka consule consumer</li>
<li>dump log</li>
<li>delete records</li>
</ul>
</li>
<li>使用record headers的能力<ul>
<li>为kafka记录增加headers</li>
<li>检索headers</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="Tip1：理解消息传递和持久化保证"><a href="#Tip1：理解消息传递和持久化保证" class="headerlink" title="Tip1：理解消息传递和持久化保证"></a>Tip1：理解消息传递和持久化保证</h2><p>针对数据持久化，KafkaProducer提供了不同的配置。acks 配置指定了当生产者接受到多少消息确认后，才认为记录已经成功发送到broker上。kafka提供了以下三种选择：</p>
<ul>
<li>none: 生产者不等待broker的确认，发送消息后就认为已经成功发送到broker上。</li>
<li>one: 生产者等待leader broker的确认(leader broker有一个)，一定收到确认，就认为消息发送成功</li>
<li>all: 生产者需要等待所有的ISR(in-sync replicas) broker都确认消息后，才认为消息发送成功。<br>如果需要更到的发送吞吐量，可以损失一定的数据，那么可以使用none或one。而如果应用不能容忍数据丢失，那么可以设置all，但是这样吞吐量会降低。<br>这里需要说明下acks=all的情况。下面的场景描述中，producer都是使用acks=all来发送消息，并且topic副本数是3，一个leader，两个follower。<br>情况1：如果这些副本中的记录偏移量是一致的，那么他们被认为是in-sync的。如下面所示，producer采用acks=all的情况:<img src="/Top-5-things-every-apache-kafka-developer-should-know/producer-ack-1024x691.png" class="" title="producer ack">
情况2：假设由于某些情况(网络分区，负载过高等)，导致两个follower没有跟上leader，那么follower就不是in sync的。此时生产者发送消息，那么实际的确认只会有一个。acks=all并不是指定有多少副本必须在in-sync。leader broker始终跟自己是同步的。<img src="/Top-5-things-every-apache-kafka-developer-should-know/in-sync-replicas-1024x710.png" class="" title="in-sync acks">
</li>
</ul>
<p>一般来说，设置acks=all, 我们的要求通常都是所有副本都应该确认，或者至少大量的in sync副本应该确认。如果不是这样，那么应该抛出异常知道所有副本都在in sync中。<br>为了满足这个要求，kafka提供了这样一个配置：min.insync.replicas. 这个配置强制指定多少个副本写成功才被认为真正写成功。需要注意的是，min.insync.replicas配置在是broker或者topic级别，而不是在producer上。min.insync.replicas默认值是1。所以为了避免上面说的情况，在三个副本的情况下，需要将min.insync.replicas设置为2。<br><img src="/Top-5-things-every-apache-kafka-developer-should-know/not-enough-replicas-1.png" class="" title="not-enough-replicas"><br>上图中展示了in sync中的副本不满足min.insync.replicas要求的情况，此时producer发送的消息，leader broker不会将记录添加到log中，而是会抛出NotEnoughReplicasException 或者 NotEnoughReplicasAfterAppendException。副本与leader不一致被认为是一种可以重试的错误，所以producer会重试直到成功或者达到超时时间（默认值两分钟）<a href="https://kafka.apache.org/documentation/#delivery.timeout.ms">delivery.timeout.ms</a>。<br>如果需要非常高的数据持久化保证，那么应该同时设置min.insync.replicas和acks=all.</p>
<h2 id="Tip-2-Learn-about-the-new-sticky-partitioner-in-the-producer-API"><a href="#Tip-2-Learn-about-the-new-sticky-partitioner-in-the-producer-API" class="headerlink" title="Tip 2: Learn about the new sticky partitioner in the producer API"></a>Tip 2: Learn about the new sticky partitioner in the producer API</h2><p>kafka需要partition来提升吞吐量并且将消息均衡到不同的broker上。kafka的消息记录是key/value格式，其中key可以为null。kafka producer在发送消息时，不会立即发送，而是将消息放置到对应的partition batch中(类似缓存)，待缓存满了，在一次发送。batch是一种增加网络利用的有效方式。在将消息发送到partition中，通常有三种方式来决定发送到哪个partition上。</p>
<ul>
<li>方式1：在发送消息时，直接指定消息对应的partition。这种情况，producer直接使用这个partition</li>
<li>方式2：如果没有提供partition，消息包含key，那么producer会使用key的hash值来决定partition。</li>
<li>方式3：如果既没有key也没有提供partition信息，那么kafka会使用round-robin的方式将消息发送到不同的partition中。producer会将第一个消息发送到partition 0，第二个消息发送到partition 1，以此类推。</li>
</ul>
<p>下图展示了方式3:<br><img src="/Top-5-things-every-apache-kafka-developer-should-know/producer-partition-updated.png" class="" title="producer-partition-updated"><br>round robin方法对于将消息均衡到不同的partition上工作的很好。但是存在一个缺点，由于producer是依次将消息发送到不同的partition batch中，那么有可能会出现每个partition中的batch都填充不满。比如下面展示的，topic有三个partition。假设应用产生了9条消息，并且消息没有key，所有的消息几乎是同时发送，如下图：<br><img src="/Top-5-things-every-apache-kafka-developer-should-know/sparse_batches_sent-updated.png" class="" title="sparse_batches_sent-updated"><br>9条记录分散到是三个batch中，每个batch有三条。但是如果我们将9条消息放到一个batch中会更好。更少的batch使用更少的网络带宽并且对于broker的负载更小。<br>kafka 2.4.0新增了sticky partitioner approach. 这种方法能够将消息发送到一个partition的batch中直到此batch满了。然后，发送这个batch，sticky partitioner使用下一个partition的batch。如下图展示了使用sticky partitioner的例子：<br><img src="/Top-5-things-every-apache-kafka-developer-should-know/batch-partition-updated.png" class="" title="batch-partition-updated"><br>通过使用sticky partitioner方法，我们减少了请求次数，同时也减少了请求队列上的负载，也减少了系统延迟。需要注意的时，sticky partitioner仍然是将消息均衡放置到不同的partition batch中。可以将这种认为是per-batch round robin 或者 eventually even approach。<br>如果想要更多了解sticky 模式，可以参考<a href="https://www.confluent.io/blog/apache-kafka-producer-improvements-sticky-partitioner/"> Apache Kafka Producer Improvements with the Sticky Partitioner</a></p>
<h2 id="Tip-3-Avoid-“stop-the-world”-consumer-group-rebalances-by-using-cooperative-rebalancing"><a href="#Tip-3-Avoid-“stop-the-world”-consumer-group-rebalances-by-using-cooperative-rebalancing" class="headerlink" title="Tip 3: Avoid “stop-the world” consumer group rebalances by using cooperative rebalancing"></a>Tip 3: Avoid “stop-the world” consumer group rebalances by using cooperative rebalancing</h2><p>kafka是一个分布式系统，而分布式系统中一个重要的事情就是如何处理失败。kafka处理失败的方式之一是使用consumer group，consumer group管理多个consumer。如果其中一个consumer停止，kafka会进行rebalance从而确保另一个consumer能够接管这个工作。<br>从2.4版本开始，kafka引入了一个新的rebalance协议，cooperative rebalancing。在深入了解cooperative rebalancing之前，先来了解一下consumer group的基础。<br>假设一个分布式应用(比如一个微服务的多个副本)有个多个consumer，订阅同一个topic。这些consumer组成了一个consumer group，具有同样的.group.id。在consumer group中的每个consumer负责从一个或多个partition中消费消息。这些partition的分配是由consumer group中的leader进行的。如下图所示：<br><img src="/Top-5-things-every-apache-kafka-developer-should-know/six-partitions.png" class="" title="six-partitions"><br>从图中可以看到，总共有6个partition，在理想的情况下，每个consumer负责消费两个partition。但是如果其中的某个应用失败了或者不能连接网络。那么对应的partition中的消息是不是就不能被消费直到应用恢复？幸运的是，由于consumer rebalancing协议的存在，不会发生这种情况。<br>下图展示了consumer group protocal过程：<br><img src="/Top-5-things-every-apache-kafka-developer-should-know/minus-consumer-2.png" class="" title="minus-consumer-2"><br>如上图，consumer2由于某些原因失败了。group coordinator将它从组中移除然后触发rebalance。rebalance尝试将工作负载在组内所有工作的consumer上进行均衡分布。在这个例子中，consumer2离开了组，rebalance会将consumer2拥有的partition分配给组内其他的consumer。所以对于一个consumer group，如果其中consumer失败了， 那么对于这些partition的处理不会产生影响。<br>但是，默认的rebalance协议有个缺点。在rebalance过程中，每个consumer都会放弃之前获得的partition(这会造成consumer停止消费)，知道topic下所有的partition都被重新分配。这种情况被称为stop the world rebalance。为了解决这个问题，依靠ConsumerPartitionAssignor实例，consumer简单的重新获取之前分配的partition，所以在这些partition上仍然能够继续消费。<br>上述描述的实现被称为<a href="https://www.confluent.io/blog/cooperative-rebalancing-in-kafka-streams-consumer-ksqldb/">eager rebalancing</a>, 因为它优先考虑的是针对一个consumer group中，不会有两个consumer同时对于一个partition拥有主权。<br>虽然对于同一个topic下的某个partition不能具有相同的consumer非常重要，但是有一种更好的方法，既能够提供安全性同时还不会暂停处理，既<a href="https://www.confluent.io/blog/incremental-cooperative-rebalancing-in-kafka/">incremental cooperative rebalancing</a>。这个方法在kafka2.3版本的kafka connect中被首次引入，现在已经在consumer group 协议中实现了。利用cooperative 方法，消费者不会在rebalance开始时主动放弃partition的所有权。在cooperative方法中，consumer group中的所有成员会将当前的分配进行编码然后将信息发送到group leader中。group leader决定那个partition需要修改对应的consumer。而不是一开始就完全从新分配。之后第二次rebalance发起，但是这一次，仅仅涉及到那些需要改变所有权的分区。这有可能是撤销不在用的partition或者新增的partition。对于那些没有改变所有权的分区，这些分区中的数据会继续进行处理。<br>这种处理办法解决了stop-the-world，而仅仅是暂停了哪些需要修改所有权分区的消费。这带来了更少的rebalance代驾以及降低了完成rebalance的时间。即使rebalance时间很长也没有关系，因为现在数据仍然被处理。使用CooperativeStickyAssignor能够开启这个功能。<br>如果要开启这个功能，则需要将partition.assignment.strategy设置为使用CooperativeStickyAssignor。这种设置完全是在客户端测，所以仅仅更新客户端版本即可。而在Kafka Stream中，这个功能是默认开启的。</p>
<h2 id="Tip-4：掌握命令行工具"><a href="#Tip-4：掌握命令行工具" class="headerlink" title="Tip 4：掌握命令行工具"></a>Tip 4：掌握命令行工具</h2><p>下面介绍了4种在平时工作中使用最多的工具。</p>
<h3 id="kafka-console-producer"><a href="#kafka-console-producer" class="headerlink" title="kafka console producer"></a>kafka console producer</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 开启发送者程序, 发送的消息只有value，没有key</span></span><br><span class="line">kafka-console-producer --topic &lt;topic&gt; --broker-list &lt;broker-host:port&gt;</span><br><span class="line"><span class="comment"># 发送消息，发送的消息包含key 和 value</span></span><br><span class="line">kafka-console-producer --topic &lt;topic&gt; --broker-list &lt;broker-host:port&gt; --property parse.key=<span class="literal">true</span> --property key.separator=<span class="string">&quot;:&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="kafka-console-consumer"><a href="#kafka-console-consumer" class="headerlink" title="kafka console consumer"></a>kafka console consumer</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 消费指定topic中的消息</span></span><br><span class="line">kafka-console-consumer --topic &lt;topic&gt; --bootstrap-server &lt;broker-host:port&gt;</span><br><span class="line"><span class="comment"># 指定从开始的地方消费</span></span><br><span class="line">kafka-console-consumer --topic &lt;topic&gt; --bootstrap-server &lt;broker-host:port&gt; --from-beginning</span><br><span class="line"><span class="comment"># 默认情况下consumer只会打印消息的value，如果想要打印消息的key，则输入下面命令</span></span><br><span class="line">kafka-console-consumer --topic &lt;topic&gt; --bootstrap-server &lt;broker-host:port&gt; --property print.key=<span class="literal">true</span> --property key.separator=<span class="string">&quot;:&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="Dump-log"><a href="#Dump-log" class="headerlink" title="Dump log"></a>Dump log</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 指定打印topic为example-0中的日志，参数--print-data-log表示输出日志</span></span><br><span class="line"><span class="comment"># 不过一般在生产环境中不会使用这个命令</span></span><br><span class="line">kafka-dump-log --print-data-log --files ./var/lib/kafka/data/example-0/00000000000000000000.<span class="built_in">log</span></span><br></pre></td></tr></table></figure>
<h3 id="delete-records"><a href="#delete-records" class="headerlink" title="delete records"></a>delete records</h3><p>kafka提供了配置来控制数据保留，包括时间和数据大小</p>
<ul>
<li>数据保留的时间由 log.retention.hours 控制，默认值是168hour，也就是一周</li>
<li>configuration.log.retention.bytes 控制segment文件最大是多少。默认值是-1, 也就是不限制大小</li>
</ul>
<p>如果想要删除数据，可以使用下述命令：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kafka-delete-records --bootstrap-server &lt;broker-host:port&gt; \</span><br><span class="line">                     --offset-json-file offsets.json</span><br></pre></td></tr></table></figure><br>offsets.json 文件内容如下：<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">   <span class="attr">&quot;partitions&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                  <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span> <span class="string">&quot;example&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> <span class="attr">&quot;offset&quot;</span><span class="punctuation">:</span> <span class="number">-1</span><span class="punctuation">&#125;</span></span><br><span class="line">                 <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                 <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="number">1</span></span><br><span class="line"> <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><br>参数介绍如下：</p>
<ul>
<li>topic：指定要删除数据对应的topic</li>
<li>partition：指定需要删除数据对应的partition</li>
<li>offset：指定从哪个offset开始删除，注：是删除offset之前的数据。-1表示删除当前HW之前的数据，HW(high watermark)表示能够开始消费的位置</li>
</ul>
<h2 id="Tip5：使用record-headers的能力"><a href="#Tip5：使用record-headers的能力" class="headerlink" title="Tip5：使用record headers的能力"></a>Tip5：使用record headers的能力</h2><p>Record headers可以给kafka消息添加一些元数据，并且不是给消息的key value添加额外的信息。比如如果你想要在消息中嵌入一些信息，如表示消息来源系统，也是是想要增加一些审计功能。<br>为什么不能将这些额外的数据添加到key中。因为给key中添加数据会带来两个潜在的问题</p>
<ol>
<li>首先，如果你使用的是压缩主题，那么给key添加信息会使得消息不正确。这样压缩不会像之前起作用</li>
<li>其次，给key添加额外的信息有可能会影响数据的partition分布</li>
</ol>
<h1 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h1><p>我们了解了kafka的五个tips，我们理解了下面的知识点</p>
<ol>
<li>消息持久性以及和消息传递之间的关系</li>
<li>producer API中的sticky partitioner</li>
<li>command line tools</li>
<li>record headers的能力</li>
</ol>
]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231n Convolutional Neural Networks for Visual Recognition</title>
    <url>/CS231n-Convolutional-Neural-Networks-for-Visual-Recognition.html</url>
    <content><![CDATA[<blockquote>
<p>这是一篇翻译文章,但是也不全是,主要是读了文章之后,用自己的话将其复述出来<br>来源: <a href="https://cs231n.github.io/convolutional-networks/">CS231n Convolutional Neural Networks for Visual Recognition</a></p>
</blockquote>
<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p>卷积神经网络跟一般的神经网络是非常相似的.它们都由神经元组成,并且这些神经元上都有需要学习的权重和偏置项.每个神经元接收输入,执行点积,然后可选择的将输出进行非线性运算.整个网络表示了一个可微的得分函数:即从原始的图像像素到对应的类.两者都有一个损失函数(例如:SVM/Softmax),并且在一般神经网络中用到的技术也能应用到CNN中.<br>两者的区别在哪里呢?ConvNet网络假设输入是图像,所以我们能够将某些属性编码到网络结构中.这使得前馈函数更有效率并且能极大的减少网络中的参数.</p>
<h1 id="CNN结构概览"><a href="#CNN结构概览" class="headerlink" title="CNN结构概览"></a>CNN结构概览</h1><p><em>回顾</em>:在一般的神经网络中,神经网络接收一个输入(一个向量),然后经过一系列的隐藏层进行转换.每个隐藏层是由一组神经元组成,每个神经元都与前一层的所有神经元相连,属于同一层的神经元完全独立并且不共享任何连接.最后一层是输出层,在分类问题中,它代表了类的得分.<br>一般的神经网络不能很好的扩展到完整的图像.在CIFAR-10中,一副图像的大小是32$\times$32$\times$3,所以隐藏层中的一个神经元上将会有32$\times$32$\times$3=3072个权重.参数的数量仍然可以接受,但是全连接结构不能扩展到更大的图像上了.例如,如果图像的大小为200$\times$200$\times$3,那么一个神经元将需要200$\times$200$\times$3=120000个权重.可见,全连接神经网络需要的参数将会非常多.这会导致过拟合.<br>卷积神经网络充分利用了输入是图像的事实,并且用一个更加合理的方式约束了神经网络的结构.特别的,与一般的神经网络不同,卷积神经网络各层由三维排列的神经元组成:宽度,高度,深度(注意,这里的深度指的是激活的第三维,而不是整个神经网络的深度).例如,在CIFAR-10中的输入图像的维度是32$\times$32$\times$3.我们很快会看到,当前层的神经元仅仅连接前一层中的部分神经元.此外,对于CIFAR-10最终的输出层的维度是1$\times$1$\times$10,因为ConvNet最后会将整个图像转换为一个类得分向量,下面是可视化:<br><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column"  style="width: 100%;"><img src="/CS231n-Convolutional-Neural-Networks-for-Visual-Recognition/neural_net2.jpeg" alt="常规神经网络"></div></div><div class="group-picture-row"><div class="group-picture-column"  style="width: 100%;"><img src="/CS231n-Convolutional-Neural-Networks-for-Visual-Recognition/cnn.jpeg" alt="ConvNet"></div></div></div></div><br>上图表示一个三层的神经网络,下图表示卷积神经网络.</p>
<blockquote>
<p>A ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters.</p>
</blockquote>
<h1 id="ConvNet-层"><a href="#ConvNet-层" class="headerlink" title="ConvNet 层"></a>ConvNet 层</h1><p>就像我们上面描述的,一个简单的ConvNet是一系列层组成,ConvNet的每层通过一个可微的函数将输入转化到输出.ConvNet主要由卷积层,池化层和全连接层组成.下面是一个针对CIFAR-10的简单例子:</p>
<ul>
<li>INPUT(32$\times$32$\times$3):输入是原始图像的像素,一副图像的宽是32,长是32,并且有三个颜色通道R,G,B</li>
<li>卷积层:当前层的神经元只连接前一层的部分神经元.如果我们使用12个过滤器,则经过卷积层后的维度是[32$\times$32$\times$12]</li>
<li>RELU:对于输入采用ReLu激活函数,并不会改变输入维度,如果前一个维度是[32$\times$32$\times$12],则经过ReLu之后仍然是[32$\times$32$\times$12]</li>
<li>POOL:池化层会在空间维度上执行下采样,这会导致维度变化,[16$\times$16$\times$12],但是注意最后一维没有改变</li>
<li><p>FC(全连接层):这是一个全连接的结构,最后的输出是[1$\times$1$\times$10].<br>卷积神经网络就是将原始的像素图像经过一层一层的计算,最后得到最终的分类得分.注意有些层需要参数,而有些层不需要参数.CONV/FC层不仅仅对于输入进行激活,同时需要将权重和偏置作用在输入上.而RELU/POOL只是一个固定的函数,并没有参数.<br>总结:</p>
</li>
<li><p>卷积神经网络就是一系列层组成,将输入图像体积转换为输出体积(体积表面了维度)</p>
</li>
<li>卷积神经网路包括完全不同的层(e.g. CONV/FC/RELU/POOl)</li>
<li>每一层通过一个可微的函数将3D volume的输入转换为3D volume的输出</li>
<li>有些层需要参数,有些不需要(e.g. CONV/FC 需要, RELU/POOlL不需要)</li>
<li>有些层需要额外的超参数,有些不需要(e.g. CONV/FC/POOL需要,RELU不需要)</li>
</ul>
<img src="/CS231n-Convolutional-Neural-Networks-for-Visual-Recognition/convnet.jpeg" class="" title="卷积神经网络结构图">
<p>因为无法很难画出3D的部分,所以这里每一层只展示了深度部分的一片.最后给出了得分最高的五个标签.这里展示的是一个很小的 VGG网络.<a href="http://cs231n.stanford.edu/">查看详细展示</a></p>
<h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>卷积层是卷积神经网络的核心部分,并且涉及了大量的计算.卷积层使用过滤器对于原图像进行卷积,过滤器每次只能针对整副图像的一部分进行计算,所以我们需要移动过滤器,遍历整个图像.这里过滤器的大小又叫做神经元的接收域.<br><em>Example 1</em>:假设输入为[32$\times$32$\times$3],过滤器大小为5$\times$5,那么卷积层中的某个神经元需要的参数为5$\times$5$\times$3 + 1=76.为什么需要这么多的参数呢?针对颜色通道R,当前过滤器对应的局部区域的点是5$\times$5=25个,有三个通道,所有总的参数为75,另外再加一个偏置项,所有一个神经元总共需要76个参数.注意这里的深度为3,这是因为输入的深度是3.</p>
<h2 id="Example-2-假设输入为-16-times-16-times-20-过滤器大小为3-times-3-那么卷积层中每个神经元都需要3-3-20-1-180个参数"><a href="#Example-2-假设输入为-16-times-16-times-20-过滤器大小为3-times-3-那么卷积层中每个神经元都需要3-3-20-1-180个参数" class="headerlink" title="Example 2:假设输入为[16$\times$16$\times$20],过滤器大小为3$\times$3,那么卷积层中每个神经元都需要3*3*20 + 1=180个参数."></a><em>Example 2</em>:假设输入为[16$\times$16$\times$20],过滤器大小为3$\times$3,那么卷积层中每个神经元都需要3*3*20 + 1=180个参数.</h2><div class="group-picture"><div class="group-picture-container"><div class="group-picture-row"><div class="group-picture-column"  style="width: 100%;"><img src="/CS231n-Convolutional-Neural-Networks-for-Visual-Recognition/depthcol.jpeg" class="" title="卷积层"></div></div><div class="group-picture-row"><div class="group-picture-column"  style="width: 100%;"><img src="/CS231n-Convolutional-Neural-Networks-for-Visual-Recognition/neuron_model.jpeg" class="" title="神经元"></div></div></div></div>
<p>第一张图展示了卷积层,可以看到一个神经元连接了原图像的局部区域,但是连接了所有的深度(这是是三个颜色通道).这里展示了五个神经元,这五个神经元都连接到了图像的同一个局域上.第二张图展示了神经元的计算.<br><strong>Spatial arrangement</strong> 前面我们仅仅讨论了卷积层中的每个神经元如何连接到前一层,我们还没有讨论在卷积层的输出中有多少个神经元.深度,步长,0值填充这些超参数控制着卷积层的输出的大小</p>
<ol>
<li>卷积层输出的深度等于过滤器的数量,而每个过滤器就是去寻找输入到卷积层数据的不同之处.如果输入是原始图像,那么过滤器就是去寻找不同方向的边,颜色等.</li>
<li>步长是过滤器移动的长度,一般常用的是1和2</li>
<li>0值填充就是在卷积层的输入的边界上填充0值,使用0值填充使得我们能够控制经过卷积层之后的空间大小.<br>下面的公式可以用来计算卷积层输出的空间大小<script type="math/tex; mode=display">(W - F + 2P)/S + 1</script>其中W(输入数据的大小),F(卷积层神经元的接收域大小),S(步长),P(零值填充的宽度).例如输入为7$\times$7,过滤器为3$\times$3,步长为1,不填充,则得出输出为5$\times$5.当步长变为2时,那么输出变为3$\times$3.</li>
</ol>
<hr>
<img src="/CS231n-Convolutional-Neural-Networks-for-Visual-Recognition/stride.jpeg" class="" title="空间排列">
<p>这里的输入只有一个x轴,输入为[1,2,-1,1,-3],过滤器大小为3,采用零值填充.所以W=5,F=3,P=1.图片最右侧是过滤器的权重,偏置为0.左图:步长为1,最后得到的输出的尺寸为5;右图:步长为2,最后得到的输出尺寸为3.所有黄色的神经元共享相同的参数</p>
<hr>
<p><em>Use of zero-padding</em>.当步长为1(即S=1),设置$P=(F-1)/2$,这样卷积层的输入跟输出将会有相同大小的空间.<br><em>Constraints on strides</em>.</p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><h2 id="Normalization-Layer"><a href="#Normalization-Layer" class="headerlink" title="Normalization Layer"></a>Normalization Layer</h2><h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><h2 id="全连接层转变为卷积层"><a href="#全连接层转变为卷积层" class="headerlink" title="全连接层转变为卷积层"></a>全连接层转变为卷积层</h2><h1 id="ConvNet-结构"><a href="#ConvNet-结构" class="headerlink" title="ConvNet 结构"></a>ConvNet 结构</h1><h2 id="层模式"><a href="#层模式" class="headerlink" title="层模式"></a>层模式</h2><h2 id="层大小模式"><a href="#层大小模式" class="headerlink" title="层大小模式"></a>层大小模式</h2><h2 id="常用CNN"><a href="#常用CNN" class="headerlink" title="常用CNN"></a>常用CNN</h2><h2 id="计算考虑"><a href="#计算考虑" class="headerlink" title="计算考虑"></a>计算考虑</h2><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1>]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Understanding LSTM Networks</title>
    <url>/Understanding-LSTM-Networks.html</url>
    <content><![CDATA[<p>这是一篇译文,<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">原文地址</a>.如果英文可以,建议直接看英文.</p>
<h1 id="循环神经网络-Recurrent-Neural-Networks"><a href="#循环神经网络-Recurrent-Neural-Networks" class="headerlink" title="循环神经网络(Recurrent Neural Networks)"></a>循环神经网络(Recurrent Neural Networks)</h1><p>在我们思考时,我们不会从头开始,肯定会在思考时加入之前的知识.就如同当你在阅读当前的博客时,你读的每个单词都是基于前面的单词.你不会扔掉所有的东西,然后在从头开始.你的想法有持久性.<br>传统的神经网络不能使用之前信息.假设你使用传统神经网络来将一部电影中的正在发生的事件分类,怎么使用当前事件之前的信息是很困难的.<br>循环神经网络解决了这个问题,在其中有循环,允许信息能够保持.<br><img src="/Understanding-LSTM-Networks/RNN-rolled.png" class="" title="Recurrent Neural Networks have loops."><br>这个图看起来有点奇怪,我们可以将其展开,如下图所示<br><img src="/Understanding-LSTM-Networks/RNN-unrolled.png" class="" title="An unrolled recurrent neural network"><br>从图中可以看出,RNN使用了前一时刻的状态来预测当前的状态<br>RNN在很多领域都取得了成功,比如:语音识别,自然语言处理,翻译,图像字幕等等.这里Andrej Karpathy的<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">blog</a>,里面列举了RNN一些应用.<br>本文主要介绍LSTM模型,LSTM模型是RNN的一种变种,在很多领域的表现都要比一般的RNN模型更好</p>
<h1 id="长期依赖存在的问题-The-Problem-of-Long-Term-Dependencies"><a href="#长期依赖存在的问题-The-Problem-of-Long-Term-Dependencies" class="headerlink" title="长期依赖存在的问题(The Problem of Long-Term Dependencies)"></a>长期依赖存在的问题(The Problem of Long-Term Dependencies)</h1><p>加入我们要基于之前的单词预测下一个单词,如”the clouds are in the <em>sky</em>“,我们要预测最后一个单词sky.在这个例子中,我们不需要更多的上下文,很明显最后一个单词是sky.RNN针对这种情况有很好的表现.<br><img src="/Understanding-LSTM-Networks/RNN-shorttermdepdencies.png" class=""><br>但是在有些情况下,我们需要更多的上下文.例如,我们要预测”I grew up in France… I speak fluent <em>French</em>.”中的最后一个单词French.从最近的信息,比如speak fluent等,可以推测最后一个单词是一种语言.但是如果要知道具体的语言,我们需要更多的上下文.预测点和其对应的相关信息之间的差距很大是由很大可能的.<br>但是,不幸的是随着差距增加,RNN不可能学会如何连接这种信息<br><img src="/Understanding-LSTM-Networks/RNN-longtermdependencies.png" class=""><br>从图中可以看出$h_{t+1}$不能很好地利用$X_0$和$X_1$的信息.理论上,RNN能够学习到长期依赖,但是在实践中,要想在RNN中使用这些长期依赖很困难.幸运的是LSTM模型解决了这个问题.</p>
<h1 id="LSTM网络-LSTM-Networks"><a href="#LSTM网络-LSTM-Networks" class="headerlink" title="LSTM网络(LSTM Networks)"></a>LSTM网络(LSTM Networks)</h1><p>LSTM全称Long Short Term Memory,长短期记忆网络.LSTM的设计就是为了避免长依赖问题,记忆长周期的信息是LSTM的默认行为.<br>所有的递归神经网络都具有重复模块的链式结构.在标准的RNN中,重复模块是一个非常简单的结构,例如单层tanh<br><img src="/Understanding-LSTM-Networks/LSTM3-SimpleRNN.png" class="" title="The repeating module in a standard RNN contains a single layer."><br>LSTM也有这种链式结构,但是重复的模块有一个不同的结构,在其中一个模块中,包含一个四层的神经网络,并且这四层以一种特别方式进行交互.<br><img src="/Understanding-LSTM-Networks/LSTM3-chain.png" class="" title="The repeating module in an LSTM contains four interacting layers."><br>图中的示例如下<br><img src="/Understanding-LSTM-Networks/LSTM2-notation.png" class=""><br>接下来我会详细介绍其中涉及的内容.</p>
<h1 id="LSTMs中的核心思想-The-Core-Idea-Behind-LSTMs"><a href="#LSTMs中的核心思想-The-Core-Idea-Behind-LSTMs" class="headerlink" title="LSTMs中的核心思想(The Core Idea Behind LSTMs)"></a>LSTMs中的核心思想(The Core Idea Behind LSTMs)</h1><p>LSTMs中的核心是单元状态,在图中就是最上面的那条水平线.单元状态就像是一条输送带.单元状态沿着整个链流动,对其只有一些线性作用,信息的流动很容易.<br><img src="/Understanding-LSTM-Networks/LSTM3-C-line.png" class=""><br>LSTM能够移除或者添加信息到单元状态,并且由成为门的结构来控制.门可以选择性的让信息通过或不通过,它是由sigmoid神经网络层和点积操作组成.<br><img src="/Understanding-LSTM-Networks/LSTM3-gate.png" class=""><br>sigmoid层的输出范围0-1,描述了可以通过多少的信息.输出为0意味着什么都不通过,输出为1意味着都能通过.从LSTM的结构中,我们可以看到LSTM的一个重复模块包括三个这样的门.</p>
<h1 id="一步一步认识LSTM"><a href="#一步一步认识LSTM" class="headerlink" title="一步一步认识LSTM"></a>一步一步认识LSTM</h1><p>LSTM的第一步就是决定从单元状态中丢弃哪些信息.这个决定是由一个称为”遗忘门(forget gate layer)”单层sigmoid层组成.它接收$h<em>{t-1}$和$x_t$作为输入,输出0到1之间的数字.对于前一个单元状态$C</em>{t-1}$,当遗忘门的输出为1时,表示完全保留$C<em>{t-1}$;当遗忘门的输出为0时,表示完全舍弃$C</em>{t-1}$.<br>我们在回到之前根据之前的内容来预测下一个单词这个问题.在这样的问题中,单元状态可能包括当前对象的性别,所以可以使用正确的代词.但是当遇到一个新的对象时,我们就想要忘记老对象的性别.<br><img src="/Understanding-LSTM-Networks/LSTM3-focus-f.png" class=""></p>
<blockquote>
<p>图中的$W<em>f \cdot [h</em>{t-1},x<em>t]$,大家看起来有些不清楚.个人认为比较合适的写法如下<br>$\sigma(W_fx_t + U_r h</em>{t-1} + b_f)$.大家可以参考下<a href="http://blog.echen.me/2017/05/30/exploring-lstms/">英文博客</a>,<a href="https://www.jiqizhixin.com/articles/2017-07-24-2">中文博客</a></p>
</blockquote>
<p>接下来这一步就是决定新信息中的哪些部分需要保存在单元状态中.这包括两个部分,第一部分是sigmoid层(input gate layer),决定更新的值.第二部分是一个tanh层,用来创建一个新的候选值.在下一步中,我们将会把这两个结合起来用来给单元状态做更新.在语言模型的例子中,这一步就代表我们将新对象的性别加入单元状态中,用来代替我们需要忘记的老对象性别.<br><img src="/Understanding-LSTM-Networks/LSTM3-focus-i.png" class=""><br>现在要把旧的单元状态$C_{t-1}$更新为$C_t$.上一步已经决定了更新的内容.我们把旧的单元状态乘以$f_t$,表示我们需要忘记的内容.然后将结果加上$i_t*\tilde{C_t}$,这表示将候选值进行缩放或者延伸.在语言模型的例子中,这表示我们从旧对象的性别中去除信息,然后加上新的信息.<br><img src="/Understanding-LSTM-Networks/LSTM3-focus-C.png" class=""><br>最终,我们需要决定输出的内容.输出内容基于单元状态,但是需要一些处理.首先,我们使用一个sigmoid层来决定单元状态的哪部分需要输出.然后,我们将单元状态经过tanh(将值限定在-1到1之间),在乘以sigmoid gate的输出.所以我们仅仅输出了我们决定的.<br>对于语言模型例子,因为网络之前看到了主语,所以接下来它可能想要输出的信息是关于动词的.例如,网络会根据主语的单数或复数来决定接下来动词的形式.<br><img src="/Understanding-LSTM-Networks/LSTM3-focus-o.png" class=""></p>
<h1 id="长短期记忆模型的其他形式-Variants-on-Long-Short-Term-Memory"><a href="#长短期记忆模型的其他形式-Variants-on-Long-Short-Term-Memory" class="headerlink" title="长短期记忆模型的其他形式(Variants on Long Short Term Memory)"></a>长短期记忆模型的其他形式(Variants on Long Short Term Memory)</h1><p>上面提到的是LSTM的一般形式.但是还有好多LSTM的一些变形,虽然变化不大.其中一个流行的LSTM变形是由<a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf">Gers &amp; Schmidhuber (2000)</a>提出.此模型添加了”peephole connections”,这意味着让门看到了单元状态.<br><img src="/Understanding-LSTM-Networks/LSTM3-var-peepholes.png" class=""><br>从图中可以看到模型对于所有的gate都添加了peepholes,但是有很多文章只添加了一些peepholes,而另一些则没有.</p>
<p>LSTM另一种变形是将input gate和forget gate进行耦合.这种网络不会单独的决定哪些内容需要忘记,哪些新的信息需要添加,而是一起做这些决定.当我们将要输入内容时,我们仅仅忘记;当我们忘记旧的内容时,我们仅仅输入一些新的值.模型的结构如下<br><img src="/Understanding-LSTM-Networks/LSTM3-var-tied.png" class=""></p>
<p>一种引入注意的LSTM变形是GRU(Gated Recurrent Unit),它将forget gate和input gate结合为一个单独的”update gate”.它同样融合了单元状态和隐藏状态以及一些其他的改变.GRU模型要比标准的LSTM模型简单,并且越来越流行.<br><img src="/Understanding-LSTM-Networks/LSTM3-var-GRU.png" class=""><br>这里仅仅列举了一些LSTM变形,还有很多其他的LSTM变形.比如Depth Gated RNNs by <a href="http://arxiv.org/pdf/1508.03790v2.pdf">Yao, et al. (2015)</a>.同时在解决长期依赖问题上,也有跟LSTM完全不同的方法,比如Clockwork RNNs by <a href="http://arxiv.org/pdf/1402.3511v1.pdf">Koutnik, et al. (2014)</a>.<br><a href="http://arxiv.org/pdf/1503.04069.pdf">Greff, et al. (2015)</a>对这些变形做了一个对比.<a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">Jozefowicz, et al. (2015)</a>测试很多的RNN结构,发现在一些特定的任务上比LSTM模型表现的更好的模型.</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">colah博客</a><br><a href="http://blog.echen.me/2017/05/30/exploring-lstms/">echen博客</a></p>
<blockquote>
<p>echen博客中公式介绍的较为详细</p>
</blockquote>
]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo搭建github博客多设备更新</title>
    <url>/hexo%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2%E5%A4%9A%E8%AE%BE%E5%A4%87%E6%9B%B4%E6%96%B0.html</url>
    <content><![CDATA[<p><strong>hexo分支上保存了原始博客文件(相关md文件)，master分支上是博客展示的内容(相关html)</strong></p>
<p>前段时间由于电脑重新安装了系统,导致自己的博客文件丢失,而github上面的只有发布后的文件,没有博客的源文件。想要恢复到源文件至今还没有找到解决方法,好在原来的博客内容不多,丢失了也无所谓了。但是以后要是换电脑了,这种问题怎么解决呢?今天介绍一个解决方案。<br>其实方法很简单,首先应该有两个分支,一个分支用来保存发布后的内容,一个分支用来保存源文件.这里用master分支保存发布后的内容,hexo分支保存源文件内容.</p>
<h2 id="第一步"><a href="#第一步" class="headerlink" title="第一步"></a>第一步</h2><p>设备A上搭建github博客</p>
<h2 id="第二步"><a href="#第二步" class="headerlink" title="第二步"></a>第二步</h2><p>在博客根目录下,打开_config.yml,添加如下内容</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">git@github.com:youname/youname.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以看到现在已经有一个master分支,但是这时候个人博客还不是一个git目录</p>
</blockquote>
<p>提交代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">// hexo编译源文件，生成静态文件，也可以分开执行</span><br><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>
<blockquote>
<p>hexo clean: 清空博客缓存<br>hexo g(hexo generator 的简写):生成静态文件<br>hexo d(hexo deploy的简写): 部署文件,这条命令会使用第一步中的配置信息进行部署</p>
</blockquote>
<p>现在打开yourname.github.io就能够看到你的博客了</p>
<h2 id="第三步"><a href="#第三步" class="headerlink" title="第三步"></a>第三步</h2><p>因为我用的是next主题(其他主题做相似处理).删除next文件下的.git文件夹,这是因为我们在要我们的博客下创建.git,如果子目录下也有.git,会有问题.然后执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">// git初始化</span><br><span class="line">git init</span><br><span class="line">// 新建分支并切换到新建的分支</span><br><span class="line">git checkout -b 分支名</span><br><span class="line">// 添加所有本地文件到git</span><br><span class="line">git add .</span><br><span class="line">// git提交</span><br><span class="line">git commit -m <span class="string">&quot;提交说明&quot;</span></span><br><span class="line">// 文件推送到hexo分支</span><br><span class="line">git push origin hexo</span><br></pre></td></tr></table></figure>
<blockquote>
<p>以后操作都是在hexo分支中,当我们修改了我们的博客内容时,先执行hexo clean &amp;&amp; hexo g &amp;&amp; hexo d ,这个命令用来将本地博客发布到github上<br>然后在将本地内容提交到hexo分支中</p>
</blockquote>
<h2 id="第四步"><a href="#第四步" class="headerlink" title="第四步"></a>第四步</h2><p>假设我们需要在电脑B上搭建我们之前的博客内容.我们需要拉取我们的hexo分支,因为hexo分支是源文件,master可以不用拉取</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">// 克隆分支到本地</span><br><span class="line">git <span class="built_in">clone</span> -b hexo https://github.com/用户名/仓库名.git</span><br><span class="line">// 进入博客文件夹</span><br><span class="line"><span class="built_in">cd</span> youname.github.io</span><br><span class="line">// 安装依赖</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>
<h2 id="第五步"><a href="#第五步" class="headerlink" title="第五步"></a>第五步</h2><p>电脑B上编辑博客内容,静态文件提交到master分支,源文件提交到hexo分支</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">//博文提交到master上面。</span><br><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</span><br><span class="line">//源文件提交到hexo分支上面。</span><br><span class="line">// 添加源文件</span><br><span class="line">git add .</span><br><span class="line">// git提交</span><br><span class="line">git commit -m <span class="string">&quot;&quot;</span></span><br><span class="line">// 先拉原来Github分支上的源文件到本地，进行合并</span><br><span class="line">git pull origin hexo</span><br><span class="line">// 比较解决前后版本冲突后，push源文件到Github的分支</span><br><span class="line">git push origin hexo</span><br></pre></td></tr></table></figure>
<h2 id="第六步"><a href="#第六步" class="headerlink" title="第六步"></a>第六步</h2><p>在电脑A上可以同步hexo分支,开始更新博客</p>
<p><strong>注意: 以后操作都是在hexo分支中,当我们修改了我们的博客内容时,先执行hexo clean &amp;&amp; hexo g &amp;&amp; hexo d ,这个命令用来将本地博客发布到github上<br>然后在将本地内容提交到hexo分支中</strong></p>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>docker安装sshd以及修改镜像源和软件源</title>
    <url>/docker%E5%AE%89%E8%A3%85sshd%E4%BB%A5%E5%8F%8A%E4%BF%AE%E6%94%B9%E9%95%9C%E5%83%8F%E6%BA%90%E5%92%8C%E8%BD%AF%E4%BB%B6%E6%BA%90.html</url>
    <content><![CDATA[<h1 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h1><p>因为最近公司需要在容器中跑深度学习任务，所以需要tensorflow的镜像。并且要求在要通过ssh进行容器的通信。这篇文章主要介绍如何在docker容器中安装软件，如何修改docker镜像源以及修改容器内部软件源地址。<br>宿主机环境：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">uname</span> -r : 3.10.0-862.11.6.el7.x86_64</span><br><span class="line"><span class="built_in">cat</span> /etc/redhat-release : CentOS Linux release 7.5.1804 (Core)</span><br><span class="line">docker version : 18.06.0-ce</span><br></pre></td></tr></table></figure>
<p>镜像主要选择的是官方的tensorflow:1.12.0-py3版本,镜像里面使用的系统环境下面会介绍</p>
<h2 id="修改docker镜像源"><a href="#修改docker镜像源" class="headerlink" title="修改docker镜像源"></a>修改docker镜像源</h2><p><a href="https://www.docker-cn.com/registry-mirror">!参考</a><br>由于docker 官方的镜像源在国外，导致下载速度很慢。所以第一步是修改docker镜像源地址。我这里采用永久修改docker镜像源地址。打开<code>/etc/docker/daemon.json</code>（如果没有此文件，则新建）,添加如下内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;registry-mirrors&quot;:</span> [<span class="string">&quot;https://registry.docker-cn.com&quot;</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后运行<code>docker pull registry.docker-cn.com/tensorflow/tensorflow:1.12.0-py3</code><br>即可以拉取镜像，而且可以看到速度提升很快</p>
<h2 id="启动镜像"><a href="#启动镜像" class="headerlink" title="启动镜像"></a>启动镜像</h2><p>我们可以使用<code>docker images</code>查看本机有的镜像。针对上面拉取的tensorflow:1.12.0-py3镜像，我们执行下面命令启动</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -it [image_name] /bin/bash</span><br></pre></td></tr></table></figure>
<p>此时我们应该是在启动的容器中。我们可以查看容器具体的系统信息。因为tensorflow基础镜像是ubuntu，所以这里运行以下命令,因为容器中一般不会有vim命令，所以采用cat命令参看系统信息。注意下面的命令都是在容器中键入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">uname</span> -r</span><br><span class="line"><span class="built_in">cat</span> /etc/issue</span><br></pre></td></tr></table></figure>
<p>查看得到系统信息为:Ubuntu 16.04.5 LTS</p>
<h2 id="修改容器中软件源地址"><a href="#修改容器中软件源地址" class="headerlink" title="修改容器中软件源地址"></a>修改容器中软件源地址</h2><p>由于容器中软件源默认地址是国外的，这里换成国内的。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/apt</span><br><span class="line"><span class="built_in">cp</span> sources.list sources.list.bak</span><br></pre></td></tr></table></figure>
<p>这里使用阿里的镜像源，将sources.list里面的内容修改为如下内容:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释</span></span><br><span class="line"><span class="string">deb</span> <span class="string">http://mirrors.aliyun.com/ubuntu/</span> <span class="string">xenial</span> <span class="string">main</span> <span class="string">restricted</span> <span class="string">universe</span> <span class="string">multiverse</span></span><br><span class="line"><span class="comment"># deb-src http://mirrors.aliyun.com/ubuntu/ xenial main main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb</span> <span class="string">http://mirrors.aliyun.com/ubuntu/</span> <span class="string">xenial-updates</span> <span class="string">main</span> <span class="string">restricted</span> <span class="string">universe</span> <span class="string">multiverse</span></span><br><span class="line"><span class="comment"># deb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb</span> <span class="string">http://mirrors.aliyun.com/ubuntu/</span> <span class="string">xenial-backports</span> <span class="string">main</span> <span class="string">restricted</span> <span class="string">universe</span> <span class="string">multiverse</span></span><br><span class="line"><span class="comment"># deb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb</span> <span class="string">http://mirrors.aliyun.com/ubuntu/</span> <span class="string">xenial-security</span> <span class="string">main</span> <span class="string">restricted</span> <span class="string">universe</span> <span class="string">multiverse</span></span><br><span class="line"><span class="comment"># deb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted universe multiverse</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预发布软件源，不建议启用</span></span><br><span class="line"><span class="comment"># deb http://mirrors.aliyun.com/ubuntu/ xenial-proposed main restricted universe multiverse</span></span><br><span class="line"><span class="comment"># deb-src http://mirrors.aliyun.com/ubuntu/ xenial-proposed main restricted universe multiverse</span></span><br></pre></td></tr></table></figure>
<h2 id="容器中安装软件"><a href="#容器中安装软件" class="headerlink" title="容器中安装软件"></a>容器中安装软件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">passwd</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install vim</span><br><span class="line">apt-get install openssh-sshd</span><br></pre></td></tr></table></figure>
<p>修改root密码以及安装完上面vim和openssh-sshd两个软件后，修改openssh-sshd配置文件内容。打开<code>/etc/ssh/sshd_config</code>将<code>PermitRootLogin</code>后面添加yes，即允许以root用户登录。后面启动sshd命令可能会报错，具体问题可以自己上网上搜索</p>
<h2 id="生成镜像"><a href="#生成镜像" class="headerlink" title="生成镜像"></a>生成镜像</h2><p>退出镜像，将容器提交为镜像</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker commit [containerID] [image_name]</span><br></pre></td></tr></table></figure>
<p>执行<code>docker images</code>可以看到生成的镜像。启动此镜像并开启sshd服务命令如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d  -p 50001:22 [images_name] /usr/sbin/sshd -D</span><br><span class="line">其中 -d表示已后台方式启动容器，-p挂载端口 ，/usr/sbin/sshd -D 是启动命令</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>镜像源</tag>
        <tag>软件源</tag>
      </tags>
  </entry>
  <entry>
    <title>docker与tensorflow结合使用</title>
    <url>/docker%E4%B8%8Etensorflow%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8.html</url>
    <content><![CDATA[<p>最近这段时间一直在学习docker的使用,以及如何在docker中使用tensorflow.今天就把在docker中如何使用tensorflow记录一下.</p>
<h1 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker安装</h1><p>我是把docker安装在centos 7.4操作系统上面,在vmware中装的centos,vmware中安装centos很简单.具体的网络配置可以参考<a href="https://segmentfault.com/a/1190000008743806">vmware nat配置</a>.docker安装很简单,找到docker官网,直接按照上面的步骤安装即可.运行<code>docker version</code>查看版本如下</p>
<img src="/docker%E4%B8%8Etensorflow%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8/docker-version.png" class="">
<p>因为docker 采用的是客户端/服务端的结构,所以这里可以看到client以及server,它们分别都有版本号.</p>
<h1 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h1><p>在docker中运行tensorflow的第一步就是要找到自己需要的镜像,我们可以去<a href="https://hub.docker.com">docker hub</a>找到自己需要的tensorflow镜像.tensorflow的镜像主要分两类,一种是在CPU上面跑的,还有一种是在GPU上面跑的,如果需要GPU的,那么还需要安装<strong>nvidia-docker</strong>.这里我使用的是CPU版本的.当然我们还需要选择具体的tensorflow版本.这里我拉取的命令如下:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull tensorflow/tensorflow:1.9.0-devel-py3</span><br></pre></td></tr></table></figure>
<p>拉取成功之后,运行<code>docker images</code>可以看到有tensorflow镜像.</p>
<h1 id="tensorflow在docker中使用"><a href="#tensorflow在docker中使用" class="headerlink" title="tensorflow在docker中使用"></a>tensorflow在docker中使用</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -it -p 8888:8888 --name tf-1.9 tensorflow/tensorflow:1.9.0-devel-py3</span><br></pre></td></tr></table></figure>
<p>运行上面的命令,在容器中启动镜像.<code>-p</code>表示指定端口映射,即将本机的8888端口映射到容器的8888端口.<code>--name</code>用来指定容器的名字为<code>tf-1.9</code>.因为这里采用的镜像是devel模式的,所以默认不启动jupyter.如果想使用默认启动jupyter的镜像,那么直接拉取不带devel的镜像就可以.即拉取最近的镜像<code>docker pull tensorflow/tensorflow</code><br>启动之后,我们就进入了容器,<code>ls /</code> 查看容器根目录内容,可以看到有<code>run_jupyter.sh</code>文件.运行此文件,即在根目录下执行<code>./run_jupyter.sh --allow-root</code>,<code>--allow-root</code>参数是因为jupyter启动不推荐使用root,这里是主动允许使用root.然后在浏览器中就可以访问jupyter的内容了.<br><img src="/docker%E4%B8%8Etensorflow%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8/jupyter.png" class=""></p>
<h1 id="创建自己的镜像"><a href="#创建自己的镜像" class="headerlink" title="创建自己的镜像"></a>创建自己的镜像</h1><p>上面仅仅是跑了一个什么都没有的镜像,如果我们需要在镜像里面跑我们的深度学习程序怎么办呢?这首先做的第一步就是要制作我们自己的镜像.这里我们跑一个简单的mnist数据集,程序可以直接去tensorflow上面找一个例子程序.这里我的程序如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;Simple, end-to-end, LeNet-5-like convolutional MNIST model example.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">This should achieve a test error of 0.7%. Please keep this model as simple and</span></span><br><span class="line"><span class="string">linear as possible, it is meant as a tutorial for simple convolutional models.</span></span><br><span class="line"><span class="string">Run with --self_test on the command line to execute a short self-test.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> xrange  <span class="comment"># pylint: disable=redefined-builtin</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># CVDF mirror of http://yann.lecun.com/exdb/mnist/</span></span><br><span class="line"><span class="comment"># 如果WORK_DIRECTORY中没有需要的数据,则从此地址下载数据</span></span><br><span class="line">SOURCE_URL = <span class="string">&#x27;https://storage.googleapis.com/cvdf-datasets/mnist/&#x27;</span></span><br><span class="line"><span class="comment"># 训练数据位置</span></span><br><span class="line"><span class="comment"># WORK_DIRECTORY = &#x27;data&#x27;</span></span><br><span class="line">WORK_DIRECTORY = <span class="string">&#x27;./MNIST-data&#x27;</span></span><br><span class="line">IMAGE_SIZE = <span class="number">28</span></span><br><span class="line">NUM_CHANNELS = <span class="number">1</span></span><br><span class="line">PIXEL_DEPTH = <span class="number">255</span></span><br><span class="line">NUM_LABELS = <span class="number">10</span></span><br><span class="line">VALIDATION_SIZE = <span class="number">5000</span>  <span class="comment"># Size of the validation set.</span></span><br><span class="line">SEED = <span class="number">66478</span>  <span class="comment"># Set to None for random seed.</span></span><br><span class="line">BATCH_SIZE = <span class="number">64</span></span><br><span class="line">NUM_EPOCHS = <span class="number">10</span></span><br><span class="line">EVAL_BATCH_SIZE = <span class="number">64</span></span><br><span class="line">EVAL_FREQUENCY = <span class="number">100</span>  <span class="comment"># Number of steps between evaluations.</span></span><br><span class="line"></span><br><span class="line">FLAGS = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印信息设置</span></span><br><span class="line"><span class="comment"># logging.basicConfig(format=&#x27;%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s&#x27;,</span></span><br><span class="line"><span class="comment">#                     level=logging.DEBUG)</span></span><br><span class="line">logging.basicConfig(level=logging.DEBUG,  <span class="comment"># 控制台打印的日志级别</span></span><br><span class="line">                    filename=<span class="string">&#x27;cnn_mnist.log&#x27;</span>,</span><br><span class="line">                    filemode=<span class="string">&#x27;a&#x27;</span>,  <span class="comment"># 模式，有w和a，w就是写模式，每次都会重新写日志，覆盖之前的日志</span></span><br><span class="line">                    <span class="comment"># a是追加模式，默认如果不写的话，就是追加模式</span></span><br><span class="line">                    <span class="built_in">format</span>=</span><br><span class="line">                    <span class="string">&#x27;%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s&#x27;</span></span><br><span class="line">                    <span class="comment"># 日志格式</span></span><br><span class="line">                    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_type</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return the type of the activations, weights, and placeholder variables.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> FLAGS.use_fp16:</span><br><span class="line">        <span class="keyword">return</span> tf.float16</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> tf.float32</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">maybe_download</span>(<span class="params">filename</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Download the data from Yann&#x27;s website, unless it&#x27;s already here.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> tf.gfile.Exists(WORK_DIRECTORY):</span><br><span class="line">        tf.gfile.MakeDirs(WORK_DIRECTORY)</span><br><span class="line">    filepath = os.path.join(WORK_DIRECTORY, filename)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> tf.gfile.Exists(filepath):</span><br><span class="line">        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)</span><br><span class="line">        <span class="keyword">with</span> tf.gfile.GFile(filepath) <span class="keyword">as</span> f:</span><br><span class="line">            size = f.size()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Successfully downloaded&#x27;</span>, filename, size, <span class="string">&#x27;bytes.&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> filepath</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_data</span>(<span class="params">filename, num_images</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Extract the images into a 4D tensor [image index, y, x, channels].</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Values are rescaled from [0, 255] down to [-0.5, 0.5].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    logging.info(<span class="string">&#x27;Extracting&#x27;</span> + filename)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Extracting&#x27;</span>, filename)</span><br><span class="line">    <span class="keyword">with</span> gzip.<span class="built_in">open</span>(filename) <span class="keyword">as</span> bytestream:</span><br><span class="line">        bytestream.read(<span class="number">16</span>)</span><br><span class="line">        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)</span><br><span class="line">        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)</span><br><span class="line">        data = (data - (PIXEL_DEPTH / <span class="number">2.0</span>)) / PIXEL_DEPTH</span><br><span class="line">        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_labels</span>(<span class="params">filename, num_images</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Extract the labels into a vector of int64 label IDs.&quot;&quot;&quot;</span></span><br><span class="line">    logging.info(<span class="string">&#x27;Extracting&#x27;</span> + filename)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Extracting&#x27;</span>, filename)</span><br><span class="line">    <span class="keyword">with</span> gzip.<span class="built_in">open</span>(filename) <span class="keyword">as</span> bytestream:</span><br><span class="line">        bytestream.read(<span class="number">8</span>)</span><br><span class="line">        buf = bytestream.read(<span class="number">1</span> * num_images)</span><br><span class="line">        labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)</span><br><span class="line">    <span class="keyword">return</span> labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fake_data</span>(<span class="params">num_images</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Generate a fake dataset that matches the dimensions of MNIST.&quot;&quot;&quot;</span></span><br><span class="line">    data = numpy.ndarray(</span><br><span class="line">        shape=(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS),</span><br><span class="line">        dtype=numpy.float32)</span><br><span class="line">    labels = numpy.zeros(shape=(num_images,), dtype=numpy.int64)</span><br><span class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> xrange(num_images):</span><br><span class="line">        label = image % <span class="number">2</span></span><br><span class="line">        data[image, :, :, <span class="number">0</span>] = label - <span class="number">0.5</span></span><br><span class="line">        labels[image] = label</span><br><span class="line">    <span class="keyword">return</span> data, labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">error_rate</span>(<span class="params">predictions, labels</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return the error rate based on dense predictions and sparse labels.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">100.0</span> - (</span><br><span class="line">            <span class="number">100.0</span> *</span><br><span class="line">            numpy.<span class="built_in">sum</span>(numpy.argmax(predictions, <span class="number">1</span>) == labels) /</span><br><span class="line">            predictions.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">_</span>):</span><br><span class="line">    <span class="keyword">if</span> FLAGS.self_test:</span><br><span class="line">        logging.info(<span class="string">&#x27;Running self-test.&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Running self-test.&#x27;</span>)</span><br><span class="line">        train_data, train_labels = fake_data(<span class="number">256</span>)</span><br><span class="line">        validation_data, validation_labels = fake_data(EVAL_BATCH_SIZE)</span><br><span class="line">        test_data, test_labels = fake_data(EVAL_BATCH_SIZE)</span><br><span class="line">        num_epochs = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Get the data.</span></span><br><span class="line">        train_data_filename = maybe_download(<span class="string">&#x27;train-images-idx3-ubyte.gz&#x27;</span>)</span><br><span class="line">        train_labels_filename = maybe_download(<span class="string">&#x27;train-labels-idx1-ubyte.gz&#x27;</span>)</span><br><span class="line">        test_data_filename = maybe_download(<span class="string">&#x27;t10k-images-idx3-ubyte.gz&#x27;</span>)</span><br><span class="line">        test_labels_filename = maybe_download(<span class="string">&#x27;t10k-labels-idx1-ubyte.gz&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Extract it into numpy arrays.</span></span><br><span class="line">        train_data = extract_data(train_data_filename, <span class="number">60000</span>)</span><br><span class="line">        train_labels = extract_labels(train_labels_filename, <span class="number">60000</span>)</span><br><span class="line">        test_data = extract_data(test_data_filename, <span class="number">10000</span>)</span><br><span class="line">        test_labels = extract_labels(test_labels_filename, <span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Generate a validation set.</span></span><br><span class="line">        validation_data = train_data[:VALIDATION_SIZE, ...]</span><br><span class="line">        validation_labels = train_labels[:VALIDATION_SIZE]</span><br><span class="line">        train_data = train_data[VALIDATION_SIZE:, ...]</span><br><span class="line">        train_labels = train_labels[VALIDATION_SIZE:]</span><br><span class="line">        num_epochs = NUM_EPOCHS</span><br><span class="line">    train_size = train_labels.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># This is where training samples and labels are fed to the graph.</span></span><br><span class="line">    <span class="comment"># These placeholder nodes will be fed a batch of training data at each</span></span><br><span class="line">    <span class="comment"># training step using the &#123;feed_dict&#125; argument to the Run() call below.</span></span><br><span class="line">    train_data_node = tf.placeholder(</span><br><span class="line">        data_type(),</span><br><span class="line">        shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))</span><br><span class="line">    train_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))</span><br><span class="line">    eval_data = tf.placeholder(</span><br><span class="line">        data_type(),</span><br><span class="line">        shape=(EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The variables below hold all the trainable weights. They are passed an</span></span><br><span class="line">    <span class="comment"># initial value which will be assigned when we call:</span></span><br><span class="line">    <span class="comment"># &#123;tf.global_variables_initializer().run()&#125;</span></span><br><span class="line">    conv1_weights = tf.Variable(</span><br><span class="line">        tf.truncated_normal([<span class="number">5</span>, <span class="number">5</span>, NUM_CHANNELS, <span class="number">32</span>],  <span class="comment"># 5x5 filter, depth 32.</span></span><br><span class="line">                            stddev=<span class="number">0.1</span>,</span><br><span class="line">                            seed=SEED, dtype=data_type()))</span><br><span class="line">    conv1_biases = tf.Variable(tf.zeros([<span class="number">32</span>], dtype=data_type()))</span><br><span class="line">    conv2_weights = tf.Variable(tf.truncated_normal(</span><br><span class="line">        [<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>], stddev=<span class="number">0.1</span>,</span><br><span class="line">        seed=SEED, dtype=data_type()))</span><br><span class="line">    conv2_biases = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[<span class="number">64</span>], dtype=data_type()))</span><br><span class="line">    fc1_weights = tf.Variable(  <span class="comment"># fully connected, depth 512.</span></span><br><span class="line">        tf.truncated_normal([IMAGE_SIZE // <span class="number">4</span> * IMAGE_SIZE // <span class="number">4</span> * <span class="number">64</span>, <span class="number">512</span>],</span><br><span class="line">                            stddev=<span class="number">0.1</span>,</span><br><span class="line">                            seed=SEED,</span><br><span class="line">                            dtype=data_type()))</span><br><span class="line">    fc1_biases = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[<span class="number">512</span>], dtype=data_type()))</span><br><span class="line">    fc2_weights = tf.Variable(tf.truncated_normal([<span class="number">512</span>, NUM_LABELS],</span><br><span class="line">                                                  stddev=<span class="number">0.1</span>,</span><br><span class="line">                                                  seed=SEED,</span><br><span class="line">                                                  dtype=data_type()))</span><br><span class="line">    fc2_biases = tf.Variable(tf.constant(</span><br><span class="line">        <span class="number">0.1</span>, shape=[NUM_LABELS], dtype=data_type()))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># We will replicate the model structure for the training subgraph, as well</span></span><br><span class="line">    <span class="comment"># as the evaluation subgraphs, while sharing the trainable parameters.</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">model</span>(<span class="params">data, train=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;The Model definition.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 2D convolution, with &#x27;SAME&#x27; padding (i.e. the output feature map has</span></span><br><span class="line">        <span class="comment"># the same size as the input). Note that &#123;strides&#125; is a 4D array whose</span></span><br><span class="line">        <span class="comment"># shape matches the data layout: [image index, y, x, depth].</span></span><br><span class="line">        conv = tf.nn.conv2d(data,</span><br><span class="line">                            conv1_weights,</span><br><span class="line">                            strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                            padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">        <span class="comment"># Bias and rectified linear non-linearity.</span></span><br><span class="line">        relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))</span><br><span class="line">        <span class="comment"># Max pooling. The kernel size spec &#123;ksize&#125; also follows the layout of</span></span><br><span class="line">        <span class="comment"># the data. Here we have a pooling window of 2, and a stride of 2.</span></span><br><span class="line">        pool = tf.nn.max_pool(relu,</span><br><span class="line">                              ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                              strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                              padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">        conv = tf.nn.conv2d(pool,</span><br><span class="line">                            conv2_weights,</span><br><span class="line">                            strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                            padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">        relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))</span><br><span class="line">        pool = tf.nn.max_pool(relu,</span><br><span class="line">                              ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                              strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                              padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">        <span class="comment"># Reshape the feature map cuboid into a 2D matrix to feed it to the</span></span><br><span class="line">        <span class="comment"># fully connected layers.</span></span><br><span class="line">        pool_shape = pool.get_shape().as_list()</span><br><span class="line">        reshape = tf.reshape(</span><br><span class="line">            pool,</span><br><span class="line">            [pool_shape[<span class="number">0</span>], pool_shape[<span class="number">1</span>] * pool_shape[<span class="number">2</span>] * pool_shape[<span class="number">3</span>]])</span><br><span class="line">        <span class="comment"># Fully connected layer. Note that the &#x27;+&#x27; operation automatically</span></span><br><span class="line">        <span class="comment"># broadcasts the biases.</span></span><br><span class="line">        hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)</span><br><span class="line">        <span class="comment"># Add a 50% dropout during training only. Dropout also scales</span></span><br><span class="line">        <span class="comment"># activations such that no rescaling is needed at evaluation time.</span></span><br><span class="line">        <span class="keyword">if</span> train:</span><br><span class="line">            hidden = tf.nn.dropout(hidden, <span class="number">0.5</span>, seed=SEED)</span><br><span class="line">        <span class="keyword">return</span> tf.matmul(hidden, fc2_weights) + fc2_biases</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Training computation: logits + cross-entropy loss.</span></span><br><span class="line">    logits = model(train_data_node, <span class="literal">True</span>)</span><br><span class="line">    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">        labels=train_labels_node, logits=logits))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># L2 regularization for the fully connected parameters.</span></span><br><span class="line">    regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +</span><br><span class="line">                    tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))</span><br><span class="line">    <span class="comment"># Add the regularization term to the loss.</span></span><br><span class="line">    loss += <span class="number">5e-4</span> * regularizers</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Optimizer: set up a variable that&#x27;s incremented once per batch and</span></span><br><span class="line">    <span class="comment"># controls the learning rate decay.</span></span><br><span class="line">    batch = tf.Variable(<span class="number">0</span>, dtype=data_type())</span><br><span class="line">    <span class="comment"># Decay once per epoch, using an exponential schedule starting at 0.01.</span></span><br><span class="line">    learning_rate = tf.train.exponential_decay(</span><br><span class="line">        <span class="number">0.01</span>,  <span class="comment"># Base learning rate.</span></span><br><span class="line">        batch * BATCH_SIZE,  <span class="comment"># Current index into the dataset.</span></span><br><span class="line">        train_size,  <span class="comment"># Decay step.</span></span><br><span class="line">        <span class="number">0.95</span>,  <span class="comment"># Decay rate.</span></span><br><span class="line">        staircase=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># Use simple momentum for the optimization.</span></span><br><span class="line">    optimizer = tf.train.MomentumOptimizer(learning_rate,</span><br><span class="line">                                           <span class="number">0.9</span>).minimize(loss,</span><br><span class="line">                                                         global_step=batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Predictions for the current training minibatch.</span></span><br><span class="line">    train_prediction = tf.nn.softmax(logits)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Predictions for the test and validation, which we&#x27;ll compute less often.</span></span><br><span class="line">    eval_prediction = tf.nn.softmax(model(eval_data))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Small utility function to evaluate a dataset by feeding batches of data to</span></span><br><span class="line">    <span class="comment"># &#123;eval_data&#125; and pulling the results from &#123;eval_predictions&#125;.</span></span><br><span class="line">    <span class="comment"># Saves memory and enables this to run on smaller GPUs.</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">eval_in_batches</span>(<span class="params">data, sess</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get all predictions for a dataset by running it in small batches.&quot;&quot;&quot;</span></span><br><span class="line">        size = data.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> size &lt; EVAL_BATCH_SIZE:</span><br><span class="line">            logging.error(<span class="string">&quot;batch size for evals larger than dataset: %d&quot;</span> % size)</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;batch size for evals larger than dataset: %d&quot;</span> % size)</span><br><span class="line">        predictions = numpy.ndarray(shape=(size, NUM_LABELS), dtype=numpy.float32)</span><br><span class="line">        <span class="keyword">for</span> begin <span class="keyword">in</span> xrange(<span class="number">0</span>, size, EVAL_BATCH_SIZE):</span><br><span class="line">            end = begin + EVAL_BATCH_SIZE</span><br><span class="line">            <span class="keyword">if</span> end &lt;= size:</span><br><span class="line">                predictions[begin:end, :] = sess.run(</span><br><span class="line">                    eval_prediction,</span><br><span class="line">                    feed_dict=&#123;eval_data: data[begin:end, ...]&#125;)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                batch_predictions = sess.run(</span><br><span class="line">                    eval_prediction,</span><br><span class="line">                    feed_dict=&#123;eval_data: data[-EVAL_BATCH_SIZE:, ...]&#125;)</span><br><span class="line">                predictions[begin:, :] = batch_predictions[begin - size:, :]</span><br><span class="line">        <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a local session to run the training.</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment"># Run all the initializers to prepare the trainable parameters.</span></span><br><span class="line">        tf.global_variables_initializer().run()</span><br><span class="line">        logging.info(<span class="string">&#x27;Initialized!&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Initialized!&#x27;</span>)</span><br><span class="line">        <span class="comment"># Loop through training steps.</span></span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> xrange(<span class="built_in">int</span>(num_epochs * train_size) // BATCH_SIZE):</span><br><span class="line">            <span class="comment"># Compute the offset of the current minibatch in the data.</span></span><br><span class="line">            <span class="comment"># Note that we could use better randomization across epochs.</span></span><br><span class="line">            offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)</span><br><span class="line">            batch_data = train_data[offset:(offset + BATCH_SIZE), ...]</span><br><span class="line">            batch_labels = train_labels[offset:(offset + BATCH_SIZE)]</span><br><span class="line">            <span class="comment"># This dictionary maps the batch data (as a numpy array) to the</span></span><br><span class="line">            <span class="comment"># node in the graph it should be fed to.</span></span><br><span class="line">            feed_dict = &#123;train_data_node: batch_data,</span><br><span class="line">                         train_labels_node: batch_labels&#125;</span><br><span class="line">            <span class="comment"># Run the optimizer to update weights.</span></span><br><span class="line">            sess.run(optimizer, feed_dict=feed_dict)</span><br><span class="line">            <span class="comment"># print some extra information once reach the evaluation frequency</span></span><br><span class="line">            <span class="keyword">if</span> step % EVAL_FREQUENCY == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># fetch some extra nodes&#x27; data</span></span><br><span class="line">                l, lr, predictions = sess.run([loss, learning_rate, train_prediction],</span><br><span class="line">                                              feed_dict=feed_dict)</span><br><span class="line">                elapsed_time = time.time() - start_time</span><br><span class="line">                start_time = time.time()</span><br><span class="line">                logging.info(<span class="string">&#x27;Step %d (epoch %.2f), %.1f ms&#x27;</span> %(step, <span class="built_in">float</span>(step) * BATCH_SIZE / train_size, <span class="number">1000</span> * elapsed_time / EVAL_FREQUENCY))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Step %d (epoch %.2f), %.1f ms&#x27;</span> %</span><br><span class="line">                      (step, <span class="built_in">float</span>(step) * BATCH_SIZE / train_size,</span><br><span class="line">                       <span class="number">1000</span> * elapsed_time / EVAL_FREQUENCY))</span><br><span class="line">                logging.info(<span class="string">&#x27;Minibatch loss: %.3f, learning rate: %.6f&#x27;</span> % (l, lr))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Minibatch loss: %.3f, learning rate: %.6f&#x27;</span> % (l, lr))</span><br><span class="line">                logging.info(<span class="string">&#x27;Minibatch error: %.1f%%&#x27;</span> % error_rate(predictions, batch_labels))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Minibatch error: %.1f%%&#x27;</span> % error_rate(predictions, batch_labels))</span><br><span class="line">                logging.info(<span class="string">&#x27;Validation error: %.1f%%&#x27;</span> % error_rate(eval_in_batches(validation_data, sess), validation_labels))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Validation error: %.1f%%&#x27;</span> % error_rate(</span><br><span class="line">                    eval_in_batches(validation_data, sess), validation_labels))</span><br><span class="line">                sys.stdout.flush()</span><br><span class="line">        <span class="comment"># Finally print the result!</span></span><br><span class="line">        test_error = error_rate(eval_in_batches(test_data, sess), test_labels)</span><br><span class="line">        logging.info(<span class="string">&#x27;Test error: %.1f%%&#x27;</span> % test_error)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test error: %.1f%%&#x27;</span> % test_error)</span><br><span class="line">        <span class="keyword">if</span> FLAGS.self_test:</span><br><span class="line">            logging.info(<span class="string">&#x27;test_error&#x27;</span> + test_error)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;test_error&#x27;</span>, test_error)</span><br><span class="line">            <span class="keyword">assert</span> test_error == <span class="number">0.0</span>, <span class="string">&#x27;expected 0.0 test_error, got %.2f&#x27;</span> % (</span><br><span class="line">                test_error,)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;--use_fp16&#x27;</span>,</span><br><span class="line">        default=<span class="literal">False</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&#x27;Use half floats instead of full floats if True.&#x27;</span>,</span><br><span class="line">        action=<span class="string">&#x27;store_true&#x27;</span>)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;--self_test&#x27;</span>,</span><br><span class="line">        default=<span class="literal">False</span>,</span><br><span class="line">        action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&#x27;True if running a self test.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    FLAGS, unparsed = parser.parse_known_args()</span><br><span class="line">    tf.app.run(main=main, argv=[sys.argv[<span class="number">0</span>]] + unparsed)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这里我在原来的程序基础上面稍微改了下,因为我已经提前将数据下载好了,所以我让程序直接读取本机指定目录下的训练数据,同时增加了日志文件输出.这是为了在公司的容器云平台上测试获取容器输出文件</p>
<h2 id="编写Dockerfile"><a href="#编写Dockerfile" class="headerlink" title="编写Dockerfile"></a>编写Dockerfile</h2><p>我们可以在我们的用户目录下,创建一个空的文件夹,将mnist数据集以及程序文件都拷贝进这个文件夹下.其实数据集应该是放在数据卷中,但是这里为了方便,我直接将训练数据打进了镜像中.然后创建Dockerfile,文件内容如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM tensorflow/tensorflow:1.9.0-devel-py3</span><br><span class="line"></span><br><span class="line">COPY . /home/ll</span><br><span class="line">WORKDIR /home/ll</span><br><span class="line">CMD [<span class="string">&#x27;python&#x27;</span>, <span class="string">&#x27;convolutional.py&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>即Dockerfile文件中最后一行表示容器启动的运行的命令</p>
<h2 id="build镜像"><a href="#build镜像" class="headerlink" title="build镜像"></a>build镜像</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build -t tf:1.9 .</span><br></pre></td></tr></table></figure>
<p><code>-t</code>参数指定镜像跟tag,最后的<code>.</code>指定了镜像中的上下文.构建完之后使用<code>docker images</code>可以查看多了<code>tf:1.9</code>镜像</p>
<h2 id="运行镜像"><a href="#运行镜像" class="headerlink" title="运行镜像"></a>运行镜像</h2><p>运行下面的命令,运行上一步构建好的镜像</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -it --name <span class="built_in">test</span> tf:1.9</span><br></pre></td></tr></table></figure>
<p>然后就能够看到训练的输出.<br><img src="/docker%E4%B8%8Etensorflow%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8/tensorflow.png" class=""><br>同时可以在看一个连接,进入容器,即运行下面命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it <span class="built_in">test</span> /bin/bash</span><br></pre></td></tr></table></figure>
<p>可以看到如下内容<br><img src="/docker%E4%B8%8Etensorflow%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8/container.png" class=""><br>即看到了cnn_mnist.log的日志输出文件</p>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>effective java third edition notes</title>
    <url>/effective-java-third-edition-notes.html</url>
    <content><![CDATA[<h1 id="effective-java-third-edition-notes"><a href="#effective-java-third-edition-notes" class="headerlink" title="effective java third edition notes"></a>effective java third edition notes</h1><p>记录阅读《effective java》得一些收获</p>
<h2 id="第二章-创建和销毁对象"><a href="#第二章-创建和销毁对象" class="headerlink" title="第二章 创建和销毁对象"></a>第二章 创建和销毁对象</h2>]]></content>
  </entry>
  <entry>
    <title>docker常用命令</title>
    <url>/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html</url>
    <content><![CDATA[<h1 id="docker命令"><a href="#docker命令" class="headerlink" title="docker命令"></a>docker命令</h1><h2 id="docker基本命令"><a href="#docker基本命令" class="headerlink" title="docker基本命令"></a>docker基本命令</h2><h3 id="查看docker版本"><a href="#查看docker版本" class="headerlink" title="查看docker版本"></a>查看docker版本</h3><p><code>docker version</code></p>
<h3 id="查看docker信息"><a href="#查看docker信息" class="headerlink" title="查看docker信息"></a>查看docker信息</h3><p><code>docker info</code></p>
<h3 id="启动docker-服务"><a href="#启动docker-服务" class="headerlink" title="启动docker 服务"></a>启动docker 服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo service docker start</span><br><span class="line">或者</span><br><span class="line">sudo systemctl start docker</span><br></pre></td></tr></table></figure>
<h2 id="镜像命令"><a href="#镜像命令" class="headerlink" title="镜像命令"></a>镜像命令</h2><h3 id="列出本机的所有image文件"><a href="#列出本机的所有image文件" class="headerlink" title="列出本机的所有image文件"></a>列出本机的所有image文件</h3><p><code>docker image ls</code></p>
<h3 id="删除image文件"><a href="#删除image文件" class="headerlink" title="删除image文件"></a>删除image文件</h3><p><code>docker image rm [imageName]</code></p>
<h3 id="拉取image文件"><a href="#拉取image文件" class="headerlink" title="拉取image文件"></a>拉取image文件</h3><p><code>docker image pull library/hello-world</code><br>library/hello-world是 image 文件在仓库里面的位置，其中library是 image 文件所在的组，hello-world是 image 文件的名字.因为Docker官方提供的镜像都在library中,所以可以省略library,即使用下面的命令<br><code>docker image pull hello-world</code></p>
<h3 id="运行image-文件"><a href="#运行image-文件" class="headerlink" title="运行image 文件"></a>运行image 文件</h3><p><code>docker container run hello-world</code><br>run命令每运行一次,就会新建一个容器.docker container run命令具有自动抓取 image 文件的功能。如果发现本地没有指定的 image 文件，就会从仓库自动抓取。因此，前面的docker image pull命令并不是必需的步骤.<br><code>-v</code>参数: 用来进行数据卷的挂载,将本机主机的目录挂载到容器的某一目录</p>
<h2 id="容器命令"><a href="#容器命令" class="headerlink" title="容器命令"></a>容器命令</h2><h3 id="终止容器"><a href="#终止容器" class="headerlink" title="终止容器"></a>终止容器</h3><p><code>docker container kill [containID]</code></p>
<blockquote>
<p>image 文件生成的容器实例，本身也是一个文件，称为容器文件。也就是说，一旦容器生成，就会同时存在两个文件： image 文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已。</p>
</blockquote>
<h3 id="列出本机正在运行的容器"><a href="#列出本机正在运行的容器" class="headerlink" title="列出本机正在运行的容器"></a>列出本机正在运行的容器</h3><p><code>docker container ls</code></p>
<h3 id="列出本机所有容器，包括终止运行的容器"><a href="#列出本机所有容器，包括终止运行的容器" class="headerlink" title="列出本机所有容器，包括终止运行的容器"></a>列出本机所有容器，包括终止运行的容器</h3><p><code>docker container ls --all</code></p>
<h3 id="删除容器文件"><a href="#删除容器文件" class="headerlink" title="删除容器文件"></a>删除容器文件</h3><p><code>docker container rm [containerID]</code>或<br><code>docker rm [containerID]</code><br>注: 删除正在运行的容器,需要添加<code>-f</code>参数;<code>-v</code>参数可以删除没有用的数据卷</p>
<h3 id="查看容器信息"><a href="#查看容器信息" class="headerlink" title="查看容器信息"></a>查看容器信息</h3><p><code>docker ps</code></p>
<h3 id="重启容器"><a href="#重启容器" class="headerlink" title="重启容器"></a>重启容器</h3><p>restart命令会将运行的容器终止,然后在重新启动<br><code>docker container restart [containerID 或 name]</code></p>
<h3 id="导出容器"><a href="#导出容器" class="headerlink" title="导出容器"></a>导出容器</h3><p>导出容器快照到本地文件<br><code>docker export [containerID]</code><br>示例:<br><code>docker export 7691a814370e &gt; ubuntu.tar</code></p>
<h3 id="创建image-文件"><a href="#创建image-文件" class="headerlink" title="创建image 文件"></a>创建image 文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker image build -t koa-demo .</span><br><span class="line">或者</span><br><span class="line">docker image build -t koa-demo:0.0.1 .</span><br></pre></td></tr></table></figure>
<p><strong>-t</strong> 用来指定image 文件的名字,后面可以用冒号指定标签.如果不指定,默认的标签就是<strong>latest</strong>. 最后的点表示Dockerfile文件所在的路径,一个点表示当前路径</p>
<h3 id="从image文件生成容器"><a href="#从image文件生成容器" class="headerlink" title="从image文件生成容器"></a>从image文件生成容器</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker container run -p 8000:3000 -it koa-demo /bin/bash</span><br><span class="line">或者</span><br><span class="line">docker container run -p 8000:3000 -it koa-demo:0.0.1 /bin/bash</span><br></pre></td></tr></table></figure>
<p>参数含义:</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">-p参数:</span> <span class="string">容器的3000端口映射到本机的8000端口.</span></span><br><span class="line"><span class="string">-it参数:</span> <span class="string">容器的Shell映射到当前的Shell,然后你在本机窗口输入的命令,就会传入容器.</span></span><br><span class="line"><span class="attr">koa-demo:0.0.1:</span> <span class="string">image文件的名字,默认标签是latest.</span></span><br><span class="line"><span class="string">/bin/bash:</span> <span class="string">容器启动以后,内部第一个执行的命令.这里启动Bash,保证用户可以使用Shell</span></span><br></pre></td></tr></table></figure>
<p><code>docker container run --rm -p 8000:3000 -it koa-demo /bin/bash</code><br>—rm参数:在容器终止运行后自动删除容器文件</p>
<h2 id="其他有用的命令"><a href="#其他有用的命令" class="headerlink" title="其他有用的命令"></a>其他有用的命令</h2><h3 id="docker-container-start"><a href="#docker-container-start" class="headerlink" title="docker container start"></a>docker container start</h3><p>前面的docker container run命令是新建容器，每运行一次，就会新建一个容器。同样的命令运行两次，就会生成两个一模一样的容器文件。如果希望重复使用容器，就要使用docker container start命令，它用来启动已经生成、已经停止运行的容器文件。<br><code>docker container start [containerID]</code></p>
<h3 id="docker-container-stop"><a href="#docker-container-stop" class="headerlink" title="docker container stop"></a>docker container stop</h3><p>前面的docker container kill命令终止容器运行，相当于向容器里面的主进程发出 SIGKILL 信号。而docker container stop命令也是用来终止容器运行，相当于向容器里面的主进程发出 SIGTERM 信号，然后过一段时间再发出 SIGKILL 信号.<br><code>docker container stop [containerID]</code><br>这两个信号的差别是，应用程序收到 SIGTERM 信号以后，可以自行进行收尾清理工作，但也可以不理会这个信号。如果收到 SIGKILL 信号，就会强行立即终止，那些正在进行中的操作会全部丢失。</p>
<h3 id="docker-container-logs"><a href="#docker-container-logs" class="headerlink" title="docker container logs"></a>docker container logs</h3><p>docker container logs命令用来查看 docker 容器的输出，即容器里面 Shell 的标准输出。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令查看输出。<br><code>docker container logs [containerID]</code></p>
<h3 id="docker-container-exec"><a href="#docker-container-exec" class="headerlink" title="docker container exec"></a>docker container exec</h3><p>docker container exec命令用于进入一个正在运行的 docker 容器。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令进入容器。一旦进入了容器，就可以在容器的 Shell 执行命令了。<br><code>docker container exec -it [containerID] /bin/bash</code></p>
<h3 id="docker-container-cp"><a href="#docker-container-cp" class="headerlink" title="docker container cp"></a>docker container cp</h3><p>docker container cp命令用于从正在运行的 Docker 容器里面，将文件拷贝到本机。下面是拷贝到当前目录的写法。<br><code>docker container cp [containID]:[/path/to/file] .</code></p>
<h3 id="删除所有不运行的容器"><a href="#删除所有不运行的容器" class="headerlink" title="删除所有不运行的容器"></a>删除所有不运行的容器</h3><p><code>docker rm $(docker ps -a -q)</code></p>
<p>参考文章:<a href="http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html">Docker 入门教程-阮一峰</a></p>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>java synchronized keyword</title>
    <url>/java-synchronized-keyword.html</url>
    <content><![CDATA[<h1 id="java-synchronized关键字"><a href="#java-synchronized关键字" class="headerlink" title="java synchronized关键字"></a>java synchronized关键字</h1><p>在平常进行java并发程序的开发过程中，synchronized关键字的出现频率很高。但是synchronized底层是如何实现的，synchronized都有哪些具体的用法。本篇将会在下面进行详细讲解。<br>synchronized关键字主要是用来进行同步操作。synchronized关键字修饰的内容，每次都只能有一个线程进入，如果其他线程想要进入相同的代码块，那么必须等前一个线程释放代码块对应的锁，其他的线程才能进入此代码块。但是同一个线程能够多次进入一个相同的同步块，也就是synchronized具有可重入锁的特性。<br>总的来说，在java中，主要在三个地方使用synchronized关键字</p>
<ol>
<li>类的实例方法</li>
<li>类的静态方法</li>
<li>修饰部分代码块</li>
</ol>
<h2 id="synchronized用在实例方法上"><a href="#synchronized用在实例方法上" class="headerlink" title="synchronized用在实例方法上"></a>synchronized用在实例方法上</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClassInstance</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> count;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> value)</span>&#123;</span><br><span class="line">      <span class="built_in">this</span>.count += value;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上面的代码中展示了，synchronized应用在实例方法的方式。当synchronized用在实例方法上时，每当线程进入此方法时，会尝试获取对应的类实例上的锁(注意是类实例)。如果没有其他的线程持有此实例上的锁，那么线程会获取此实例锁，然后运行此方法。<br>下面的图显示了使用javap进行反编译后的内容(运行：<code>javap -v MyClassInstance.class</code>)：<br><img src="/java-synchronized-keyword/MyClassInstance.png" class="" title="java-memory-model"><br>图中仅仅展示了add方法反编译后的内容，可以看到在方法的flags标记中出现了ACC_SYNCHRONIZED。这个就是表明前面方法是用synchronized关键字修饰的。这个跟同步代码块的反编译结果是不同的。但是在线程执行同步操作时，都是要获取对应对象上的锁。</p>
<h2 id="synchronized用在类的静态方法上"><a href="#synchronized用在类的静态方法上" class="headerlink" title="synchronized用在类的静态方法上"></a>synchronized用在类的静态方法上</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClassStatic</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> value)</span> &#123;</span><br><span class="line">        System.out.print(value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面代码展示了如何在静态方法上使用synchronized关键字。当线程尝试进入类的静态方法时，会尝试获取类上的锁(注意是类上的锁，跟类实例上的锁不同的东西)。如果没有其他线程持有此类上的锁，那么当前线程会获取此类上的锁，然后运行此方法。<br>下面展示了反编译的结果(运行命令:<code>javap -v MyClassStatic.class</code>)<br><img src="/java-synchronized-keyword/MyClassStatic.png" class="" title="java-memory-model"><br>可以从反编译的结果中看到在方法的flags中也是包含了ACC_SYNCHRONIZED.</p>
<h2 id="synchronized用在代码块上"><a href="#synchronized用在代码块上" class="headerlink" title="synchronized用在代码块上"></a>synchronized用在代码块上</h2><p>如果synchronized关键字用在代码块上，会在其之后括号中的对象获取锁。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">log</span><span class="params">(String msg)</span> &#123;</span><br><span class="line">        <span class="keyword">synchronized</span>(<span class="built_in">this</span>) &#123;</span><br><span class="line">            System.out.println(msg);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">func</span><span class="params">(String msg)</span> &#123;</span><br><span class="line">        <span class="keyword">synchronized</span>(MyClass.class) &#123;</span><br><span class="line">            System.out.print(msg);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>在上面的代码中，在方法log中，当线程进入log方法，然后执行synchronized关键字修饰的代码块。线程会尝试获取当前类实例上的锁，因为括号中使用的是this关键字。而在func方法中，线程会尝试获取MyClass类的锁。注意这两个锁是不同的。所以一个线程可以执行log中的同步代码块，而同时另一个线程也可以执行func中的同步代码块。<br>反编译结果如下(运行命令:<code>javap -v MyClass.class</code>):<br><img src="/java-synchronized-keyword/MyClass1.png" class="" title="java-memory-model"><br>可以看到在方法的签名中是没有ACC_SYNCHRONIZED的。但是在代码中出现了monitorenter和monitorexit。<br><strong>monitorenter</strong>：</p>
<blockquote>
<p>Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows:<br>• If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.<br>• If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count.<br>• If another thread already owns the monitor associated with objectref, the thread blocks until the monitor’s entry count is zero, then tries again to gain ownership.</p>
</blockquote>
<p>引用中的内容来自JVM规范。这段话的大概意思为：<br>每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：</p>
<ol>
<li>如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。</li>
<li>如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.</li>
<li>如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。</li>
</ol>
<p><strong>monitorexit</strong>:</p>
<blockquote>
<p>The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref.<br>The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero, the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so.</p>
</blockquote>
<p>这段话的大概意思为：<br>执行monitorexit的线程必须是objectref所对应的monitor的所有者。<br>指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个 monitor 的所有权。<br>通过这两段描述，我们应该能很清楚的看出Synchronized的实现原理，Synchronized的语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。<br>一个monitorenter都会对应有一个monitorexit。但是我们从反编译的结果中，可以看到多出了一个monitorexit，即第18行。因为在synchronized中的代码遇到异常时，会释放锁。第一个 monitorexit 指令如果正确执行，会走到下面的 goto 指令，直接跳转到 21 行 return，而如果发生异常，下面的 astore_3 和 aload_2 指令会继续执行异常问题，下一步会继续执行 monitorexit 指令退出同步。</p>
<p>当然，有时候，我们也可以这样用synchronized关键字修饰代码块<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyClass2</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Object</span> <span class="variable">obj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">Object</span> <span class="variable">obj2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">log</span><span class="params">(String msg)</span> &#123;</span><br><span class="line">        <span class="keyword">synchronized</span>(obj) &#123;</span><br><span class="line">            System.out.print(msg);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">func</span><span class="params">(String msg)</span> &#123;</span><br><span class="line">        <span class="keyword">synchronized</span>(obj2) &#123;</span><br><span class="line">            System.out.print(msg);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>在上面的代码中，log方法中的同步块是对obj实例进行加锁，注意每个MyClass2实例中的obj都是不同的。而func中的同步块是对obj2静态成员进行加锁。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>java-zero-copy</title>
    <url>/java-zero-copy.html</url>
    <content><![CDATA[<blockquote>
<p>本篇内容主要翻译自<a href="https://developer.ibm.com/articles/j-zerocopy/">Efficient data transfer through zero copy</a>，包括有些自己的思考</p>
</blockquote>
<h1 id="java-zero-copy"><a href="#java-zero-copy" class="headerlink" title="java zero copy"></a>java zero copy</h1><p>很多网页应用有大量的静态内容，针对这些静态内容主要的处理逻辑就是从磁盘读取数据，然后将数据写入到响应的socket中。这项工作应该需要较少的CPU资源。但是有时候并不是。内核从磁盘读取数据，然后将数据拷贝到应用中。之后应用将数据写入到内核，然后推送到socket中。实际上，应用程序在这里扮演了一个无效率的中间层，既将数据从磁盘写入到socket。<br>每一次当数据扩容user-kernel边界时，数据都会被拷贝，而这会消耗cpu cycles以及内存带宽。幸运的是，我们可以采用zero copy技术来避免内核和应用程序之间的数据拷贝。应用程序使用zero copy技术来请求内核直接将数据从磁盘文件拷贝到socket中，而不需要经过应用程序。zero copy技术能够极大的提升应用程序性能并且减少内核空间和用户空间之间的切换。<br>Java中使用<code>java.nio.channels.FileChannel</code>中的<code>transferTo()</code>方法在linux和Unix系统重实现zero copy。使用<code>transferTo()</code>方法能够直接将字节数据从一个channel写入到另一个channel中，而数据不需要经过应用程序。本篇文章首先展示使用传统的拷贝方法消耗的资源，然后展示使用zero copy获得的性能提升。</p>
<h2 id="数据传输-传统方法"><a href="#数据传输-传统方法" class="headerlink" title="数据传输:传统方法"></a>数据传输:传统方法</h2><p>想想一个简单的场景，从一个文件读取数据，然后将数据通过网络写入到另一个程序中。核心操作如下所示。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">File.read(fileDesc, buf, len);</span><br><span class="line">Socket.send(socket, buf, len);</span><br></pre></td></tr></table></figure><br>虽然看起来很简单，但是这个操作需要再内核空间和用户空间4次上下文切换，以及4次数据拷贝。下图展示了具体过程<br><img src="/java-zero-copy/figure1.gif" class="" title="传统的数据拷贝过程"><br>下图展示了上下文切换过程<br><img src="/java-zero-copy/figure2.gif" class="" title="上下文切换"></p>
<p>主要的步骤如下：</p>
<ol>
<li><code>read()</code>方法从user mode 转换到 kernel mode。在read内部是发一起了一次系统调用<code>sys_read()</code>从文件读取数据。第一次数据拷贝是由DMA引擎来执行，DMA从磁盘读取文件，然后将数据保存到内核缓冲区中。</li>
<li>请求的数据被从内核缓冲区拷贝到用户缓冲区，<code>read()</code>方法返回。这引起了第二次的上下文切换。现在数据是在用户空间中的缓冲区中。</li>
<li><code>send()</code>方法调用引起用户空间到内核空间的切换。这次会将数据从用户空间拷贝到内核缓冲区。这一次数据是放置到另外一个内核缓冲区中，与目的socket相关联。</li>
<li><code>send()</code>方法返回，又引起了一次上下文切换。DMA将数据从内核缓冲区拷贝到网卡缓冲区中，这是第四次数据拷贝。</li>
</ol>
<p>我们为什么不直接讲数据拷贝到用户空间，而要经过内核空间呢？这是因为操作系统引入内核缓冲区是为了提升性能。操作系统读取数据都会预读取一些数据，这样在应用程序读取额外的数据时，可以不用发起系统调用，直接从内核缓冲区获取即可。而写入过程，可以完全实现为异步过程。既应用程序只需要将数据写入到内核缓冲区中，而不是写入到磁盘中。<br>但是，设想当前应用程序需要处理的数据要远远大于内核空间缓冲区的大小。而此时，数据需要在磁盘，内核缓冲区，用户空间中来回拷贝。这会严重影响性能。<br>Zero copy技术是解决这个问题的方法。</p>
<h2 id="数据传输：zero-copy方法"><a href="#数据传输：zero-copy方法" class="headerlink" title="数据传输：zero copy方法"></a>数据传输：zero copy方法</h2><p>如果你仔细检查上面的过程，你会发现第二次和第三次数据拷贝可以省略。应用程序针对这些数据什么也不做。因此数据可以被直接从内核缓冲区拷贝到socket buffer中。<code>transferTo()</code>方法可以完成这个操作。下面展示了此方法<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">transferTo</span><span class="params">(<span class="type">long</span> position, <span class="type">long</span> count, WritableByteChannel target)</span>;</span><br></pre></td></tr></table></figure><br><code>transferTo()</code>方法将数据从文件channel拷贝到target channel中。这个方法依赖底层操作系统对于zero copy的支持。在UNIX或linux中，使用的是<code>sendfile()</code>系统调用。如下所示：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">sendfile</span><span class="params">(<span class="type">int</span> out_fd, <span class="type">int</span> in_fd, <span class="type">off_t</span> *offset, <span class="type">size_t</span> count)</span>;</span><br></pre></td></tr></table></figure><br>下图展示了<code>transferTo()</code>方法执行过程<br><img src="/java-zero-copy/figure3.gif" class="" title="transferTo过程"></p>
<p>下图展示了具体的上下文切换<br><img src="/java-zero-copy/figure4.gif" class="" title="上下文切换"></p>
<p><code>transferTo()</code>方法执行过程如下：</p>
<ol>
<li>DMA引擎将文件内容拷贝到内核缓冲区。然后数据从内核缓冲区拷贝到socket buffer中。(涉及到两次数据拷贝)</li>
<li>第三次数据拷贝发生在DMA引擎将数据从socket buffer拷贝到网卡中。</li>
</ol>
<p>我们将上下文切换从4次降低到2次，数据拷贝从4次降低到3次(其中仅有一个数据拷贝需要CPU参与)。但是这还没有达到zero copy的目的。如果底层网卡支持gather操作，那么我们可以减少内核空间中的数据重复。在linux kernel2.4及以后版本中，socket buffer已经支持了这个操作。这个方法不仅仅减少了上下文切换并且也消除了CPU参与的数据拷贝。具体如下：</p>
<ol>
<li><code>transferTo()</code>方法将文件内容拷贝到内核缓冲区，由DMA引擎执行</li>
<li>不需要将数据拷贝进socket buffer中，仅仅将数据的位置以及数据长度添加到kernel buffer中。DMA引擎直接将kernel buffer中的数据拷贝到网卡中。<br>下图展示了包含gather操作的<code>transferTo()</code><img src="/java-zero-copy/figure5.gif" class="" title="gather操作的transferTo方法">
</li>
</ol>
<h2 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h2><p>使用java实现了文件传输，同时采用传统的IO和nio来实现。完整代码<a href="https://github.com/lightnine/j-zerocopy">参考</a>.其中客户端是主要的视线，服务端仅仅读取数据。</p>
<h3 id="传统IO-client-代码"><a href="#传统IO-client-代码" class="headerlink" title="传统IO client 代码"></a>传统IO client 代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1. create socket and connect to server</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            socket = <span class="keyword">new</span> <span class="title class_">Socket</span>(Common.SERVER, port);</span><br><span class="line">            System.out.println(<span class="string">&quot;Connected with server &quot;</span> + socket.getInetAddress() + <span class="string">&quot;:&quot;</span> + socket.getPort());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnknownHostException e) &#123;</span><br><span class="line">            System.out.println(e);</span><br><span class="line">            System.exit(Common.ERROR);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            System.out.println(e);</span><br><span class="line">            System.exit(Common.ERROR);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. send data to server</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            inputStream = Files.newInputStream(Paths.get(fileName));</span><br><span class="line">            output = <span class="keyword">new</span> <span class="title class_">DataOutputStream</span>(socket.getOutputStream());</span><br><span class="line">            <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            <span class="type">byte</span>[] b = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">4096</span>];</span><br><span class="line">            <span class="type">long</span> <span class="variable">read</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="type">long</span> <span class="variable">total</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="comment">// read function cause user mode to kernel mode,</span></span><br><span class="line">            <span class="comment">// and DMA engine read file content from disk to kernel buffer</span></span><br><span class="line">            <span class="comment">// then copy kernel buffer to the b array. This cause another context switch</span></span><br><span class="line">            <span class="comment">// then when read return, cause kernel mode to user mode</span></span><br><span class="line">            <span class="comment">// Summary: two context switch, two copy(one cpu copy)</span></span><br><span class="line">            <span class="keyword">while</span> ((read = inputStream.read(b)) &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                total = total + read;</span><br><span class="line">                System.out.println(<span class="string">&quot;total size:&quot;</span> + total);</span><br><span class="line">                <span class="comment">// write function cause user mode to kernel mode,</span></span><br><span class="line">                <span class="comment">// and copy data from b array to socket buffer,</span></span><br><span class="line">                <span class="comment">// then DMA engine copy socket buffer to nic(network interface) buffer</span></span><br><span class="line">                <span class="comment">// then when write return, cause kernel mode to user mode,</span></span><br><span class="line">                <span class="comment">// Summary: two context switch, two copy(one cpu copy)</span></span><br><span class="line">                output.write(b);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;bytes send: &quot;</span> + total + <span class="string">&quot; and totalTime(ms):&quot;</span> + (System.currentTimeMillis() - start));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            System.out.println(e);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<h3 id="nio-client-代码"><a href="#nio-client-代码" class="headerlink" title="nio client 代码"></a>nio client 代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testSendfile</span><span class="params">()</span> <span class="keyword">throws</span> IOException  &#123;</span><br><span class="line">        <span class="comment">// 1. get file size(bytes)</span></span><br><span class="line">        <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> Paths.get(fileName);</span><br><span class="line">        <span class="type">long</span> <span class="variable">fsize</span> <span class="operator">=</span> Files.size(path);</span><br><span class="line"></span><br><span class="line">        <span class="type">SocketAddress</span> <span class="variable">sad</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(Common.SERVER, port);</span><br><span class="line">        <span class="type">SocketChannel</span> <span class="variable">sc</span> <span class="operator">=</span> SocketChannel.open();</span><br><span class="line">        sc.connect(sad);</span><br><span class="line">        sc.configureBlocking(<span class="literal">true</span>);</span><br><span class="line">        <span class="type">FileInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileInputStream</span>(fileName);</span><br><span class="line">        <span class="type">FileChannel</span> <span class="variable">fc</span> <span class="operator">=</span> fis.getChannel();</span><br><span class="line">        <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">        <span class="type">long</span> <span class="variable">curnset</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// in linux kernel 2.4 and later</span></span><br><span class="line">        <span class="comment">// transferTo() function cause user mode to kernel mode</span></span><br><span class="line">        <span class="comment">// DMA engine copy data from disk to kernel buffer</span></span><br><span class="line">        <span class="comment">// then just copy data position and data length to kernel buffer</span></span><br><span class="line">        <span class="comment">// then DMA engine copy kernel buffer to NIC buffer</span></span><br><span class="line">        <span class="comment">// when transferTo return, cause another context switch</span></span><br><span class="line">        <span class="comment">// Summary: two context switch, two copy(zero CPU copy)</span></span><br><span class="line">        curnset = fc.transferTo(<span class="number">0</span>, fsize, sc);</span><br><span class="line">        System.out.println(<span class="string">&quot;total bytes transferred: &quot;</span> + curnset + <span class="string">&quot; and time taken in MS: &quot;</span> +</span><br><span class="line">                (System.currentTimeMillis() - start) );</span><br><span class="line"></span><br><span class="line">        fc.close();</span><br><span class="line">        fis.close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>性能比较如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>file size</th>
<th>traditional(ms)</th>
<th>nio(ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>12MB</td>
<td>50</td>
<td>18</td>
</tr>
<tr>
<td>221MB</td>
<td>690</td>
<td>314</td>
</tr>
<tr>
<td>2.5G</td>
<td>15496</td>
<td>2610</td>
</tr>
</tbody>
</table>
</div>
<p>评测环境：</p>
<ol>
<li>java : openjdk version “1.8.0_382”, OpenJDK Runtime Environment (build 1.8.0_382-b05), OpenJDK 64-Bit Server VM (build 25.382-b05, mixed mode)</li>
<li>linux: CentOS Linux release 7.6 (Final)</li>
<li>kernel: 4.14.0_1-0-0-51</li>
</ol>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>linux</tag>
        <tag>zero-copy</tag>
      </tags>
  </entry>
  <entry>
    <title>linux鸟哥私房菜收获</title>
    <url>/linux%E9%B8%9F%E5%93%A5%E7%A7%81%E6%88%BF%E8%8F%9C%E6%94%B6%E8%8E%B7.html</url>
    <content><![CDATA[<blockquote>
<p>最近半个月读完了《linux鸟哥私房菜》这本书，其实在研究生的时候这本书已经读过一遍，这次拿出来读，主要是巩固熟悉一下linux操作系统的相关概念。</p>
</blockquote>
<p>这本书整体来说对于初学者还是比较合适的。但是里面也有错误，同时书排版的方式有些地方有些问题，但是这些问题都不是很大。通过阅读这本书，对于linux的了解还是比较深度一些的。如果想要更深入的了解linux，可以看看《Unix &amp; Linux大学教程》这本书，这本书对于命令的介绍和使用会更加深入些。</p>
<h1 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h1><p>操作系统是硬件和在操作系统上面运行软件的一个中间层。当然这里面包括了很多的内容，包括如何管理硬盘，内存，CPU等等一系列内容。所以一个操作系统要包括以下内容：文件系统，内存管理，网络管理，进程线程管理等等。下面主要聊一聊读了《linux鸟哥私房菜》的一些获得内容。</p>
<h2 id="linux命令"><a href="#linux命令" class="headerlink" title="linux命令"></a>linux命令</h2><p>在linux中更常用的还是命令行命令，由于在我们平时的工作中，使用linux主要是作为服务器，而服务器基本上是不提供X Window的。所以掌握linux命令就变得很重要。在linux下面的命令，我们要学会使用帮助文档，即如下获取命令的详细使用说明，其实就是软件程序的使用说明。</p>
<h3 id="命令帮助"><a href="#命令帮助" class="headerlink" title="命令帮助"></a>命令帮助</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">man [<span class="built_in">command</span>]</span><br><span class="line">[<span class="built_in">command</span>] --<span class="built_in">help</span>(-h)</span><br></pre></td></tr></table></figure>
<p>man的输出内容主要包括以下内容：<br>NAME：简短的命令，数据名称说明<br>SYNOPSIS：简短的命令执行语法简介<br>DESCRIPTION：较为完整的说明<br>OPTIONS：针对SYNOPSIS部分，所有可用的选项说明<br>COMMANDS:当这个程序在执行的时候，可以在此程序中执行的命令<br>FILES：这个程序所使用或参考或连接到的某些文件<br>SEE ALSO：这个命令有相关的其他说明<br>EXAMPLE：一些可以参考的使用例子<br>BUGS：是否有错误</p>
<h3 id="命令分类"><a href="#命令分类" class="headerlink" title="命令分类"></a>命令分类</h3><p>因为在linux中命令太多了，我们不可能全部都记住的，但是一些常用的还是需要记忆一下的，这样至少我们在使用linux的时候可以能够操作。还有就是我们在使用命令的时候，可以稍微联想一下这个命令对应的英文单词，这样子能够帮助我们进行记忆。比如cd(change directory),mv(move),rm(remove)等等。而且linux下的很多命令在其他的软件中都有相同的意思。比如在docker操作中，<code>docker rm</code>也是代表的删除等意思。其实外国人这些简写都是根据相对应的单词而来。当然我这里仅仅列举了较少的一些命令，更多的命令大家还是多多使用linux进行探索吧。</p>
<h4 id="文件与目录相关管理命令"><a href="#文件与目录相关管理命令" class="headerlink" title="文件与目录相关管理命令"></a>文件与目录相关管理命令</h4><p>这部分命令主要是如何新建文件，目录；如何复制，移动文件；如何查看文件，目录等等。常用的命令如下，具体的使用规则可以使用帮助进行查看。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span>:切换目录；<span class="built_in">ls</span>:列出目录和文件；<span class="built_in">cp</span>:复制；</span><br><span class="line"><span class="built_in">rm</span>：删除；<span class="built_in">mv</span>：移动；<span class="built_in">touch</span>：创建文件；</span><br><span class="line"><span class="built_in">mkdir</span>：创建文件夹；<span class="built_in">cat</span>：查看文件内容；more：查看文件内容（每次输出一页）；</span><br><span class="line">less:查看文件内容（可以往前翻页）</span><br></pre></td></tr></table></figure>
<h4 id="磁盘和文件系统管理"><a href="#磁盘和文件系统管理" class="headerlink" title="磁盘和文件系统管理"></a>磁盘和文件系统管理</h4><p>对于文件系统，大家可以找本关于操作系统原理的书好好了解一下。了解常规的文件系统对于理解分布式文件系统会比较有帮助。文件系统在我们开发的过程中是很重要的，特别是现在容器话，集群化。在linux文件系统中mount(挂载点)的含义，日志系统如何记录文件的操作，inode等等。常用命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">df:查看磁盘整体的情况；</span><br><span class="line">du：查看某一个目录的容量情况；</span><br><span class="line">mount：挂载某一个文件系统；</span><br><span class="line">ln：创建连接文件（有点类似于windows的快捷方式，但是分为软连接和硬连接）</span><br></pre></td></tr></table></figure>
<h4 id="文件和文件系统的压缩和打包"><a href="#文件和文件系统的压缩和打包" class="headerlink" title="文件和文件系统的压缩和打包"></a>文件和文件系统的压缩和打包</h4><p>在平时我们linux的过程中，tar命令是一个经常出现的命令，掌握tar命令的使用很关键。因为tar命令不光能够打包文件，同时还能够解压文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar:打包文件；</span><br><span class="line">gzip:压缩文件；bzip2：压缩文件；</span><br><span class="line">dump：备份工具</span><br></pre></td></tr></table></figure>
<p>tar命令能够压缩文件是因为这个命令支持gzip和bzip2软件。对于tar命令我们要掌握以下常用的命令<br><strong>压缩</strong>：<code>tar -jcv -f filename.tar.bz2 被压缩的文件或目录名称</code><br><strong>查询</strong>：<code>tar -jtv -f filename.tar.bz2</code>,可以查看文件内的内容<br><strong>解压缩</strong>：<code>tar -jxv -f filename.tar.bz2 -C 被解压缩的目录</code></p>
<h4 id="其他常用命令"><a href="#其他常用命令" class="headerlink" title="其他常用命令"></a>其他常用命令</h4><p>其他常用的命令，比如管道和数据重定向等等，如果我们需要编写shell脚本，这些命令会非常有用。在linux中掌握shell脚本是很重要的，shell脚本能够帮助我们做一些自动化的事情，代替手工作业。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep:匹配文件；<span class="built_in">sort</span>：排序；</span><br><span class="line"><span class="built_in">wc</span>：计数，比如统计文件内行数；<span class="built_in">history</span>：查看历史命令</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在linux的学习中，更重要的还是要多用。关记忆这些命令是没有用的，在我们用linux的命令的过程中，仔细想想每个命令的用法，同时加深自己对于这些命令背后的原理以及linux系统本身的原理的理解，相信能够完全掌握linux的使用的</p>
</blockquote>
<h2 id="权限理解"><a href="#权限理解" class="headerlink" title="权限理解"></a>权限理解</h2><p>因为linux是支持多用户的，即多个人可以同时登陆一台linux系统上的。所以权限管理就变得非常重要。如果不考虑特殊权限的，文件和目录的权限主要分为三种，分别为可读(r)、可写(w)、可执行(x)，对应的数字分别为4,2,1。<br>对于文件，这三个权限比较好理解。那么对于目录呢？<br><strong>目录可读</strong>：你可以查询改目录下的文件名数据，即可以利用ls这个命令将目录下的内容列表显示出来。<br><strong>目录可写</strong>：表示你具有更改该目录结构列表的权限，即在该目录下新建文件和目录；删除已经存在的文件与目录（不论文件的权限如何）；将已经存在的文件或目录进行重命名；转移该目录内的文件，目录位置。<br><strong>目录可执行</strong>：目录的x代表用户能否进入该目录成为工作目录的用途。能不能进入某个目录只与该目录的x权限有关。同时如果没有某个目录的x权限，是无法执行该目录下的任何命令。</p>
<p>常用命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span>:改变文件权限；<span class="built_in">chown</span>：改变文件所有者；<span class="built_in">chgrp</span>：改变文件所属用户组</span><br></pre></td></tr></table></figure>
<h2 id="linux常用目录介绍"><a href="#linux常用目录介绍" class="headerlink" title="linux常用目录介绍"></a>linux常用目录介绍</h2><p>在linux中，目录的用途是有具体的规范的，即FHS标准。这个规范的目的就是系统让用户可以了解已安装软件通常放置与哪个目录下。大家在平时的使用过程中最好是遵循这些规范。<br>FHS主要定义了三层目录，分别如下：<br><strong>/(root,根目录)</strong>:与开机系统有关<br><strong>/usr(UNIX software resource)</strong>:与软件安装/执行有关，可以看到usr是UNIX软件资源的缩写<br><strong>/var(variable)</strong>:与系统运作过程有关</p>
<h3 id="根目录分类"><a href="#根目录分类" class="headerlink" title="根目录分类"></a>根目录分类</h3><p>根目录一般情况下会有这些目录，目录的含义如下：<br><strong>/bin</strong>:主要放置在单用户维护模式下还能使用的命令，可以被root和一般用户使用，主要由cat，chmod，chown，date，mv，mkdir，cp，bash等<br><strong>/boot</strong>:开机会用到的文件，包括内核文件和开机的配置文件<br><strong>/dev</strong>:因为linux中所有的内容都是文件，而任何设备和接口设备都是以文件的形式存在于这个目录中。<br><strong>/etc</strong>:系统主要的配置文件。例如用户的账户密码，各种服务的起始文件等。<br><strong>/home</strong>:系统默认的用户主文件夹<br><strong>/lib</strong>:开机时会用到的函数库，以及在/bin,/sbin下面的命令会调用的函数库。<br><strong>/media</strong>:可删除的设备，包括软盘，光盘，DVD等<br><strong>/mnt</strong>:如果暂时挂载某些额外的设备，一般建议放置在这个目录中<br><strong>/opt</strong>:给第三方软件放置的目录<br><strong>/root</strong>:系统管理员的主文件夹<br><strong>/sbin</strong>:主要是开机过程中需要的，包括开机、修复、还原系统所需要的命令<br><strong>/srv(service的缩写)</strong>:一些网络服务启动之后，这些网络服务需要取用数据的目录。如WWW服务需要的网页数据就可以放置在/srv/www中<br><strong>/tmp</strong>:放置临时文件的目录，重要一般不建议放在这个目录里，因为这个目录会定时清理<br><strong>/proc</strong>:这个目录下的数据都在内存中，如系统的内核，进程，外部设备，网络状态等。</p>
<h3 id="usr下目录"><a href="#usr下目录" class="headerlink" title="/usr下目录"></a>/usr下目录</h3><p><strong>/usr/bin/</strong>:绝大部分的用户可使用命令<br><strong>/usr/include/</strong>:C/C++等程序语言的头文件与包含文件放置处。<br><strong>/usr/lib/</strong>:包含应用软件的函数库、目标文件以及不被一般用户惯用的执行文件或脚本<br><strong>/usr/local/</strong>:系统管理员在本机自行安装自己下载的软件，一般安装在这个目录下<br><strong>/usr/sbin/</strong>:非系统正常运行所需要的系统命令<br><strong>/usr/share/</strong>:放置共享文件的地方<br><strong>/usr/src/</strong>:一般源码放置在这个目录下，而内核源码一般放在/usr/src/linux下</p>
<h3 id="var-下目录"><a href="#var-下目录" class="headerlink" title="/var 下目录"></a>/var 下目录</h3><p><strong>/var/cache/</strong>:应用程序本身运行过程中会产生的一些暂存文件<br><strong>/var/lib/</strong>:程序本身执行的过程中，需要使用到的数据文件放置的目录，比如Mysql数据库放置在/var/lib/mysql,rpm数据库主要放到/var/lib/rpm下<br><strong>/var/log/</strong>：登录文件放置的目录，如/var/log/wtmp（记录登录者的信息）<br><strong>/var/mail/</strong>:放置个人邮箱的目录</p>
<blockquote>
<p>你有时候看到的linux系统目录可能不仅仅包括这些或者不存在其中的某些目录，这是因为linux系统版本，同时这也是个规范，有些linux开发厂商会依据这些规范做些修改。所以不一样也没有关系。</p>
</blockquote>
<p>总结：因为linux系统包括的内容太多了，这里我仅仅提到了linux系统下的冰山一角。比如如何关机，系统的等级，如何在线安装软件，如何离线安装软件，如何创建用户和用户组，SELinux等等内容。大家都可以通过这本书学到。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>jupyter notebook使用</title>
    <url>/jupyter-notebook%E4%BD%BF%E7%94%A8.html</url>
    <content><![CDATA[<h1 id="jupyter-notebook"><a href="#jupyter-notebook" class="headerlink" title="jupyter notebook"></a>jupyter notebook</h1><p>Jupyter notebook, 前身是 IPython notebook, 它是一个非常灵活的工具，有助于帮助你构建很多可读的分析，你可以在里面同时保留代码，图片，评论，公式和绘制的图像。<br>这篇文章主要是记录下jupyter notebook使用过程中一些常用的内容和技巧，包括一些magic使用</p>
<h2 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h2><p>windows上，<strong>Ctrl + Shift + P</strong>可以调出快捷键的帮助信息，所有的快捷键都能够看到。掌握快捷键能够帮助我们更好的使用jupyter notebook</p>
<h2 id="Jupyter-Magic-Commands"><a href="#Jupyter-Magic-Commands" class="headerlink" title="Jupyter Magic Commands"></a>Jupyter Magic Commands</h2><ol>
<li>%matplotlib inline</li>
</ol>
<p>如果想在jupyter中画图，可以添加如下代码，则图像就能够进行显示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<p>2. Timing</p>
<p>对于计时有两个十分有用的魔法命令：%%time 和 %timeit. 如果你有些代码运行地十分缓慢，而你想确定是否问题出在这里，这两个命令将会非常方便。</p>
<p><strong>%%time</strong> 将会给出cell的代码运行一次所花费的时间。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%time</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    time.sleep(<span class="number">0.01</span>)<span class="comment"># sleep for 0.01 seconds</span></span><br></pre></td></tr></table></figure>
<p><strong>%timeit</strong> 使用Python的timeit模块，它将会执行一个语句100，000次(默认情况下)，然后给出运行最快3次的平均值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line">%timeit numpy.random.normal(size=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<h2 id="运行文件"><a href="#运行文件" class="headerlink" title="运行文件"></a>运行文件</h2>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>jupyter</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>python3学习</title>
    <url>/python3%E5%AD%A6%E4%B9%A0.html</url>
    <content><![CDATA[<h1 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h1><p>在python中,一个py文件就是一个模块.而为了避免模块名称冲突,Python又引入了按目录来组织模块的方法,成为Package.引入了包后,对应的模块名前面就添加了包名.类似于Java中的Package.</p>
<p>__init__.py:在包目录下,必须有__init__.py这个文件,如果没有这个文件,那么python会将此文件作为一个普通目录,而不在是一个package.__init__.py可以为空,也可以有代码(一般都是一些import语句).__init__.py本身是一个模块,其模块名为对应的package名称.</p>
<h1 id="Python示例程序"><a href="#Python示例程序" class="headerlink" title="Python示例程序"></a>Python示例程序</h1><figure class="highlight python"><figcaption><span>hello.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27; a test module &#x27;</span></span><br><span class="line"></span><br><span class="line">__author__ = <span class="string">&#x27;Michael Liao&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    args = sys.argv</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(args)==<span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Hello, world!&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">len</span>(args)==<span class="number">2</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Hello, %s!&#x27;</span> % args[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Too many arguments!&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    test()</span><br></pre></td></tr></table></figure>
<p>程序说明:程序开始的一,二行是标准注释.第一行注释说明这个文件可以直接在Unix/Linux/Max上运行.第二行表示文件本身使用utf-8编码.第四行是模块的文档注释,第六行是作者信息.<br><code>if __name__ == &#39;__main__&#39;:</code>:当我们在命令行运行模块时,python解释器会将一个特殊的变量<code>__name__</code>设置为<code>__main__</code>.但是如果在其他模块中导入此模块,python解释器并不是设置<code>__name__</code>变量.</p>
<h1 id="python中的作用域"><a href="#python中的作用域" class="headerlink" title="python中的作用域"></a>python中的作用域</h1><p>正常的变量或函数是公开的,可以直接引用如<code>abc</code>,<code>xyz</code>等.<br>类似<code>__xxx__</code>的变量时特殊变量,也可以直接引用,但是有特殊用途.如<code>__author__</code>,<code>__name__</code>.而模块的文档注释可以用<code>__doc__</code>来访问<br>类似于<code>_x</code>,<code>__x</code>这样定义的变量或函数是非公开的,类似Java的private.</p>
<h1 id="python模块搜索路径"><a href="#python模块搜索路径" class="headerlink" title="python模块搜索路径"></a>python模块搜索路径</h1><p>当我们引入模块时,即使用import导入模块时,python解释器从搜索路径中查找对应的模块.如果找不到,则会报错.<br>默认情况下,Python解释器会搜索当前目录、所有已安装的内置模块和第三方模块，搜索路径存放在sys模块的path变量中.下面代码可以查看搜索路径内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; import sys</span><br><span class="line">&gt;&gt;&gt; sys.path</span><br></pre></td></tr></table></figure>
<h2 id="修改搜索路径"><a href="#修改搜索路径" class="headerlink" title="修改搜索路径"></a>修改搜索路径</h2><p>可以使用两种方式修改搜索路径</p>
<ol>
<li>直接修改<code>sys.path</code> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; import sys</span><br><span class="line">&gt;&gt;&gt; sys.path.append(<span class="string">&#x27;待添加路径&#x27;</span>)</span><br></pre></td></tr></table></figure>
 但是这种方式只在程序运行时有效,程序运行结束后失效</li>
<li>设置<code>PATHONPATH</code><br> 直接将待添加的路径加入<code>PATHONPATH</code>环境变量中即可</li>
</ol>
<h1 id="类与对象"><a href="#类与对象" class="headerlink" title="类与对象"></a>类与对象</h1><p>在python类中,<code>__init__</code>方法就相当于Java中类的构造函数,<strong>self</strong>表示实例自身.<br>如果类中的变量定义前加了两个下划线,那么此变量就成为一个私有变量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, score</span>):</span><br><span class="line">        self.__name = name</span><br><span class="line">        self.score = score</span><br><span class="line">a = Student(<span class="string">&#x27;1&#x27;</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(a.__name)</span><br><span class="line"><span class="built_in">print</span>(a.score)</span><br></pre></td></tr></table></figure>
<p>打印<code>__name</code>时,将会报错,而可以打印score的内容.</p>
<h2 id="鸭子类型"><a href="#鸭子类型" class="headerlink" title="鸭子类型"></a>鸭子类型</h2><blockquote>
<p>注明:个人解决因为无法限制方法入参的类型,那么传递进去什么都可以</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Animal</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Animal is running...&#x27;</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_twice</span>(<span class="params">animal</span>):</span><br><span class="line">    animal.run()</span><br><span class="line">    animal.run()</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Timer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Start...&#x27;</span>)</span><br><span class="line">run_twice(Timer())</span><br></pre></td></tr></table></figure>
<p>在Java中,如果定义<code>run_twice</code>方法,必须定义函数的形参类型,如果指定了只能接受Animal类型,则只能传递Animal类型或其子类.但是在python不是这样,只要传递进的类型中存在<code>run</code>方法即可.不过python中不存在限制入参是什么类型.</p>
<blockquote>
<p>这就是动态语言的“鸭子类型”，它并不要求严格的继承体系，一个对象只要“看起来像鸭子，走起路来像鸭子”，那它就可以被看做是鸭子。</p>
</blockquote>
<h2 id="slots"><a href="#slots" class="headerlink" title="__slots__"></a><code>__slots__</code></h2><p>python是动态语言，可以在运行过程中给类实例以及类本身添加属性和方法。如果想要限制动态添加的属性，则可以在类中定义<code>__slots__</code>,如下代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    __slots__ = (<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;age&#x27;</span>) <span class="comment"># 运行绑定的属性限制为name和age</span></span><br></pre></td></tr></table></figure>
<h2 id="property"><a href="#property" class="headerlink" title="@property"></a><code>@property</code></h2><p><code>@property</code>是python内置装饰器,可以在给属性添加getter以及setter方法，从而简化代码。如下使用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._score</span><br><span class="line"></span><br><span class="line"><span class="meta">    @score.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self, value</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(value, <span class="built_in">int</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;score must be an integer!&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> value &lt; <span class="number">0</span> <span class="keyword">or</span> value &gt; <span class="number">100</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;score must between 0 ~ 100!&#x27;</span>)</span><br><span class="line">        self._score = value</span><br></pre></td></tr></table></figure>
<p>第一个score方法被<code>@property</code>修改,从而为score属性添加了getter方法,第二个score方法被<code>@score.setter</code>修饰,添加了setter方法.如果去掉第二个score,则score属性将没有setter方法.</p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>pip以及conda镜像源修改及命令使用</title>
    <url>/pip%E4%BB%A5%E5%8F%8Aconda%E9%95%9C%E5%83%8F%E6%BA%90%E4%BF%AE%E6%94%B9%E5%8F%8A%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8.html</url>
    <content><![CDATA[<h1 id="Python包的安装"><a href="#Python包的安装" class="headerlink" title="Python包的安装"></a>Python包的安装</h1><p>在国内环境下，因为网络原因，所以Python下很多包安装不了或者安装的速度很慢。这里主要介绍下如何修改conda以及pip对应的镜像源。</p>
<h2 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h2><p>pip主要是用来管理python包的工具，类似于Maven工具。</p>
<h3 id="临时修改pip安装源"><a href="#临时修改pip安装源" class="headerlink" title="临时修改pip安装源"></a>临时修改pip安装源</h3><p>比如我们要安装gevent包，我们可以输入一下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple gevent</span><br></pre></td></tr></table></figure>
<p>这样就会从清华这边的镜像去安装gevent库.其中<code>-i</code>参数指定了使用清华的pip源</p>
<p>有时候可能需要添加受信源，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install packagename -i http://pypi.douban.com/simple --trusted-host pypi.douban.com</span><br></pre></td></tr></table></figure>
<p>其中<code>--trusted-host</code> 参数是指设置为受信源，否则在安全性较高的连接下是连接不上的</p>
<h3 id="永久修改"><a href="#永久修改" class="headerlink" title="永久修改"></a>永久修改</h3><p>在用户根目录(~，而非系统根目录 / )下添加配置~/.pip/pip.conf目录添加可信源，如果目录文件不存在，可直接创建。写入如下内容：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">global</span>]</span><br><span class="line"><span class="string">index-url=http://pypi.douban.com/simple</span></span><br><span class="line"><span class="string">trusted-host</span> <span class="string">=</span> <span class="string">pypi.douban.com</span> </span><br></pre></td></tr></table></figure>
<p>这里添加的是豆瓣源，也可以添加清华源</p>
<h2 id="conda使用及源修改"><a href="#conda使用及源修改" class="headerlink" title="conda使用及源修改"></a>conda使用及源修改</h2><p>conda是Anaconda中用来安装python包的工具。在Anaconda中将镜像分为两类，一类是官方的python包，放在anaconda中；另一类是第三方的python包，放在conda-forge中。</p>
<p>采用conda 安装python包时，可以使用以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda install -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/linux-64 joblib</span><br></pre></td></tr></table></figure>
<p>其中参数<code>-c</code>指定了镜像源的通道，这里实在anaconda官方中安装joblib</p>
<p>或者</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda install -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/linux-64 jieba</span><br></pre></td></tr></table></figure>
<p>这里是在conda-forge中安装jieba第三方的Python包</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pip</tag>
        <tag>conda</tag>
      </tags>
  </entry>
  <entry>
    <title>python知识点</title>
    <url>/python%E7%9F%A5%E8%AF%86%E7%82%B9.html</url>
    <content><![CDATA[<blockquote>
<p>都是关于python3的内容</p>
</blockquote>
<h1 id="Python知识点"><a href="#Python知识点" class="headerlink" title="Python知识点"></a>Python知识点</h1><p>这里主要是记录下我平常编程中用到，但是不太清楚地知识点，仅仅作为一个记录使用</p>
<h2 id="python基本类型"><a href="#python基本类型" class="headerlink" title="python基本类型"></a>python基本类型</h2><ol>
<li>Number(数字)</li>
<li>String(字符串)</li>
<li>List(列表)</li>
<li>Tuple(元组)</li>
<li>Set(集合)</li>
<li>Dictionary(字典)</li>
</ol>
<p>不可变数据：Number（数字）、String（字符串）、Tuple（元组）；<br>可变数据：List（列表）、Dictionary（字典）、Set（集合）。<br>使用type()可以查看变量的类型，用isinstance()也可以查看。区别：</p>
<ul>
<li>type()不会认为子类是一种父类类型</li>
<li>isinstance()认为子类是一种父类类型</li>
</ul>
<p>如下代码所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">B</span>(<span class="title class_ inherited__">A</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">isinstance</span>(A(), A)  <span class="comment"># returns True</span></span><br><span class="line"><span class="built_in">type</span>(A()) == A      <span class="comment"># returns True</span></span><br><span class="line"><span class="built_in">isinstance</span>(B(), A)    <span class="comment"># returns True</span></span><br><span class="line"><span class="built_in">type</span>(B()) == A        <span class="comment"># returns False</span></span><br></pre></td></tr></table></figure>
<h3 id="Number"><a href="#Number" class="headerlink" title="Number"></a>Number</h3><p>Python3中Number包括：int,float,bool,complex.注意只有一种整数类型int，表示长整型。</p>
<h2 id="numpy相关"><a href="#numpy相关" class="headerlink" title="numpy相关"></a>numpy相关</h2><h3 id="维度问题"><a href="#维度问题" class="headerlink" title="维度问题"></a>维度问题</h3><p>注意下面的col_r1和col_r2的输出以及对应维度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>], [<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">col_r1 = a[:, <span class="number">1</span>]</span><br><span class="line">col_r2 = a[:, <span class="number">1</span>:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(col_r1)</span><br><span class="line"><span class="built_in">print</span>(col_r1.shape)</span><br><span class="line"><span class="built_in">print</span>(col_r2)</span><br><span class="line"><span class="built_in">print</span>(col_r2.shape)</span><br></pre></td></tr></table></figure>
<h3 id="numpy数组访问"><a href="#numpy数组访问" class="headerlink" title="numpy数组访问"></a>numpy数组访问</h3><p>注意这里使用数组索引来访问numpy数组。这里可以看成[[[0, 1, 2], [0, 1, 0]]]中(0,0),(1,1),(2,0)看成三对<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])  <span class="comment"># Prints &quot;[1 4 5]&quot;</span></span><br></pre></td></tr></table></figure></p>
<ol>
<li>numpy中有mat和array，都可以用来表示多维数据。如果一个</li>
</ol>
]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>redis study</title>
    <url>/redis-study.html</url>
    <content><![CDATA[<h2 id="redis-数据结构"><a href="#redis-数据结构" class="headerlink" title="redis 数据结构"></a>redis 数据结构</h2><h3 id="简单动态字符串"><a href="#简单动态字符串" class="headerlink" title="简单动态字符串"></a>简单动态字符串</h3><p>redis中字符串是自己定义的结构，名为SDS。不是用的c语言的字符串。<br>SDS的定义如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sdshdr</span> &#123;</span></span><br><span class="line">    <span class="comment">// 记录buf数组中已使用字节的数量</span></span><br><span class="line">    <span class="type">int</span> len;</span><br><span class="line">    <span class="comment">// 记录buf数组中未使用字节的数量</span></span><br><span class="line">    <span class="type">int</span> <span class="built_in">free</span>;</span><br><span class="line">    <span class="comment">// 字节数组，用于存储字符串;其中最后一位保存&#x27;\0&#x27;字符</span></span><br><span class="line">    <span class="type">char</span> buf[];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>为什么要自己实现，而不是复用c中对于字符串的定义？</p>
<ul>
<li>获取字符串长度，在O(1)复杂度获取</li>
<li>杜绝缓冲区溢出。SDS在进行修改时，会检查SDS空间是否满足要求。若不满足，则会进行扩容。</li>
<li>二进制安全，c中的字符串必须符合某种编码格式(比如ASCII)，并且除了字符串的末尾之外，字符串中不能包含空字符。而sds使用len记录字符串长度，所以是二进制安全的。</li>
</ul>
<p>SDS的扩容机制：</p>
<ul>
<li>空间预分配（若对sds进行修改，先将len设置为需要的空间大小）<ul>
<li>若sds中len小于1MB，则将free设置为跟len一样的大小</li>
<li>若sds中len大于1MB，则将free设置为1MB</li>
</ul>
</li>
<li>惰性空间释放<ul>
<li>若释放sds中内容，则free中进行增加。实际占用的空间不释放；当然也提供了相应的api，在需要时，真正释放sds未使用空间。</li>
</ul>
</li>
</ul>
<h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><p>redis中链表结构<br>链表中节点定义<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> &#123;</span></span><br><span class="line">    <span class="comment">// 前置节点</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">prev</span>;</span></span><br><span class="line">    <span class="comment">// 后置节点</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">next</span>;</span></span><br><span class="line">    <span class="comment">// 节点值</span></span><br><span class="line">    <span class="type">void</span> *value;</span><br><span class="line">&#125; listNode;</span><br></pre></td></tr></table></figure><br>链表定义<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">list</span> &#123;</span></span><br><span class="line">    <span class="comment">// 表头节点</span></span><br><span class="line">    listNode *head;</span><br><span class="line">    <span class="comment">// 表尾节点</span></span><br><span class="line">    listNode *tail;</span><br><span class="line">    <span class="comment">// 链表包含的节点数量</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> len;</span><br><span class="line">    <span class="comment">// 节点值复制函数</span></span><br><span class="line">    <span class="type">void</span> *(*dup) (<span class="type">void</span> *ptr);</span><br><span class="line">    <span class="comment">// 节点值释放函数</span></span><br><span class="line">    <span class="type">void</span> (*<span class="built_in">free</span>) (<span class="type">void</span> *ptr);</span><br><span class="line">    <span class="comment">// 节点值对比函数</span></span><br><span class="line">    <span class="type">int</span> (*match) (<span class="type">void</span> *ptr, <span class="type">void</span> *key);</span><br><span class="line">&#125; <span class="built_in">list</span>;</span><br></pre></td></tr></table></figure><br>注：链表节点使用 void*指针保存节点值，并且通过list中的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以保存各种不同类型的值。</p>
<h3 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h3><h3 id="跳跃表"><a href="#跳跃表" class="headerlink" title="跳跃表"></a>跳跃表</h3><h3 id="整数集合"><a href="#整数集合" class="headerlink" title="整数集合"></a>整数集合</h3><h3 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h3><h3 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h3>]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>svm原理介绍</title>
    <url>/svm%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D.html</url>
    <content><![CDATA[<h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><p>这篇博客主要介绍如何推导svm算法。写这篇博客主要是最近在学习svm算法，想着合上书，自己推导一遍算法的原理，发现还是有很多需要思考的地方。<br>其实一般推导机器学习算法，是有一个模式的。</p>
<ol>
<li>定义模型，这里模型理解为如何定义公式</li>
<li>选择损失函数</li>
<li>采用优化算法求损失函数的最小值</li>
<li>推导完毕</li>
</ol>
<p>比如拿逻辑回归算法举例：</p>
<ol>
<li>定义模型，即选取sigmoid函数</li>
<li>定义损失函数</li>
<li>采用最大梯度下降算法求损失函数的最小值</li>
<li>得到算法的w和b</li>
</ol>
<p>但是svm的推导基本上没有怎么提损失函数的内容，大家等会可以在这篇博客中看到如何推导svm算法</p>
<h2 id="判别函数"><a href="#判别函数" class="headerlink" title="判别函数"></a>判别函数</h2><script type="math/tex; mode=display">h_{w,b}(x) = g(w^T + b)</script><p>上式是SVM的判别函数，其中函数g如下所示：</p>
<script type="math/tex; mode=display">g(z)=\left\{
\begin{array}{rcl}
1       &      & {z \geq 0 }\\
-1     &      & {z < 0 }
\end{array} \right.</script><p>即$g(z)$的输出为1时，判别为正例；输出为-1时，判别为反例。</p>
<h2 id="函数间隔和几何间隔-Functional-and-geometric-margins"><a href="#函数间隔和几何间隔-Functional-and-geometric-margins" class="headerlink" title="函数间隔和几何间隔(Functional and geometric margins)"></a>函数间隔和几何间隔(Functional and geometric margins)</h2><h3 id="函数间隔"><a href="#函数间隔" class="headerlink" title="函数间隔"></a>函数间隔</h3><p>对于某一个训练样本$(x^(i), y^(i))$定义函数间隔如下式：</p>
<script type="math/tex; mode=display">\hat{\gamma}^{(i)} = y^{(i)}(w^T + b)</script><p>分析函数间隔公式,可以得出如下的结论.当$y^{(i)}=1$时,则$w^T+b&gt;0$,所以$g(z) = 1$;当$y^{(i)}=-1$时,则$w^T+b&lt;0$,所以$g(z) = -1$.所以函数间隔对于判别样本的类别是有作用的.<br>但是,当我们将$w,b$扩大两倍时,函数函数间隔扩大两倍,但是对于$g(z)$并没有什么变化.即下式成立</p>
<script type="math/tex; mode=display">g(2w^T+2b) = g(w^T+b)</script><p>所以更大的函数间隔并不一定比小的函数间隔的置信度大.由此引出了几何间隔</p>
<h3 id="几何间隔"><a href="#几何间隔" class="headerlink" title="几何间隔"></a>几何间隔</h3><p>针对几何间隔,我们考虑二维平面,如下图所示:<br><img src="/svm%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/%E5%87%A0%E4%BD%95%E9%97%B4%E9%9A%94.png" class=""><br>图中的斜线是对应于参数$(w,b)$的决策分隔线.注意$w$是垂直于决策线的,即$w$是决策线的法向量.</p>
<blockquote>
<p>证明如下:<br>设$x_0,x_1$是直线$w^T+b=0$上不同的两个点,则有下式成立</p>
<script type="math/tex; mode=display">\left\{
\begin{array}{rcl}
w^Tx_0 + b = 0       &      & \\
w^Tx_1 + b = 0     &      &
\end{array} \right.</script><p>两式相减的$w^T(x_0 - x_1) = 0$,而其中$x_0 - x_1$是直线$w^T+b=0$的方向向量,所以w是法向量.</p>
</blockquote>
<p>图中$\gamma^{(i)}$是A点对应的几何间隔.设A点为$x^{(i)}$,而向量$w/{\left|w\right|}$是法向量上的单位向量.因此得到B点为$x^{(i)} - \gamma^{(i)}\cdot w/{\left|w\right|}$,又因为B点在分离平面上,所以下式成立:</p>
<script type="math/tex; mode=display">w^T(x^{(i)} - \gamma^{(i)}{\frac w {\left\|w\right\|}}) = 0</script><p>从而得到下式:</p>
<script type="math/tex; mode=display">\gamma^{(i)} = {\frac {w^Tx^{(i)}+b} {\left\|w\right\|} }=({\frac w {\left\|w\right\|}})^Tx^{(i)} + {\frac b {\left\|w\right\|} }</script><p>如果A点在B点的另外一侧,则B点可以表示为下式:</p>
<script type="math/tex; mode=display">x^{(i)} + \gamma^{(i)}\cdot w/{\left\|w\right\|}$$,带入分离超平面,得到几何间隔如下:
$$\gamma^{(i)} = -{\frac {w^Tx^{(i)}+b} {\left\|w\right\|} }</script><p>综合两种情况,得到</p>
<script type="math/tex; mode=display">\gamma^{(i)} =y^{(i)}(({\frac w {\left\|w\right\|}})^Tx^{(i)} + {\frac b {\left\|w\right\|} })</script><p>具体的公式推导过程中,并没有完全限制在二维平面上(虽然开始展示的图像是二维平面上的),所以对于高维平面也是得到上述公式.<br>几何间隔反应了样本到分离面的距离,直观上最小的几何间隔越大越好.并且几何间隔中的参数$w,b$可以随意的进行尺度变换而不影响几何间隔的大小(这是因为几何间隔的式子中除以了w的二范数).同时当$\left|w\right|=1$时,几何间隔就等于函数间隔.<br>定义</p>
<script type="math/tex; mode=display">\hat{\gamma} = \min_{i=1,...,m}{\hat{\gamma}^{(i)}}</script><script type="math/tex; mode=display">{\gamma} = \min_{i=1,...,m}{\gamma}^{(i)}</script><p>即$\hat{\gamma}$和${\gamma}$分别是函数间隔和几何间隔的最小值.</p>
<h2 id="最优间隔分类器"><a href="#最优间隔分类器" class="headerlink" title="最优间隔分类器"></a>最优间隔分类器</h2><p>通过上面的函数间隔和几何间隔,我们自然能够想到优化目标如下式所示:</p>
<script type="math/tex; mode=display">\max_{\gamma,w,b} {\gamma} \\
s.t.\quad   y^{(i)}(w^T + b) \geq \gamma, i=1,...,m \\
\left\|w\right\|=1 \tag{1.1}</script><p>即在满足所有样本的几何间隔都大于最小几何间隔的情况下,求使得几何间隔最大的参数$w,b$<br>我们可以将上述优化公式转变成用函数间隔进行表达,如下式所示:</p>
<script type="math/tex; mode=display">\max_{\gamma,w,b} {\frac {\hat\gamma} {\left\|w\right\|}}\\
s.t.\quad   y^{(i)}(w^T + b) \geq \hat\gamma, i=1,...,m \tag{1.2}</script><blockquote>
<p>上述两个优化问题为什么等价?因为$\gamma={\frac {\hat\gamma} {\left|w\right|}}$.针对优化公式(1.2),即求取几何间隔最大,同时在约束不等式两边同时除以$\left|w\right|$,即得所有的几何间隔都大于最小的几何间隔.这即等价于优化公式(1.1)</p>
</blockquote>
<p>由于参数$w,b$进行尺度变化,所以我们可以固定函数间隔等于1,即$\hat\gamma=1$<br>最终将优化公式化简为下式:</p>
<script type="math/tex; mode=display">\min_{\gamma,w,b}{\frac 1 2}{\left\|w\right\|}^2 \\
s.t.\quad y^{(i)}(w^T + b) \geq 1, i=1,...,m \tag{1.3}</script><p>针对这个优化公式,即满足不等式的条件下,求取二次函数的最小值,虽然可以采用优化算法求取此最优值.但是我们下面介绍拉格朗日对偶来进行求取,第一求取最优值会变得更加简单,第二能够使用核函数.</p>
<h2 id="拉格朗日对偶-Lagrange-duality"><a href="#拉格朗日对偶-Lagrange-duality" class="headerlink" title="拉格朗日对偶(Lagrange duality)"></a>拉格朗日对偶(Lagrange duality)</h2><p>拉格朗日对偶主要是将优化公式转变为其对偶形式,具体的推导过程可以参考Andrew Ng cs229课程中的内容.</p>
<h2 id="再次求解最优间隔分类器"><a href="#再次求解最优间隔分类器" class="headerlink" title="再次求解最优间隔分类器"></a>再次求解最优间隔分类器</h2><p>通过拉格朗日对偶,将SVM的优化目标转变为对偶形式,从而得到参数$w,b$</p>
]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>svm</tag>
        <tag>支持向量机</tag>
      </tags>
  </entry>
  <entry>
    <title>tensorboard介绍</title>
    <url>/tensorboard%E4%BB%8B%E7%BB%8D.html</url>
    <content><![CDATA[<p>最近因为工作需要，看了下tensorboard的使用方式，这里做了简单的学习记录。使用的tensorflow版本是<strong>1.10.0</strong>,tensorboard的版本也是一样。</p>
<h1 id="tensorboard介绍"><a href="#tensorboard介绍" class="headerlink" title="tensorboard介绍"></a>tensorboard介绍</h1><p>tensorboard主要是为了查看tensorflow程序，将程序进行图示化，可以用来查看程序的运行情况，也可以用来debug程序。</p>
<h2 id="tensorflow写tensorboard日志"><a href="#tensorflow写tensorboard日志" class="headerlink" title="tensorflow写tensorboard日志"></a>tensorflow写tensorboard日志</h2><p>在程序中主要使用<code>tf.summary.FileWriter</code>来将需要记录的事件日志记录到硬盘中。这个函数主要由三个参数需要注意的，如果想要查看详细的内容，可以去源码中查找具体的使用方式。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">logdir:指定日志写入的具体目录</span></span><br><span class="line"><span class="string">graph:指定记录的tensorflow图</span></span><br><span class="line"><span class="string">filename_suffix:事件日志文件的后缀</span></span><br></pre></td></tr></table></figure>
<h2 id="tensorboard启动"><a href="#tensorboard启动" class="headerlink" title="tensorboard启动"></a>tensorboard启动</h2><p>tensorboard的启动是在命令行中，输入<code>tensorboard --logdir=/path/to/log</code>命令启动，然后打开ip+port在浏览器中进行查看。查看tensorboard的参数信息，可以运行<code>tensorboard --help</code>来进行查看。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">--inspect:</span> <span class="string">用来查看事件日志信息，并不启动tensorboard</span></span><br><span class="line"><span class="string">--logdir：用来指定事件日志的存储目录</span></span><br></pre></td></tr></table></figure>
<p>tensorboard主要是扫描logdir指定目录下的内容，扫描文件名带有<em>.tfevents.</em>的文件进行展示。如果logdir下有多个目录，则在浏览器中可以分别进行浏览。如果有多个相同的文件，则会显示时间戳距离最近的文件。文件名中带有时间戳。例如：<strong>events.out.tfevents.1545795299.DESKTOP-123</strong></p>
]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>tensorboard</tag>
      </tags>
  </entry>
  <entry>
    <title>左耳朵耗子-陈皓经历(转)</title>
    <url>/%E5%B7%A6%E8%80%B3%E6%9C%B5%E8%80%97%E5%AD%90-%E9%99%88%E7%9A%93%E7%BB%8F%E5%8E%86-%E8%BD%AC.html</url>
    <content><![CDATA[<h1 id="左耳朵耗子-陈皓"><a href="#左耳朵耗子-陈皓" class="headerlink" title="左耳朵耗子-陈皓"></a>左耳朵耗子-陈皓</h1><h2 id="一、个人简历"><a href="#一、个人简历" class="headerlink" title="一、个人简历"></a>一、个人简历</h2><p>陈皓，coolshell.cn博客博主。<br>14年以上软件开发相关工作经验，8年以上项目和团队管理经验。<br>擅长底层技术架构，软件工程。<br>对高性能，高可用，分布式，高并发，大规模数据处理系统有一定研究。<br>技术擅长C/C++/Java和Unix/Linux/Windows。</p>
<h2 id="二、轶事和思考"><a href="#二、轶事和思考" class="headerlink" title="二、轶事和思考"></a>二、轶事和思考</h2><h3 id="2-1、毅然辞掉银行工作"><a href="#2-1、毅然辞掉银行工作" class="headerlink" title="2.1、毅然辞掉银行工作"></a>2.1、毅然辞掉银行工作</h3><p>我当时在银行做银行网络、银行的电子邮件系统和办公自动化系统。当时正处在银行信息化的阶段，加上当时互联网和IT业刚刚火起来，得到这份工作其实是很幸运的。银行正值扩张电子信息化业务的时候，其实应该有很多事可做，但是当时的主要工作都是由厂商来干。比如说IBM或Cisco拿下单子来，会把工作外包给系统集成商。作为一位技术人员，其实可以发挥的空间并不大，多数时间我只是出了问题打电话的角色。没有人会教你任何事，出了问题，就是打电话，然后按照他们的指导来完成工作。但这个还不是促使我离职的最主要原因，我离开是因为互联网和IT业的兴起让我有些心向往之，有想去看一看的冲动。我还记得当时的辞职书是这么写的：“本人对现有工作毫无兴趣，申请辞职”。处长说，“你可以这么写，但是要加上‘经调解无效’，另外，分给你的房就不能要了”。我说好啊。就这样就辞去了工作，去了上海。老实说，这个决定真不好做，因为几乎所有的朋友和亲人都很反对。</p>
<h3 id="2-2、选择上海闯荡的原因"><a href="#2-2、选择上海闯荡的原因" class="headerlink" title="2.2、选择上海闯荡的原因"></a>2.2、选择上海闯荡的原因</h3><p>当时选择上海是有原因的，我觉得在当时的环境（2000年）下，上海的发展比较不错。没有选择深圳的原因是个人感觉那是因为政治原因凭空冒出来的一座城市，我不是很喜欢。北京我有很多同学，而我想去一个陌生的地方。但是后来发现上海也不是做技术的地方，过得有些压抑，初来到上海的时候经常会被人瞧不起，毕竟是刚刚来到大城市。<br>我当时感觉银行束缚了我，想看看自己可以跑多远，能发挥出多大的价值。于是决定出来闯一闯，主要就是要去经历一些应该去经历的事情，不希望老了以后会后悔年轻的时候没有去。当时IT产业的发展是一个大趋势，我感觉我必须要去一座大城市，去经历一些东西。在小地方基本没有这些机会。要学会游泳就必须要跳到水里去呛两口水，所以我就义无反顾地出来了。</p>
<h3 id="2-3、工作挫折和自省"><a href="#2-3、工作挫折和自省" class="headerlink" title="2.3、工作挫折和自省"></a>2.3、工作挫折和自省</h3><p>我仍然记得自己拎着皮箱站在上海火车站的样子，举目无亲。原来在老家的时候觉得自己还挺厉害的，自以为不愁找不到好工作。不过事实却不是这样的。<br>我还记得第一次去面试时，（面试官）问了很多和C相关的问题，问了我半个小时，我一个问题都答不上来。我一直低着头，好像被审问的犯罪分子一样。我从大学毕业出来就没经历过什么面试，再加上自己内向的性格，所以，整个过程我都在低着头，不敢看别人一眼。最后，面试官问了我一个问题是“有不懂的问题你会怎么办”，这样的问题我都不敢回答，其实这道题的答案不过就是“问别人”或是“自己看书”或是“上网查资料”什么的。很显然，这场面试我肯定是被灭掉了。但这还没完，最后面试官对我说：“你出来干什么，像你这种性格根本不适合到大城市来”。<br>我当时被严重地打击了，感觉到自己确实有一些东西很差。第一个是性格差，不知道怎么与人交往；第二个是技术差，很多问题不知道；第三个就是视野狭窄，没见过世面。后面的几家公司的面试都大同小异。一个人在异地他乡，经历了这些事情，心里会非常地恐慌，“我这条路是不是走错了？”，我经常这样问自己。<br>面对这样的情况，我被逼迫着一定要改变自己。因为，离开银行时，我的家人、同学和朋友都很反对我出来，如果这样灰溜溜地回去，我面对不了他们。而前面的人还看不起我。我当时的处境真的很难堪，就像爬在悬崖中间，上不去也下不来。所以，当时只有一个想法，就是要证明自己不是那么差的人。人被逼到那个份上，活得就比较简单，哪有什么职业发展规划，只想拼命地多学技术，提高自己的能力。这个经历有点像是一剂兴奋剂，同时也相当阵痛。但是回头想想，第一个面试官应该是我最感谢的人。</p>
<h3 id="2-4、疯狂成长"><a href="#2-4、疯狂成长" class="headerlink" title="2.4、疯狂成长"></a>2.4、疯狂成长</h3><p>在同学的帮助下我找到了在上海的第一份工作。南天公司，这是一家给银行做系统集成软件的公司，大学毕业时本来也可以进去，现在绕了一圈而且还是靠同学帮助进去的，所以那时的心态还很不平稳；另一方面因为以前是做银行的，是甲方，现在成了乙方了，两边的人都用异样的眼光看我，心态非常不好。<br>不过，这是个技术不错的企业，国内早期很多搞Unix/C的高手都是从这个公司培养出来的。我当时的技术还是不行，比如说到了用户站点以后，不知道怎么做，我曾经误操作把用户的数据删掉了。经常犯低级错误，不但没做好自己的工作，反而还给别人添了麻烦。这些经历都让我有一种“技术焦虑感”，或者叫“技术忧郁症”。我觉得自己这也不行，那也不行。这也是我今天仍然在拼命学习的原因。这就好像我们经常在参加工作多年后还会梦见自己的英语四级没过，或者是期末考试没过一样。我经常会梦见的是项目又做砸了，又把用户的系统搞乱了，一大堆人要审我、要训斥我。<br>因为技术差，沟通差，不会面试，所以，我决定经常出去面试，基本上每周都要去，不管懂不懂，也不管是什么公司，也不管别人鄙不鄙视我，反正一有机会就去面试，多见见人这样可以让我的性格有所改善，同时，也可以知道社会上需要一些什么样的技能，把别人面我回答不上来的东西都记下来，然后回头找答案。那个时候我会经常去上海书城看书，看很多很多的书。我学的东西很杂，什么做网页，Windows，Unix，Java，.NET，flash，连3DMax/Photoshop我也学，还去考CCNA的认证等等。这样散乱地学习两年后，我才慢慢确定了要走C/C++/Unix/Windows系统底层的路子。而这样扑天盖地学习的结果有一个好处就是，我成长的速度相当之快。我自己摸索到了适合我的学习方法（从基础和原理上学习），从而不再害怕各种新的技术。那时，所有人都在休黄金周出去玩的时候，我还呆在办公室或住处看书学习。<br>等到一年半之后，用句赵本山的台词说，我在面试中学会抢答了。面试官的问题没问完，我就能说出答案了。其实，基本上是面一个公司过一个（当然都是一些小公司），此时，我就开始挑公司了。<br>感到技术能力不行就去学技术，交往能力不行我就去面试，这两个问题都可以通过大量地实践和努力来弥补，但是眼界这个东西没有办法通过努力来弥补。所以，当时非常想去一些更大的公司看看，如果能去外企更好。</p>
<h3 id="2-5、变得不一样"><a href="#2-5、变得不一样" class="headerlink" title="2.5、变得不一样"></a>2.5、变得不一样</h3><p>我还记得，有一天，有一个和网络相关的技术问题，同事们搞了三四个通宵，也没弄明白，后来想起我好像在看这方面的书，他们就让我去看看、试试，结果我只用了20分钟就搞定了。基础真的很重要，这受益于我看了《TCP/IP详解》这套书。<br>后来，我去了一家做电信软件的公司，他们让我做PowerBuilder，尽管我当时想做的是C++，但是因为当时各种原因很需要这份工作，就去了。进了那里的第一天发现公司里有一个论坛，上面都是一些技术上悬而未决的问题，都是关于Windows/C++的。我一看，都是些很简单的问题，一下午的时间就被我全部解决掉了，我的基础知识发挥了作用。于是，当天下午我一下子就被调到了核心组。不过，我只在那里呆了两个多月，因为那时我已经不愁找工作了，这期间有两家北京的公司录用了我，于是，02年我就来到了北京，去到一家做分布式计算平台软件的公司。<br>在上海的这两年的时间，从什么都不是，到得到工作上的全面肯定。那段时间感觉自己牛得不得了，有些狂妄和骄傲了，经常上网和不认识的人争论一些很傻的问题，后来发展到对当时的领导以及银行客户的领导不敬，总觉得这些人太二。现在回头看过去，我觉得那是我人生特定时期的记号，人生的痕迹。</p>
<h3 id="2-6、建立coolshell-cn的原因"><a href="#2-6、建立coolshell-cn的原因" class="headerlink" title="2.6、建立coolshell.cn的原因"></a>2.6、建立coolshell.cn的原因</h3><p>我2002年在CSDN开了一个blog，当时叫专家专栏。开个专栏很简单，只要发6个帖子。我也不是什么专家，只是喜欢看书、喜欢学习而已，也喜欢做一些学习笔记。那时候没有笔记本也没有台式机，市面上好像也没有U盘和移动硬盘。正好有CSDN这么一个地方，就去CSDN的站点上把自己的一些学习笔记放在了上面。后来03年的时候技术专栏转到了博客，因为CSDN对其博客经营得不好，我09年就离开了csdn，创建了酷壳。花了4500块钱，租了一个server。我离开那里主要有两个原因，一个是因为当时CSDN博客有一些性能上的问题，.NET架构嘛，大家都懂的。另外一个原因就是当时出现了很多博客营销的站点，有点像今天的36氪。好像那时候出现最早的叫煎蛋，那上面会有一些报纸上不会出现的国外的趣闻，是以博客的方式形成的媒体。这和常规的以日记形式出现的博客大不一样。煎蛋、有意思吧等这些博客让我看到了博客还能这样写，我觉得很好玩儿。而我当时也经常会去国外社区看一些文章，也能看到一些有意思的东西（因为我当时有了学习瓶颈，国内的网站已经满足不了我了）。心想，既然这些东西这么有意思，我为什么不自己开一个博客呢？<br>我老婆是学新闻编辑的，她鄙视我说，你的博客虽然有很多人读，但是只能算是个书呆子的博客，全是一些书呆子式的文章。我有些不服，我觉得技术人员不全是书呆子，我们这个圈子里也有很多有趣的东西，只不过是你不知道而已。于是我想弄一个有意思的、有娱乐性质的东西，里面都是技术圈里面有意思的事儿，但是很多技术圈以外的人也能看懂。一开始酷壳和CSDN博客的风格完全迥然，如果有技术性的文章我还会在CSDN上贴，但是后来我就完全抛弃了原来CSDN上的博客。酷壳的初衷是希望很多人都可以来上面发表一些东西，但是可能是我写得太多了，别人就被压制住了。<br>现在博客更新频率是一周一篇，一开始的时候一周三篇。磨刀不误砍柴工，总是有时间来做这些事的。我经常看书，需要把学到的东西整理成学习笔记。自从在CSDN上写博客的时候，就有这样的习惯了，而且又有“技术焦虑症”，害怕跟不上，所以维护博客的事对我来说是很自然的。<br>现在我已经不用自己再租服务器了，由于酷壳的访问量比较有保证，我提供了广告位，就免费得到服务器了。</p>
<h3 id="2-7、对于新技术的态度"><a href="#2-7、对于新技术的态度" class="headerlink" title="2.7、对于新技术的态度"></a>2.7、对于新技术的态度</h3><p>遇到新技术我会去了解，但不会把很大的精力放在这。这些技术尚不成熟，我只需要跟得住就可以了。我的团队自己想学什么我都不干涉，但是用到项目里的技术，必须是很成熟的，（技术应用）十年以上可能是一个门槛。有人说技术更新换代很快，我一点儿都不这样想。虽然有不成熟的技术不断地涌出，但是成熟的技术，比如Unix，40多年，C，40多年，C++，30多年，Java也有将近20年了……，所以，技术并不多啊。还有很多技术比如Ruby，Lisp这样的，它们没有进入主流的原因主要是缺少企业级的应用背景。<br>如果要捋一个脉络下来，70年代Unix的出现，是软件发展方面的一个里程碑，那个时期的C语言，也是语言方面的里程碑。当时所有的项目都在Unix/C上，全世界人都在用这两样东西写软件。Linux跟随的是Unix，Windows下的开发也是C。这时候出现的C++很自然就被大家接受了，企业级的系统很自然就会迁移到这上面，C++虽然接过了C的接力棒，但是它的问题是它没有一个企业方面的架构，否则也不会有今天的Java。C++和C非常接近，它只不过是C的一个扩展，长年没有一个企业架构的框架。而Java出现之后，IBM把企业架构这部分的需求接了过来，J2EE的出现让C/C++捉襟见肘了，后面还有了.NET，但可惜的是这只局限在Windows平台上。这些就是企业级软件方面语言层面这条线上的技术主干。</p>
<p>另外一条脉络就是互联网方面的（HTML/CSS/JS/LAMP…）。这条脉络和上述的那条C/C++/Java的我都没有放，作为一个有技术忧虑症的人，这两条软件开发的主线一定不能放弃。无论是应用还是学术，我都会看，知识不愁多。何必搞应用的和搞学术的分开阵营，互相看不起呢？都是知识，学就好了。<br>技术的发展要根植于历史，而不是未来。不要和我描述这个技术的未来会多么美好，用这个技术可以实现什么花哨的东西。很多常青的技术都是承前的。所以说“某某（技术）要火”这样的话是没有意义的，等它火了、应用多了咱们再说嘛。有些人说不学C/C++也是没有问题的，我对此的回应是：如果连主干都可以不学的话，还有什么其他的好学呢？极端一点，我要这么说：这些是计算机发展的根、脉络、祖师爷，这样的东西怎么可以不学呢？大部分学校虽然都会教授C，但是教得都不好。学校喜欢教微软的东西，老师好教学生好学。我不是说Windows不好，但那不是计算机文化的主干，那只是微软的主干、PC的主干。整个计算机文化的主干肯定是源起于Unix/C这条线上（注意，我说的是文化不是技术）。我也写过很多与Unix文化相关的文章，大家可以看看我写的“Unix传奇”。</p>
<h3 id="2-8、对于学校计算机科学教育的看法"><a href="#2-8、对于学校计算机科学教育的看法" class="headerlink" title="2.8、对于学校计算机科学教育的看法"></a>2.8、对于学校计算机科学教育的看法</h3><p>学校教的大部分都是知识密集型的技术，但是社会上的企业大部分都是劳动密集型的。什么是劳动密集型的企业呢？麦当劳炸薯条就是劳动密集型的工作，用不到学校教授的那些知识。如果有一天你不炸薯条了，而要去做更大更专业的东西，学校里的知识就会派上用场。有人说一个语言、一个技术，能解决问题能用就行了，我不这样认为。我觉得你应该至少要知道这些演变和进化的过程。而如果你要解决一些业务和技术难题，就需要抓住某种技术很深入地学习，当成艺术一样来学习。</p>
<p>我在“软件开发‘三重门’”里说过，第一重门是业务功能，在这重门里，的确是会编程就可以了；第二重门是业务性能，在这一重门里，技术的基础就很管用了，比如：操作系统的文件管理，进程调度，内存管理，网络的七层模型，TCP/UDP的协议，语言用法、编译和类库的实现，数据结构，算法等等就非常关键了；第三重门是业务智能，在这一重门里，你会发现很多东西都很学院派了，比如，搜索算法，推荐算法，预测，统计，机器学习，图像识别，分布式架构和算法等等，你需要读很多计算机学院派的论文。<br>总之，这主要看你职业生涯的背景了，如果你整天被当作劳动力来使用，你用到的技术就比较浅，比较实用，但是如果你做一些知识密集型的工作，你就需要用心来搞搞研究，就会发现你需要理论上的知识。比如说，我之前做过的跨国库存调配，需要知道最短路径的算法，而我现在在亚马逊做的库存预测系统，数据挖掘的那些东西都需要很强的数学建模、算法、数据挖掘的功底。<br>我觉得真正的高手都来自知识密集型的学院派。他们更强的是，可以把那些理论的基础知识应用到现在的业务上来。但很可惜，我们国内今天的教育并没有很好地把那些学院派的理论知识和现实的业务问题很好地结合起来。比如说一些哈希表或二叉树的数据结构，如果我们的学校在讲述这些知识的时候能够结合实际的业务问题，效果会非常不错，比如：设计一个IP地址和地理位置的查询系统，设计一个分布式的NoSQL的数据库，或是设计一个地理位置的检索应用等等。在学习操作系统的时候，如果老师可以带学生做一个手机或嵌入式操作系统，或是研究一下Unix System V或是Linux的源码的话，会更有意思。在学习网络知识的时候，能带学生重点学一下以太网和TCP/IP的特性，并调优，或是能做一个网络上的Pub/Sub消息系统或是做一个像Nginx一样的web server，那会更好。如果在学图形学的过程中能带领学生实践开发一个作图工具或是一个游戏引擎，那会更有意思。<br>总之，我们的教育和现实脱节太严重了，教的东西无论是在技术还是在实践上都严重落后和脱节，没有通过实际的业务或技术问题来教学生那些理论知识，这是一个失败。</p>
<h3 id="2-9、如何在压力下，享受技术带来的快乐"><a href="#2-9、如何在压力下，享受技术带来的快乐" class="headerlink" title="2.9、如何在压力下，享受技术带来的快乐"></a>2.9、如何在压力下，享受技术带来的快乐</h3><p>中国人中庸的思想，入世和出世，每天的工作就是入世。举个例子，在上海的时候，给交通银行做项目的时候，每周休息一天，早九点到晚十点，每天工作12个小时，这样的工作持续了一整年，没有节假日，项目上的技术也没什么意思。当时我晚上十点回到住处，还想学一些C++/Java和Unix/Windows的技术，于是就看书到晚上11:30，每天如此，一年下来学到很多东西，时间没有荒废，心里就很开心。我觉得当时是快乐的，因为有成长的感觉是快乐的。</p>
<p>现在的我，工作、写博客、养孩子，事情其实更多。我早上7:30起床，会浏览一下国外的新闻，hacker news，tech church，reddit，highavailability之类的站点，9点上班。晚上6、7点钟下班，开始带孩子。十点钟孩子睡了觉，我会开始重新细读一下这一天都发生了些什么事情。这个时间也有可能会用来看书。学习的过程我是不喜欢被打断的，所以从十点到十二点，家人都睡了，这正是我连续学习的好时间。可能从晚上11:30开始，我会做点笔记或者写博客。我现在对酷壳文章的质量要求比较高一些，所以大概积累一个星期的时间才可以生成一篇文章。每天我大概都在一两点钟才会睡觉。没办法，我有技术焦虑症。但是觉得这样的生活很充实，也很踏实。<br>另外，任何一门技术玩深了，都是很有意思的。有些人形成了一个价值取向，“我只做什么，绝不做什么”。前段时间有一个刚来亚马逊的工程师，他原来做的是数据挖掘推荐系统，后来公司重组要他做前端，他不肯。我觉得，前端后端都是编程，Javascript是编程，C++也是编程。编程不在于你用什么语言去coding，而是你组织程序、设计软件的能力，只要你上升到脑力劳动上来，用什么都一样，技术无贵贱就是这个意思。<br>回到问题，怎么才能享受到快乐呢？第一，入世和出世要分开，不要让世俗的东西打扰到你的内心世界，你的情绪不应该为别人所控，也不应该被世俗所污染，活得真实，你才会快乐。第二点就是要有热情，有了热情，你的心情就会很好，加班都可以是快乐的，想一想我们整个通宵用来打游戏的时光，虽然很累，但是你也很开心，这都是因为有了热情的缘故。</p>
<h3 id="2-10、做自己是最难的"><a href="#2-10、做自己是最难的" class="headerlink" title="2.10、做自己是最难的"></a>2.10、做自己是最难的</h3><p>我承认我活在我的精神家园里面。我推荐大家看一下王小波的《我的精神家园》，这篇文章对我的影响非常大。看了这篇文章，你就会明白我为什么要躺在自己的池子里，如果不想被这个社会所污染，就必须要躺在自己的池子里。做大众是很容易的，做自己是最难的。当你老了的时候，回想过去，如果你是为自己而活的，你总会觉得很踏实。可能有人会觉得我偏激，没关系，为什么要所有人看法都一致呢？世界因为不同而美丽，多元化的价值观并不冲突。</p>
<p>转载自：<a href="http://www.ituring.com.cn/article/9174">http://www.ituring.com.cn/article/9174</a></p>
]]></content>
      <categories>
        <category>编程人生</category>
      </categories>
  </entry>
  <entry>
    <title>欧洲四国行</title>
    <url>/%E6%AC%A7%E6%B4%B2%E5%9B%9B%E5%9B%BD%E8%A1%8C.html</url>
    <content><![CDATA[<p>今年九月份去了一趟欧洲,总共去了有十五天的样子。去了比利时,西班牙(巴萨罗那),葡萄牙(里斯本),法国(巴黎)四个国家。除了比利时，其他的三个国家都是只去了一个城市。</p>
<h1 id="比利时"><a href="#比利时" class="headerlink" title="比利时"></a>比利时</h1><p>比利时是我到达欧洲的第一站,第一天主要是在布鲁塞尔市内玩。去了市中心的大广场，雨果笔下世界上最美丽的广场。第一眼看到此广场，给我很大的震撼，整个广场四周全部是欧式建筑，有巴洛克式，也有哥特式。建筑上面的人物雕塑也非常精美。置身其中，你能感觉到建筑帮助我直达它所在的那个年代，像我展示着那个时代的辉煌。而且这种建筑不单单只是作为居住或者商业的功能，它的美感也是其重要的组成部分。第二天去了比利时的古城-布鲁日，还有靠近海边的城市奥斯坦德。早上早早出发，乘坐火车前往布鲁日，到了地方，渐渐的天空中开始飘起雨。可能因为前一天看了布鲁塞尔的大广场，来到布鲁日，虽然建筑很好看，但是并没有给我很大的震撼了。现在回想起来，也就能记得当时主要是沿布鲁日古城区转了转，并没有特别深的印象了。因为准备工作做得不足，本来想要去奥斯坦德看下北海的，但是到了地方之后，发现太冷了，也就没有转，下了火车就又回去了，也是一个遗憾吧。<br>来比利时之前，并不是怎么了解这个国家。来了之后发现国家虽然小，但是有名的东西还是很多的。首先是啤酒。可能说到啤酒，大家想到的一个就是德国。但是来了比利时之后，才发现比利时啤酒才真的是啤酒的王国。首先不像德国啤酒种类较为较为单一，这里的啤酒种类非常丰富，据说有四五百种。而且大街上酒吧也非常密集。假如超市里面只有六个货架，那么光酒就能占三个货架，哈哈。来到此地，怎么能不尝尝呢？去超市买了七八种啤酒，还有一瓶产自法国勃艮第的红酒。三天时间全部被我喝完了，这里的啤酒真的名不虚传，味道真不错，比国内的啤酒强太多了。哎，现在想喝也很难喝到了。说到啤酒，为啥比利时这么多呢？据说因为比利时地势较为低，水不好喝，比较涩口，所以采用本地的水和啤酒花酿做了啤酒。原来比利时人是将啤酒作为水的替代品了。虽然啤酒种类很多，但是这里有一种啤酒很难喝到。它就是修道院啤酒。虽然价格不是很贵，但是真的很难买到，而且被评价为最好喝的啤酒。首先，全球能够生产修道院啤酒只有七个修道院，荷兰有一家，比利时占了剩下六家，三家在比利时的荷语区，三家在比利时的法语区。并且每年生产的啤酒就那么多，不会有多的。这些啤酒都是修道院里面的修士酿造的。修士除了平时进行宗教的学习，剩下很多的时间都在潜心专研如何酿造好喝的啤酒。比利时除了啤酒以外，还有它的巧克力也是全球闻名。路边的巧克力店很多。还有炸薯条。</p>
<h1 id="巴塞罗那"><a href="#巴塞罗那" class="headerlink" title="巴塞罗那"></a>巴塞罗那</h1><h1 id="里斯本"><a href="#里斯本" class="headerlink" title="里斯本"></a>里斯本</h1><h1 id="巴黎"><a href="#巴黎" class="headerlink" title="巴黎"></a>巴黎</h1>]]></content>
      <categories>
        <category>欧洲</category>
        <category>旅行</category>
      </categories>
      <tags>
        <tag>比利时</tag>
        <tag>巴塞罗那</tag>
        <tag>里斯本</tag>
        <tag>巴黎</tag>
      </tags>
  </entry>
  <entry>
    <title>统计学知识</title>
    <url>/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E7%9F%A5%E8%AF%86.html</url>
    <content><![CDATA[<h1 id="统计学相关知识"><a href="#统计学相关知识" class="headerlink" title="统计学相关知识"></a>统计学相关知识</h1><p>在平常的机器学习应用中,我们首先要做的事情就是分析数据.分析数据有很多种方法,而且其中很多方法都是统计学中的内容.本篇blog主要记录我认为平常经常能够用到的统计学内容.</p>
<h2 id="箱线图-box"><a href="#箱线图-box" class="headerlink" title="箱线图(box)"></a>箱线图(box)</h2><p>箱线图主要是用来分析数据中的异常值,在数据分析中非常有用.同时它也能够用来分析某一个特征跟预测值之间的关系,<a href="https://blog.csdn.net/clairliu/article/details/79217546">参考</a>.如下图所示<br><img src="/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E7%9F%A5%E8%AF%86/%E7%AE%B1%E7%BA%BF%E5%9B%BE.png" class="" title="箱线图"></p>
<p>在python的seaborn包中画箱线图主要是调用<strong>boxplot</strong>函数,具体的使用方法可以查看相关文档.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.boxplot(x,y,data)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>统计学</category>
      </categories>
  </entry>
  <entry>
    <title>线性回归算法</title>
    <url>/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95.html</url>
    <content><![CDATA[<h1 id="线性回归算法"><a href="#线性回归算法" class="headerlink" title="线性回归算法"></a>线性回归算法</h1><blockquote>
<p>注：本文所有代码和数据均在个人github下<a href="https://github.com/lightnine/machine-learning/blob/master/src/regression/regression.py">click me</a></p>
</blockquote>
<p>回归算法一般是针对预测是连续的情况下，对于预测值是离散的，采用的算法是分类算法。线性回归算法包括很多种变形，这里提到的线性回归算法是其中的几种典型算法。在实际应用中，我们采用线性算法可以预测商品的价格，预测房子的房价等等，虽然线性回归算法比较简单，但是在实际中还是有很多的使用的。</p>
<blockquote>
<p>在机器学习中，我们要紧盯三件事情。第一，算法的损失函数；第二，采用什么求值算法求损失函数的最小值；第三，算法的评价指标</p>
</blockquote>
<h2 id="一般线性回归算法"><a href="#一般线性回归算法" class="headerlink" title="一般线性回归算法"></a>一般线性回归算法</h2><p>一般的线性回归又叫做最小二乘算法，最小二乘是因为算法的损失函数是最小二乘的，损失函数如下：</p>
<script type="math/tex; mode=display">J(\theta)={\frac 12}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})^2 \tag {1.1}</script><p>其中$h_\theta(x^{(i)})$是算法针对数据的预测值，而$y^{(i)}$是数据的真实值，$m$表示训练数据的条数，而${\frac 12}$是为了此公式求导方便而加入的。而$\theta$是算法的参数，在这里就是线性回归的权重值。通过此公式我们可以得到，线性回归算法的损失函数就是针对每个样本计算预测值和真实值得差，然后将差求平方，之后将全体样本的差平方相加即得到损失函数。<br>针对损失函数，我们有两种算法可以求取损失函数的最小值。</p>
<h3 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h3><p>梯度下降算法的一般形式：</p>
<script type="math/tex; mode=display">\theta_j: = \theta_j - \alpha{\frac \partial  {\partial\theta_j}}J(\theta) \tag {1.2}</script><p>这里写的是梯度下降算法的标量形式。这个公式描述了梯度下降算法是如何更新算法的参数的，其中$\alpha$是参数的更新步长。可以看到这里的关键是如何求取损失函数关于参数j的偏导数。<br>将损失函数带入到梯度下降算法,即公式$(1.2)$中，并且求导，可以得到下式：</p>
<script type="math/tex; mode=display">\theta_j:= \theta_j + \alpha{\sum_{i=1}^m (y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}} \tag {1.3}</script><p>我们重复的使用公式$(1.3)$直到达到收敛条件，即可以求得线性回归算法中的参数值。<br>从公式中，可以看到用真实值和预测值之间的差值来更新参数值，这种方式或者思想在很多的机器学习算法中可以看到，包括深度学习的后向传播算法。同时，可以看到每一次的迭代都要使用整个数据集。这种方式叫做批量梯度下降算法。还有一种方式可以求取$\theta$值，叫做随机梯度下降算法，算法如下：<br><img src="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.PNG" class="" title="随机梯度下降算法"><br>从中我们可以看到，随机梯度下降算法每次采用一个训练样本取更新所有的参数值，注意那里的(for every j)。当训练样本很多时，相比于批量梯度下降算法，随机梯度下降算法能够更快的更新算法的参数值，并且能够更快的逼近损失函数的最小值。</p>
<h3 id="代数解"><a href="#代数解" class="headerlink" title="代数解"></a>代数解</h3><p>我们将损失函数用向量表示，如下所示：</p>
<script type="math/tex; mode=display">J(\theta) = {\frac 12}(X\theta - \vec{y})^T(X\theta - \vec{y}) \tag{1.4}</script><p>公式中的$X$表示训练数据的矩阵。因为损失函数是凸二次函数，所以只有一个最小值，所以导数为0的点就是损失函数的最小值。<br>具体的推导过程如下(主要利用了矩阵的迹运算)：<br><img src="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E5%AF%BC%E6%95%B0.PNG" class="" title="推导过程"><br>令导数等于0，从而得到：</p>
<script type="math/tex; mode=display">\theta = (X^TX)^{(-1)}X^T\vec{y} \tag{1.5}</script><h3 id="回归模型的概率解释"><a href="#回归模型的概率解释" class="headerlink" title="回归模型的概率解释"></a>回归模型的概率解释</h3><p>大家想过没有，为什么在线性回归模型里面选择最小二乘作为损失函数？接下来从概率的角度来解释选择最小二乘作为损失函数的原因。<br>首先，假设目标变量和输入数据存入如下的关系：</p>
<script type="math/tex; mode=display">y^{(i)} = \theta^Tx^{(i)} + \epsilon^{(i)} \tag{1.6}</script><p>这里的$\epsilon^{(i)}$是误差项，包括模型未考虑到影响目标变量的因素和随机噪声。<br>接下来假设，误差项相互独立同分布，并且服从高斯分布(即正态分布)</p>
<blockquote>
<p>为什么要假设误差项服从高斯分布? 第一是因为采用高斯分布，在数学上处理会比较简单；第二是因为根据中心极限定理，独立的随机变量的和，其总的影响接近高斯分布</p>
</blockquote>
<p>误差项的概率密度函数为：</p>
<script type="math/tex; mode=display">p(\epsilon^{(i)}) = {\frac 1{\sqrt{2\pi}}}exp(-{\frac {(\epsilon^{(i)})^2} {2\sigma^2}}) \tag {1.7}</script><p>根据公式$(1.6)$和公式$(1.7)$,我们可以得出如下结论：<br><img src="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83.PNG" class="" title="概率分布"><br>在公式中，$\theta$不是随机变量，而是实际存在的值，虽然我们不知道真实值是多少。$p(y^{(i)}|x^{(i)};\theta)$的含义是给定$x^{(i)}$,参数设定为$\theta$时,<script type="math/tex">y^{(i)}</script>的概率密度。注意公式中用的分号。<br>数据的概率是由$p(\vec{y} | X;\theta)$给出的，而总的概率可以看成是在固定$\theta$时，关于$\vec{y}$的函数。换个角度，我们想要将这个函数明确的看成是关于$\theta$的函数，所以我们将其称作似然函数，从而我们得到关于$\theta$的似然函数：</p>
<blockquote>
<p>似然(likelihood)和概率(probability)实际上是一个东西，但是似然函数是对参数$\theta$定义的，为了加以区分，使用了似然这一术语。我们可以说参数的似然，数据的概率，但不能说数据的似然，参数的概率。</p>
</blockquote>
<script type="math/tex; mode=display">L(\theta) = L(\theta;X,\vec{y}) = p(\vec{y}|X;\theta)</script><p>极大似然估计就是选择$\theta$,使参数的似然函数最大化，也就是选择参数使得已有样本的出现概率最大。<br>因为$L(\theta)$是严格单调递增的，并且对数函数也是递增的，所以取对数，得到的$\theta$跟不取对象是一样的。<br><img src="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0.PNG" class="" title="似然函数"><br>对数似然函数$\mathcal {l}(\theta)$:<br><img src="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E5%AF%B9%E6%95%B0%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0.PNG" class="" title="对数似然函数"><br>最大化似然函数，就是最大化对数似然函数，即最小化</p>
<script type="math/tex; mode=display">{\frac 12}{\sum\limits_{i=1}^{m}}(y^{(i)} - \theta^Tx^{(i)})^2</script><p>这个式子刚好是线性回归算法中采用的损失函数。总结一下，最小二乘回归模型刚好就是在假设了误差独立同服从正态分布后，得到的最大似然估计。同时注意到，正态分布中的方差$\sigma^2$的取值对模型并没有影响。</p>
<h3 id="编程实现"><a href="#编程实现" class="headerlink" title="编程实现"></a>编程实现</h3><h4 id="代数解实现线性回归算法"><a href="#代数解实现线性回归算法" class="headerlink" title="代数解实现线性回归算法"></a>代数解实现线性回归算法</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">standard_regression</span>(<span class="params">x_arr, y_arr</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    这里直接采用代数解直接求取权重大小.这里有个条件是xTx的逆必须存在,</span></span><br><span class="line"><span class="string">    如果不存在,则直接返回</span></span><br><span class="line"><span class="string">    :param x_arr:</span></span><br><span class="line"><span class="string">    :param y_arr:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x_mat = np.mat(x_arr)</span><br><span class="line">    y_mat = np.mat(y_arr).T</span><br><span class="line">    xTx = x_mat.T * x_mat</span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(xTx) == <span class="number">0.0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;矩阵是奇异的,逆不存在&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    ws = xTx.I * (x_mat.T * y_mat)</span><br><span class="line">    <span class="keyword">return</span> ws</span><br></pre></td></tr></table></figure>
<p>根据<code>standard_regression</code>函数可以直接求取算法的权重。然后根据权重就可以求得数据的预测结果，这里选择的数据在<a href="https://github.com/lightnine/machine-learning/blob/master/src/regression/data/ex0.txt">点我</a><br>画出的图像如下：<br><img src="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%B5%8B%E8%AF%95.png" class="" title="测试"><br>直线为拟合直线，散点是真实值。</p>
<h4 id="随机梯度下降实现线性回归"><a href="#随机梯度下降实现线性回归" class="headerlink" title="随机梯度下降实现线性回归"></a>随机梯度下降实现线性回归</h4><p>由于代码篇幅比较长，所以可以直接上我的github上面看。<a href="https://github.com/lightnine/machine-learning/blob/master/src/regression/regression_sgd.py">代码</a></p>
<h2 id="局部加权线性回归算法"><a href="#局部加权线性回归算法" class="headerlink" title="局部加权线性回归算法"></a>局部加权线性回归算法</h2><img src="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E5%B1%80%E9%83%A8%E5%8A%A0%E6%9D%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.PNG" class="" title="局部加权线性回归">
<p>每个点都对应一个不同的$\theta$，利用$\theta$计算预测值。<br>下面我们用刚才介绍的局部加权线性回归来拟合一下这个模型，简单回顾一下过程：<br>1.用高斯核函数计算出第ｉ个样本处，其它所有样本点的权重Ｗ<br>2.用权重ｗ对第ｉ个样本作加权线性回归，得到回归方程，即拟合的直线方程<br>3.用刚才得到的经验回归直线计算出$x^i$处的估计值$y^i$<br>4.重复一至三步，得到每个样本点的估计值</p>
<p>同时,从计算公式中，可以看到对于每个点的预测值，需要利用所有的数据样本进行计算。如果数据量比较大，计算量就会是一个大问题。<br>相比于上面提到线性回归算法(<strong>参数算法</strong>)，局部加权线性回归算法是<strong>非参数算法</strong>。</p>
<h3 id="参数算法vs非参数算法"><a href="#参数算法vs非参数算法" class="headerlink" title="参数算法vs非参数算法"></a>参数算法vs非参数算法</h3><p>引用<a href="https://zhuanlan.zhihu.com/p/26012348">地址</a></p>
<blockquote>
<p>参数算法：<br>如果我们对所要学习的问题有足够的认识，具备一定的先验知识，此时我们一般会假定要学习的目标函数f(x)或分布P(y|x)的具体形式。然后，通过训练数据集，基于ERM、SRM、MLE、MAP等学习策略，可以估计出f(x)或P(y|x)中含有的未知参数。一旦未知参数估计完毕，训练数据一般来说，就失去其作用了，因为这些估计出来的参数就是训练数据的浓缩。通过这种方式建立起来的模型就是参数模型。参数模型的一个很重要的特点是，如果对于模型的假设正确，那么只需要很少的训练数据就可以从假设空间中学出一个很好的模型。但是，如果模型的假设错误，那么无论训练的数据量有多大，甚至趋于无穷大，学出的模型都会与实际模型出现不可磨灭的偏差。感知机、逻辑斯特回归、高斯判别分析、朴素贝叶斯、线性支持向量机都属于参数模型。对于神经网络来说，当固定了隐层的数目以及每一层神经元的个数，它也属于参数模型。但由于隐层数目与每一层神经元个数的不确定性，很多时候，神经网络都被归类为半参数模型。<br>非参数算法：<br>当我们对所要学习的问题知之甚少，此时我们一般不会对潜在的模型做过多的假设。在面对预测任务的时候，我们通常会用上所有的训练数据。例如简单的核密度估计(KDE)的表达式中，就带有所有训练数据的信息。通过这种方式建立的模型就是非参数模型。非参数模型的一个很重要的特点就是：let the data speak for itself. 正因为如此，非参数模型的存储开销、计算开销都会比参数模型大的多。但是，由于不存在模型的错误假定问题，可以证明，当训练数据量趋于无穷大的时候，非参数模型可以逼近任意复杂的真实模型。这正是非参数模型诱人的一点。另外需要说明的一点是，非参数模型之所以叫做非参数，并不是因为模型中没有参数。实际上，非参数模型中一般会含有一个或多个超参数，外加无穷多个普通的参数。k近邻就是典型的非参数模型。</p>
</blockquote>
<p>总结就是所谓参数学习算法它有固定的明确的参数，参数 一旦确定，就不会改变了，我们不需要在保留训练集中的训练样本。而非参数学习算法，每进行一次预测，就需要重新学习一组 ， 是变化的，所以需要一直保留训练样本。</p>
<h3 id="实际使用"><a href="#实际使用" class="headerlink" title="实际使用"></a>实际使用</h3><p>这里采用的数据跟线性回归算法采用的相同。选取不同的k值，得到的拟合曲线如下图：<br><img src="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E5%B1%80%E9%83%A8%E5%8A%A0%E6%9D%83%E5%9B%9E%E5%BD%92%E6%8B%9F%E5%90%88.png" class="" title="不同k值对于拟合曲线的影响"><br>从图中可以看到，当k值较小时，对于训练数据有很好的拟合效果；当k值较大时(比如取1)，对于训练数据拟合的效果不是很好。当然这都是针对训练数据，在实际使用中，我们更关注的是对于测试数据的效果如何。在实际中，我们可以将数据进行十倍交叉验证，选择最合适的k值。<br>从高斯公式中，我们从两个方面看。首先，我们固定k值，那么距离$x^{(i)}$较远的样本，其对应的权重相对较小；距离$x^{(i)}$较近的样本，其对应的权重相对较大，当x取$x^{(i)}$时，对应的权重为1。而如果我们固定x(即只看某一特定样本点)，k取值较大时，此样本点对应的权重相对较大；k取值较小时，此样本点对应的权重相对较大。所以k可以控制算法选择$x^{(i)}$点附近有多少样本参与计算。<br><img src="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/k%E5%80%BC%E7%9A%84%E5%BD%B1%E5%93%8D.PNG" class="" title="k值的影响"><br>最上面的图是样本点，剩下三幅图都是针对样本点x=0.5,根据不同的k值，画出的x附近样本的权重变化。可以看到，当k取0.5时，当计算x=0.5时的预测值时，几乎所有的样本点都包括了；而当k=0.01时，仅仅取了x=0.5附近的点参与计算。如果k值取无穷大，那么w对于所有的点的权重都是1，那么局部加权线性回归就变成了普通的线性回归算法。</p>
<h2 id="岭回归算法-Ridge-Regression"><a href="#岭回归算法-Ridge-Regression" class="headerlink" title="岭回归算法(Ridge Regression)"></a>岭回归算法(Ridge Regression)</h2><p>上面介绍的线性回归算法里面可以看到需要计算$X^TX$的逆，那么如果逆不存在呢？首先思考第一个问题，什么情况下，$X^TX$的逆不存在呢？</p>
<ol>
<li>X本身存在相关关系，即非满秩矩阵。比如其中两列是具有线性关系</li>
<li>如果特征列多余样本数量，那么$X^TX$也是非满秩的。</li>
</ol>
<p>对于逆不存在的情况下，我们需要将原来的线性回归算法进行处理，使原先无法求逆的$X^TX$变成非奇异的。可以通过缩减的方式来处理这类问题，比如岭回归算法和LASSO算法。同时由于能够调整算法中权重的大小，能够防止线性回归算法的过拟合问题。</p>
<h3 id="岭回归算法损失函数"><a href="#岭回归算法损失函数" class="headerlink" title="岭回归算法损失函数"></a>岭回归算法损失函数</h3><script type="math/tex; mode=display">f(w) = {\sum\limits_{i=1}^m{(y_i - x_i^Tw})^2} + \lambda{\sum\limits_{i=1}^n{w_i^2}}</script><p>通过改变$\lambda$的值，可以使得算法的方差和偏差之间达到平衡，增加$\lambda$,模型的方差减小而偏差增加。<br>对损失函数求取一阶导数，并另导数等于0，求得权重如下式：</p>
<script type="math/tex; mode=display">\hat{w} = (X^TX + \lambda{I})^{(-1)}X^TY</script><p>在岭回归算法中$\lambda$的选择对于算法有很大的影响。下图展示了不同的$\lambda$的取值对于权重的影响，因为数据有八个特征，所以这里有八个权重。当$\lambda$较小时，权重的值跟采用常规的线性回归差不多；而当$\lambda$较大时，权重的值都会被调解的较小。<br><img src="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/%E5%B2%AD%E5%9B%9E%E5%BD%92.png" class="" title="lambda值与权重的关系"><br>为了找到合适的$\lambda$值，我们在实践中往往会采用交叉测试来找到合适的$\lambda$值。</p>
<h2 id="lasso回归算法-Least-Absolute-Shrinkage-and-Selection-Operator"><a href="#lasso回归算法-Least-Absolute-Shrinkage-and-Selection-Operator" class="headerlink" title="lasso回归算法(Least Absolute Shrinkage and Selection Operator)"></a>lasso回归算法(Least Absolute Shrinkage and Selection Operator)</h2><p>从岭回归算法中，我们可以看到，算法防止过拟合主要是在损失函数中添加惩罚项。在岭回归中，惩罚项如下所示:</p>
<script type="math/tex; mode=display">{\sum\limits_{k=1}^n{w_k^2}} <= \lambda</script><p>而在lasso回归算法中，惩罚项变成下式：</p>
<script type="math/tex; mode=display">{\sum\limits_{k=1}^n{|w_k|}} <= \lambda</script><p>即将权重的平方和小于$\lambda$，替换为权重的绝对值和小于$\lambda$.进行了这个变化后，能够将权重缩小到0，而岭回归中无法将权重值缩小到0，只能接近0.</p>
<h3 id="lasso回归算法损失函数"><a href="#lasso回归算法损失函数" class="headerlink" title="lasso回归算法损失函数"></a>lasso回归算法损失函数</h3><script type="math/tex; mode=display">f(w) = {\sum\limits_{i=1}^m{(y_i - x_i^Tw})^2} + \lambda{\sum\limits_{i=1}^n{|w_i|}}</script><blockquote>
<p>我们也可以结合岭回归算法和lasso的损失函数，构建新的损失函数。这就是弹性网络(ElasticNet)</p>
</blockquote>
<h3 id="逐步向前回归"><a href="#逐步向前回归" class="headerlink" title="逐步向前回归"></a>逐步向前回归</h3><p>LASSO计算复杂度相对较高，本部分稍微介绍一下逐步向前回归，他属于一种贪心算法，给定初始系数向量，然后不断迭代遍历每个系数，增加或减小一个很小的数，看看代价函数是否变小，如果变小就保留，如果变大就舍弃，然后不断迭代直到回归系数达到稳定。代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_stage</span>():</span><br><span class="line">    x_arr, y_arr = load_data_set(<span class="string">&#x27;./data/abalone.txt&#x27;</span>)</span><br><span class="line">    all_w_001 = stage_wise(x_arr, y_arr, <span class="number">0.001</span>, <span class="number">5000</span>)</span><br><span class="line">    <span class="built_in">print</span>(all_w_001)</span><br><span class="line">    all_w_01 = stage_wise(x_arr, y_arr, <span class="number">0.01</span>, <span class="number">200</span>)</span><br><span class="line">    <span class="built_in">print</span>(all_w_01)</span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stage_wise</span>(<span class="params">x_arr, y_arr, eps=<span class="number">0.01</span>, num_iter=<span class="number">100</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    forward stagewise regression算法（前向梯度算法）</span></span><br><span class="line"><span class="string">    是一种近似的 lasso算法</span></span><br><span class="line"><span class="string">    :param x_arr:</span></span><br><span class="line"><span class="string">    :param y_arr:</span></span><br><span class="line"><span class="string">    :param eps:每次特征权重的变化步长</span></span><br><span class="line"><span class="string">    :param num_iter: 迭代次数</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x_mat = np.mat(x_arr)</span><br><span class="line">    y_mat = np.mat(y_arr).T</span><br><span class="line">    y_mean = np.mean(y_mat, <span class="number">0</span>)</span><br><span class="line">    y_mat = y_mat - y_mean</span><br><span class="line">    x_mean = np.mean(x_mat, <span class="number">0</span>)</span><br><span class="line">    x_var = np.var(x_mat, <span class="number">0</span>)</span><br><span class="line">    x_mat = (x_mat - x_mean) / x_var</span><br><span class="line">    m, n = np.shape(x_mat)</span><br><span class="line">    ws = np.zeros((n, <span class="number">1</span>))</span><br><span class="line">    ws_best = ws.copy()</span><br><span class="line">    return_mat = np.zeros((num_iter, n))  <span class="comment"># 保存每次迭代最好的权重值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iter):</span><br><span class="line">        <span class="comment"># print(ws.T)</span></span><br><span class="line">        lowest_error = np.inf</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> sign <span class="keyword">in</span> [-<span class="number">1</span>, <span class="number">1</span>]:</span><br><span class="line">                ws_test = ws.copy()</span><br><span class="line">                ws_test[j] += eps * sign</span><br><span class="line">                y_test = x_mat * ws_test</span><br><span class="line">                rss_err = rss_error(y_mat.A, y_test.A)  <span class="comment"># 将矩阵转为数组</span></span><br><span class="line">                <span class="keyword">if</span> rss_err &lt; lowest_error:</span><br><span class="line">                    lowest_error = rss_err</span><br><span class="line">                    ws_best = ws_test</span><br><span class="line">        ws = ws_best.copy()</span><br><span class="line">        return_mat[i, :] = ws.T</span><br><span class="line">    <span class="keyword">return</span> return_mat</span><br></pre></td></tr></table></figure>
<p>逐步回归算法的主要有点在于他可以帮助人们理解现有的模型并作出改进。当构建了一个模型后，可以运行逐步回归算法找出重要的特征，即使停止那些不重要特征的收集。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面提到的这些线性回归算法，我们应该怎么选择呢？一般来说有一点正则项的表现更好，因此通常你应该避免使用简单的线性回归。岭回归是一个很好的首选项，但是如果你的特征仅有少数是真正有用的，你应该选择Lasso和弹性网络。就像我们讨论的那样，它两能够将无用特征的权重降为零。一般来说，弹性网络的表现要比Lasso好，因为当特征数量比样例的数量大的时候，或者特征之间有很强的相关性时，Lasso可能会表现的不规律。</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ol>
<li>《吴恩达cs229 课程讲义》</li>
<li>《机器学习实战》</li>
<li><a href="https://segmentfault.com/a/1190000015172330">机器学习实战_线性回归&amp;逻辑回归（二）</a></li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>线性回归算法</tag>
        <tag>局部加权回归算法</tag>
        <tag>岭回归算法</tag>
        <tag>lasso回归算法</tag>
      </tags>
  </entry>
  <entry>
    <title>用静态工厂方法替换构造函数</title>
    <url>/%E7%94%A8%E9%9D%99%E6%80%81%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%9B%BF%E6%8D%A2%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0.html</url>
    <content><![CDATA[<p>这是根据effective java中的Item1条目来写的。在写java程序时，我们构造一个实例用的最多的就是调用类的构造函数.如<code>A a = new A()</code>.但是还存在一种方法可以获取类的实例。而且相对于调用类的构造函数有很多好处，那就类的静态工厂函数。比如，在Java中的<code>Boolean.valueOf(boolean b)</code>方法：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Boolean <span class="title function_">valueOf</span><span class="params">(<span class="type">boolean</span> b)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> b ? Boolean.TRUE:Boolean.FALSE;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>静态工厂函数相对于构造函数有优点也有缺点，下面会依次进行说明</p>
<h1 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h1><h2 id="静态工厂函数相对于构造函数有具体的名字"><a href="#静态工厂函数相对于构造函数有具体的名字" class="headerlink" title="静态工厂函数相对于构造函数有具体的名字"></a>静态工厂函数相对于构造函数有具体的名字</h2><p>首先，有具体的名字有什么好处呢？如果有名字，可以让调用者更加清楚此函数的作用。因为构造函数的名字要相同，那如果构造函数做的事情不一样，则只能通过增加或删除构造函数的入参才能表达不同的构造函数。这样子对于调用者会造成负担，调用者必须了解构造函数代码做的事情，才能知道此构造函数的真正目的。而使用静态工厂函数，可以通过合理取函数名称，来表达不同的目的以及区别。</p>
<h2 id="静态工厂函数每次被调用时可以不需要创建新的对象"><a href="#静态工厂函数每次被调用时可以不需要创建新的对象" class="headerlink" title="静态工厂函数每次被调用时可以不需要创建新的对象"></a>静态工厂函数每次被调用时可以不需要创建新的对象</h2><p>一般我们调用构造函数时，都是会返回一个新的对象。但是有时候我们不需要返回新的对象，比如单例模式。</p>
<h2 id="静态工厂函数可以返回静态工厂函数返回类型的子类型"><a href="#静态工厂函数可以返回静态工厂函数返回类型的子类型" class="headerlink" title="静态工厂函数可以返回静态工厂函数返回类型的子类型"></a>静态工厂函数可以返回静态工厂函数返回类型的子类型</h2><p>这个是什么意思呢？比如我们拿java中的Collections的静态工厂方法<code>synchronizedMap</code>为例：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;K,V&gt; Map&lt;K,V&gt; <span class="title function_">synchronizedMap</span><span class="params">(Map&lt;K,V&gt; m)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SynchronizedMap</span>&lt;&gt;(m);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>可以看到函数定义的返回类型是<code>Map</code>，但是实际返回的类型是<code>SynchronizedMap</code>.但是这样做有什么好处呢？<br>这种方式可以隐藏实现类，从而形成一个非常紧凑的API。我们还是以Collections类为例。Collections框架中有45个接口实现工具实现，提供了不可修改集合、同步集合等。这些都是通过Collections提供静态工厂函数来实现，而且返回的子类型都是非公共的。所以Collections框架API比它导出45个独立的公共类要小的多，这样不仅减少了API的数量，同时也减少了框架使用者需要了解的概念。框架使用者不需要了解这45个实现类。同时因为返回的是接口类型，这也是很好的做法。</p>
<h2 id="第四个优点，静态工厂函数返回的类可以根据输入参数来改变"><a href="#第四个优点，静态工厂函数返回的类可以根据输入参数来改变" class="headerlink" title="第四个优点，静态工厂函数返回的类可以根据输入参数来改变"></a>第四个优点，静态工厂函数返回的类可以根据输入参数来改变</h2><p>静态工厂方法返回的类可以根据版本而改变。Java中的<code>EnumSet</code>类没有公共构造函数，只有静态工厂方法。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;E <span class="keyword">extends</span> <span class="title class_">Enum</span>&lt;E&gt;&gt; EnumSet&lt;E&gt; <span class="title function_">noneOf</span><span class="params">(Class&lt;E&gt; elementType)</span> &#123;</span><br><span class="line">        Enum&lt;?&gt;[] universe = getUniverse(elementType);</span><br><span class="line">        <span class="keyword">if</span> (universe == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">ClassCastException</span>(elementType + <span class="string">&quot; not an enum&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (universe.length &lt;= <span class="number">64</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RegularEnumSet</span>&lt;&gt;(elementType, universe);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">JumboEnumSet</span>&lt;&gt;(elementType, universe);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><br>通过代码我们可以看出，noneOf返回两个子类中的一个实例，这取决于底层enum类型的大小。如果有64个或更少的元素，那么返回一个long类型的RegularEnumSet实例；如果enum类型有65或更多的元素，方法将返回一个long[]类型的JumboEnumSet实例。<br>客户端感知不到这两个实现类的存在。如果 RegularEnumSet 不再为小型 enum 类型提供性能优势，它可能会在未来的版本中被消除，而不会产生不良影响。类似地，如果事实证明 EnumSet 有益于性能，未来的版本可以添加第三或第四个 EnumSet 实现。客户端既不知道也不关心从工厂返回的对象的类；它们只关心它是 EnumSet 的某个子类。</p>
<h2 id="第五个优点，编写包含静态工厂函数的类时，此静态工厂函数返回对象所属的类可以不存在"><a href="#第五个优点，编写包含静态工厂函数的类时，此静态工厂函数返回对象所属的类可以不存在" class="headerlink" title="第五个优点，编写包含静态工厂函数的类时，此静态工厂函数返回对象所属的类可以不存在"></a>第五个优点，编写包含静态工厂函数的类时，此静态工厂函数返回对象所属的类可以不存在</h2><p>上面这句话，听起来有点难以理解。这里做个例子进行说明，比如我们正在编写类A，其中包含factory1 静态工厂函数，factory1函数的定义返回类型是接口 Interface1，而实际</p>
<p><strong>这一点暂时没有理解</strong></p>
<h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><h2 id="第一个缺点，类如果没有公有或者受保护的构造器，那么此类就不能被继承。"><a href="#第一个缺点，类如果没有公有或者受保护的构造器，那么此类就不能被继承。" class="headerlink" title="第一个缺点，类如果没有公有或者受保护的构造器，那么此类就不能被继承。"></a>第一个缺点，类如果没有公有或者受保护的构造器，那么此类就不能被继承。</h2><p>例如，我们不能继承Collection框架中的任何类</p>
<h2 id="第二个缺点，我们不太容易在类文档中找到静态工厂函数"><a href="#第二个缺点，我们不太容易在类文档中找到静态工厂函数" class="headerlink" title="第二个缺点，我们不太容易在类文档中找到静态工厂函数"></a>第二个缺点，我们不太容易在类文档中找到静态工厂函数</h2><p>因为Javadoc 工具不能明确的标注静态工厂函数，所以在文档中静态工厂函数就不会突出显示。而构造函数在文档中会突出显示。我们也可以遵守一些给静态工厂函数起名的规范，下面是一些建议：</p>
<ol>
<li>from: 将输入转为与之对应的相关类,接受一个参数，然后返回对应的类实例<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Date</span> <span class="variable">d</span> <span class="operator">=</span> Date.from(instant);</span><br></pre></td></tr></table></figure></li>
<li>of：接受多个参数，返回包含多个参数的类实例<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Set&lt;Rank&gt; faceCards = EnumSet.of(JACK, QUEEN, KING);</span><br></pre></td></tr></table></figure></li>
<li>valueOf: 介于from和of之间<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">BigInteger</span> <span class="variable">prime</span> <span class="operator">=</span> BigInteger.valueOf(Integer.MAX_VALUE);</span><br></pre></td></tr></table></figure></li>
<li>instance 或者getInstance：返回参数对应的类实例，但是值有可能会改变<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">StackWalker</span> <span class="variable">luke</span> <span class="operator">=</span> StackWalker.getInstance(options);</span><br></pre></td></tr></table></figure></li>
<li>create 或者 newInstance: 类似于instance或getInstance，但是每次调用都会返回一个新的实例<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">newArray</span> <span class="operator">=</span> Array.newIntance(classObject, arrayLen);</span><br></pre></td></tr></table></figure></li>
<li>getType: 类似getInstance,获取实例，但是静态工厂函数在另一个类中。Type表面返回实例的类型<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">FileStore</span> <span class="variable">fs</span> <span class="operator">=</span> Files.getFileStore(path);</span><br></pre></td></tr></table></figure></li>
<li>newType: 类似newInstance，但是静态工厂函数在另一个类中<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">BufferedReader</span> <span class="variable">br</span> <span class="operator">=</span> Files.newBufferedReader(path);</span><br></pre></td></tr></table></figure></li>
<li>type: 一种精确的转换<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Complaint&gt; litany = Collections.list(legacyLitany);</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>构造器和静态工厂函数有各自的优点和缺点，但是一般来说，静态工厂函数要比构造器好。在平常的编程过程中，我们不要一上来就直接写构造函数，可以先考虑一下，用静态工厂函数是不是更好。</p>
]]></content>
      <categories>
        <category>effective java</category>
      </categories>
  </entry>
  <entry>
    <title>读过的书</title>
    <url>/%E8%AF%BB%E8%BF%87%E7%9A%84%E4%B9%A6.html</url>
    <content><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>本篇主要记录自己看过的书,督促自己平时多多的读书啊!</p>
<h2 id="《假如我有时光机》-村上春树"><a href="#《假如我有时光机》-村上春树" class="headerlink" title="《假如我有时光机》-村上春树"></a>《假如我有时光机》-村上春树</h2><p><strong>2018-11-26</strong><br>这本书是村上春树写的,主要描写了作者在全球旅游去过的国家和城市。这是我第一次读村上春树的书，整本书看起来还是比较吸人眼球的，同时本书篇幅也不是很长。从作者的文笔中，可以感受到作者是一个待人应该很和善，同时也非常有礼貌的一个作者。通过阅读此书，不单单能够感受到作者去过的地方，也能够感受到别人在旅行中收到的感受。对于自己也是一种心理上面的成长。书中第一章写到了美国波士顿，特别是里面的查尔斯河，读完之后，有很强烈的冲动去美国玩了。应该是最近两三年的计划中。</p>
<h2 id="《局外人》-加缪"><a href="#《局外人》-加缪" class="headerlink" title="《局外人》 -加缪"></a>《局外人》 -加缪</h2><p><strong>2018-11-27~2018-12-4</strong><br>这本书主要讲述了一个杀了人的罪犯，最后被判处死刑的故事。判处死刑的原因并不是因为他杀了一个人，而是因为他在母亲的葬礼上面没有哭，还有在服丧期间干了一些在社会上认为不应该做的事情。比如看滑稽电影，跟女友做爱以及主人公不信上帝等。这些与社会上不同的事情竟然导致法官判处主角死刑。我们跳脱出来来看整个事情，会发现整个法律在执行的过程中，会强烈的加上社会倾向，即社会上认为你这个人格格不入，会导致你在法律上处于一个非常不利的地步。这本书最震撼我的事书的最后，主角主动放弃了上诉的机会，面对自己的死亡。如果人人都说你做错了，那么到底是你真的做错了，还是这个世界错了呢？</p>
<h2 id="《逻辑学导论》-欧文·M·柯丕-卡尔·科恩"><a href="#《逻辑学导论》-欧文·M·柯丕-卡尔·科恩" class="headerlink" title="《逻辑学导论》 -欧文·M·柯丕, 卡尔·科恩"></a>《逻辑学导论》 -欧文·M·柯丕, 卡尔·科恩</h2><p><strong>2018-12-5~</strong></p>
<h2 id="《高效人士的七个习惯》"><a href="#《高效人士的七个习惯》" class="headerlink" title="《高效人士的七个习惯》"></a>《高效人士的七个习惯》</h2><p><strong>2018-12-29~</strong></p>
]]></content>
      <categories>
        <category>书</category>
      </categories>
  </entry>
  <entry>
    <title>&#39;编写可读代码的艺术&#39;读书笔记</title>
    <url>/%E7%BC%96%E5%86%99%E5%8F%AF%E8%AF%BB%E4%BB%A3%E7%A0%81%E7%9A%84%E8%89%BA%E6%9C%AF-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0.html</url>
    <content><![CDATA[<blockquote>
<p>最近读了《the art of readable code》这本书，书的内容是叫你如何写出可读性高的代码。觉得里面的很多例子和观点有很大的参考价值，所以在这篇博客中记录下来。</p>
</blockquote>
<p>书中有个很强的观点，代码是给人看的，不是给机器看的。所以写代码要将可读性放到第一位。写代码时要时刻考虑这段代码别人是不是容易阅读。<br>全书分为四部分，分别为：</p>
<ul>
<li>代码外观上的改进</li>
<li>简化循环和代码逻辑</li>
<li>重新组织代码</li>
<li>单元测试可读性</li>
</ul>
<h2 id="代码外观上的改进"><a href="#代码外观上的改进" class="headerlink" title="代码外观上的改进"></a>代码外观上的改进</h2><p>这一部分主要是从变量命名、函数命名、注释等方面介绍如何提升代码可读性。</p>
<h3 id="命名和注释"><a href="#命名和注释" class="headerlink" title="命名和注释"></a>命名和注释</h3><p>“代码中最困难的两件事情，是命名和缓存失效”。可见命名的困难性。在选择名称时，我们遵循如下原则：</p>
<ul>
<li><strong>选择能够准确表达代码意图的名称</strong><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">// GetPage函数不能表示page从哪里获取。推荐使用FetchPage和DownloadPage进行替换。</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">GetPage</span>(<span class="params">url</span>):</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
下面展示了英文中单词对应的同义词</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>单词</th>
<th>同义词</th>
</tr>
</thead>
<tbody>
<tr>
<td>send</td>
<td>deliver，dispatch，announce，distribute，route</td>
</tr>
<tr>
<td>find</td>
<td>search，extract，locate，recover</td>
</tr>
<tr>
<td>start</td>
<td>launch，create，begin，open</td>
</tr>
<tr>
<td>make</td>
<td>add, push, enqueue</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>避免使用泛化的名称，比如tmp、retval之类的东西。<br>但在一些特殊情况下可以使用，比如循环、交换两个数时的临时变量中</li>
<li>名称中附带额外信息<br>下面展示了一些具体的例子</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>函数参数</th>
<th>推荐重构后的内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>Start(int delay)</td>
<td>delay -&gt; delay_secs</td>
</tr>
<tr>
<td>CreateCache(int size)</td>
<td>size -&gt; size_mb</td>
</tr>
<tr>
<td>ThrottleDownload(float limit)</td>
<td>limit -M max_kbps</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p>根据变量的作用域选择合适的名称<br><strong>变量的作用域如果比较长，则变量名称尽量多携带信息；变量作用域如果比较短，则变量名称推荐用简单的、简短的。</strong></p>
</li>
<li><p>英文中一些推荐变量命名做法</p>
<ul>
<li>使用min和max表示下限和上限(包含)</li>
<li>使用first和last表示范围，其中last包含最后一个数</li>
<li>使用begin和end表示范围，其中end是最后一个数的下一个数</li>
</ul>
</li>
<li>布尔命名中避免携带否定词<br>disable_ssl就没有use_ssl 好</li>
<li>代码需要有段落</li>
<li>如果代码表达的意思已经很明确了，那么没有必要添加注释</li>
</ul>
<h2 id="简化循环和代码逻辑"><a href="#简化循环和代码逻辑" class="headerlink" title="简化循环和代码逻辑"></a>简化循环和代码逻辑</h2><ul>
<li>尽早从函数返回(卫语句使用)</li>
<li>避免使用do-while循环语句</li>
<li>减少代码中的嵌套(比如可以使用提前返回)</li>
<li>代码中的巨大表达式要进行简化</li>
<li>代码中使用的变量越多，程序阅读起来就越困难<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">下面的now完全没有必要，直接用后面的内容替换now就行</span><br><span class="line">now = datetime.datetime.now()</span><br><span class="line">root_message.last_view_time = now</span><br></pre></td></tr></table></figure></li>
<li>尽量降低变量的作用域。(全局变量越少越好，其实就是降低耦合度)</li>
<li>变量应该在需要的时候进行定义，而不是在函数的开头就定义当前函数中需要的所有变量</li>
<li>变量改变的越多，追踪变量的当前值就越困难(尽量使用只写一次的变量，比如java中的final，go中的const等)</li>
</ul>
<h2 id="重新组织代码"><a href="#重新组织代码" class="headerlink" title="重新组织代码"></a>重新组织代码</h2><ul>
<li>首先用自然语言描述代码需要完成的功能，然后在进行实现；这个方法在重构代码时也非常有用。</li>
<li>尽量创建通用的代码，与项目无关的代码尽量放到独立的模块中，比如util模块中。</li>
<li>代码应该只做一件事情(do only one task at a time)；借鉴：unix哲学中，一个函数只做一件事。</li>
<li>对于用到的语言，第三方库要尽量掌握，并熟悉常用的函数。</li>
</ul>
<h2 id="单元测试可读性"><a href="#单元测试可读性" class="headerlink" title="单元测试可读性"></a>单元测试可读性</h2><ul>
<li>测试代码提高可读性要遵循一个原则是：对用户隐藏不重要的细节，将重要的细节进行展示。</li>
<li>测试的输入内容应该是完全覆盖被测代码，并且在满足这一前提下是最简单的</li>
<li>好的代码是更加容易测试的</li>
<li>在测试代码中，可以使用帮助函数来简化测试代码。</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>读过的技术书籍</title>
    <url>/%E8%AF%BB%E8%BF%87%E7%9A%84%E6%8A%80%E6%9C%AF%E4%B9%A6%E7%B1%8D.html</url>
    <content><![CDATA[<h1 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h1><p>都说书籍是人类进步的阶梯,现在这篇博客就是记录下我个人梯子的组成,主要是技术相关的.隔一段时间会更新一次,因为梯子一直在增长,哈哈.</p>
<h2 id="Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow"><a href="#Hands-On-Machine-Learning-with-Scikit-Learn-and-TensorFlow" class="headerlink" title="Hands-On Machine Learning with Scikit-Learn and TensorFlow"></a>Hands-On Machine Learning with Scikit-Learn and TensorFlow</h2><p>这本书主要是通过scikit-learn工具包来讲解如何使用常用的机器学习算法以及机器学习算法在平常的工作中的应用流程.深度学习主要是通过tensorflow来进行讲解.</p>
<h2 id="Andrew-Ng-斯坦福-cs229机器学习讲义"><a href="#Andrew-Ng-斯坦福-cs229机器学习讲义" class="headerlink" title="Andrew Ng 斯坦福 cs229机器学习讲义"></a>Andrew Ng 斯坦福 cs229机器学习讲义</h2><p>想要入门机器学习的同学,强烈建议学一学Andrew Ng的这么课,最好把里面的数学公式都自己推一遍,我自己推完这些数学公式之后,对于机器学习算法中原理有了很清晰的认识.</p>
<h2 id="《mysql必知必会》"><a href="#《mysql必知必会》" class="headerlink" title="《mysql必知必会》"></a>《mysql必知必会》</h2><p>阅读时间：2019-4-7~2019-4-9<br>感想：这几天看完了mysql必知必会，其实基本上mysql的语法都会，只是为了能够看看还有什么地方自己不太知道的。总体来说，这本书对于初学者比较适合，按着里面的内容手敲一遍例子。掌握mysql的使用是没有问题的。</p>
<h2 id="《图解tcp-ip-第五版》"><a href="#《图解tcp-ip-第五版》" class="headerlink" title="《图解tcp-ip 第五版》"></a>《图解tcp-ip 第五版》</h2><p>阅读时间：2019-4-9<br>感想：</p>
<h2 id="《effective-java-第三版》-英文"><a href="#《effective-java-第三版》-英文" class="headerlink" title="《effective java 第三版》 英文"></a>《effective java 第三版》 英文</h2><p>阅读时间：2019-4-10<br>感想：</p>
]]></content>
      <categories>
        <category>书</category>
      </categories>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>集成算法</title>
    <url>/%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>运行kubectl run会发生什么(what happens when i type kubectl run)</title>
    <url>/%E8%BF%90%E8%A1%8Ckubectl-run%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88-what-happens-when-i-type-kubectl-run.html</url>
    <content><![CDATA[<blockquote>
<p>原文链接：<a href="https://github.com/jamiehannaford/what-happens-when-k8s">https://github.com/jamiehannaford/what-happens-when-k8s</a></p>
<p>想像一下当你运行下面的命令时<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl create deployment nginx --image=nginx --replica=3</span><br></pre></td></tr></table></figure><br>在一切顺利的情况下，在k8s集群中能够看到生成了3个pod。那么在底层到底发生了什么？本篇文章试图解决一个请求从客户端到kubelet整体的流程，并且也链接了源码。</p>
</blockquote>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li>kubectl<ul>
<li>Validation and generators(验证和生成)</li>
<li>API groups and version negotiation(API组和版本协商)</li>
<li>Client auth(客户端认证)</li>
</ul>
</li>
<li>kube-apiserver<ul>
<li>Authentication（认证）</li>
<li>Authorization（鉴权）</li>
<li>Admission control（admission控制）</li>
</ul>
</li>
<li>etcd</li>
<li>Initializers</li>
<li>Control loops<ul>
<li>Deployments controller</li>
<li>ReplicaSet controller</li>
<li>Informers</li>
<li>Scheduler</li>
</ul>
</li>
<li>kubelet<ul>
<li>Pod sync</li>
<li>CRI and pause containers</li>
<li>CNI and pod networking</li>
<li>Inter-host networking</li>
<li>Container startup</li>
</ul>
</li>
<li>Wrap-up（总结）</li>
</ol>
<h2 id="kubectl"><a href="#kubectl" class="headerlink" title="kubectl"></a>kubectl</h2><h3 id="Validation-and-generators"><a href="#Validation-and-generators" class="headerlink" title="Validation and generators"></a>Validation and generators</h3><p>针对开头提到的命令，在命令行输入回车后，会发生什么呢？<br>kubectl首先会进行客户端侧的验证。针对非法的命令(比如不支持的资源或镜像不合法)能够快速失败提示，避免发送到kube-apiserver，从而降低k8s负载。<br>经过验证后，kubectl组装将要发送到api-server的http请求。在k8s中，获取或者改变k8s中的状态都要通过apiserver，apiserver负责与etcd交互。kubectl使用generators来构建http请求，generators是负责序列化的一种抽象（注：可以简单的把generators理解为帮帮助用户构建完成的资源的工具，比如kubectl create中我们只指定了部分的内容，剩下的内容是generators帮助我们生成的）。<br>kubectl run 命令可以通过使用—generator参数指定运行多种资源，而不仅仅是deployments。如果不使用—generator参数，kubectl可以主动推断要运行的资源。<br>例如，参数<code>--restart-policy=Always</code>会触发deployments，而<code>--restrart-policy=Never</code>会触发pods。kubectl也会根据其他的参数确定需要执行的其他动作。比如记录命令(回滚或审计)，或者<code>--dry-run</code><br>在确定要创建的资源是Deployment后，kubectl将会使用<code>DeploymnetAppsV1</code> generator来根据命令行参数构造runtime object。runtime object是k8s resource的通用表示。</p>
<h3 id="API-groups-and-version-negotiation"><a href="#API-groups-and-version-negotiation" class="headerlink" title="API groups and version negotiation"></a>API groups and version negotiation</h3><p>k8s使用版本API，并且每个版本有自己所属的API groups。API groups意味着一些相似资源的集合。这比使用单调递增的版本号更加灵活。比如deployment的api group是apps，最近的版本是v1。这也是在deployment中写<code>apiVersion: apps/v1</code>的原因。<br>kubectl生成了runtime object后，kubectl开始找到正确的API group和version，并且会组装versioned client。versioned client能够意识到资源的各种REST 语义。这个阶段被称为版本协商，它涉及kubectl扫描远程API上的/apis路径，从而检索所有可能的API组。由于kube-apiserver在此路径上公开了其模式文档(以OpenAPI格式),因此客户端可以很容易执行自己的发现。<br>为了提高性能，kubectl会将OpenAPI schema缓存到 ~/.kube/cache/discovery 目录中。如果想要看到API 发现的过程，那么可以将这个缓存目录删除，然后运行kubectl命令时带上-v参数。你将会看到查询API versions的所有http请求。<br>kubectl最后一步是发送http请求。一旦接收到成功的响应后，那么kubectl就会按照期望的格式打印结果。</p>
<h3 id="Client-auth"><a href="#Client-auth" class="headerlink" title="Client auth"></a>Client auth</h3><p>为了成功发送请求，kubectl需要能够处理认证信息。用户的凭证一般存储在<code>kubeconfig</code>文件中，但是有时候也在其他地方。kubectl做了下面的事情来决定用户凭证：</p>
<ul>
<li>如果kubectl中使用了<code>--kubeconfig</code>，那么就使用这个参数指定的文件</li>
<li>如果当前环境变量中定义了<code>$KUBECONFIG</code>，那么使用这个环境变量指定的文件</li>
<li>否则使用推荐的主目录，比如<code>~/.kube</code>,然后使用此目录中的第一个文件<br>当kubectl解析了凭证文件后，kubectl会决定当前需要使用的上下文，当前需要连接的集群，与当前用户关联的认证信息。如果kubectl中提供了指定的参数，比如<code>--username</code>, 那么这些参数将会覆盖凭证文件的配置。一旦有了这些信息，那么kubectl将会用这些信息去修饰http请求：</li>
<li>使用tls.TLSConfig来发送x509证书</li>
<li>bearer token放到http header中的”Authorization”</li>
<li>username 和 password通过http basic authentication发送</li>
<li>OpenID认证流程是由用户事先手动处理的，生成一个类似于Bearer令牌的token，然后发送。</li>
</ul>
<h2 id="kube-apiserver"><a href="#kube-apiserver" class="headerlink" title="kube-apiserver"></a>kube-apiserver</h2><h3 id="Authentication-认证，确定用户是谁"><a href="#Authentication-认证，确定用户是谁" class="headerlink" title="Authentication(认证，确定用户是谁)"></a>Authentication(认证，确定用户是谁)</h3><p>k8s客户端和k8s系统组件与k8s交互主要是通过kube-apiserver来进行，比如获取和存储系统状态。kube-apiserver第一步要做的就是要验证请求的身份信息，这一步叫做认证(authentication).<br>apiserver如何进行认证呢？首先，apiserver在启动时，它会首先检查启动参数，然后组装一系列的认证器(authenticators)。举个例子，比如<code>--client-ca-file</code>传递进来，那么会添加x509认证器；如果提供<code>--token-auth-file</code>，那么会添加token认证器。apiserver收到的每个请求都会经过这些认证器，并且会依次进行认证，直到有一个认证器成功，那么请求就通过了。</p>
<ul>
<li>x509 handler 将会检查请求的证书是否有效，并且是否在指定的ca文件中</li>
<li>bearer token handler 将会检查token(http Authorization header)是否在指定的文件中(由<code>--token-auth-file</code>指定)</li>
<li>basic handler仅仅简单的检查http 请求中的basic 认证信息是否与本地状态匹配<br>如果每个认证器都认证失败了，那么一个组装的错误(每个错误的认证)会返回。如果认证成功，那么在http header中的<code>Authorization</code>会移除，并且用户信息会添加到上下文中。这样后续的apiserver处理逻辑(比如authorization和admission controllers)能够直接获取到用户信息。</li>
</ul>
<h3 id="Authorization-鉴权，确定用户是否有权限"><a href="#Authorization-鉴权，确定用户是否有权限" class="headerlink" title="Authorization(鉴权，确定用户是否有权限)"></a>Authorization(鉴权，确定用户是否有权限)</h3><p>经过认证后，apiserver会进行鉴权检查，确定执行的请求动作是否允许。<br>apiserver处理鉴权跟认证类似。基于启动的参数，apiserver会组装一系列的鉴权器(authorizers), 这些鉴权器会依次检查请求。如果所有的鉴权都没有通过，那么请求会被拒绝并返回给客户端。如果其中某个鉴权器通过，那么请求会继续。<br>下面展示了一些鉴权器：</p>
<ul>
<li>webhook，负责与k8s集群外的http(s) service进行交互的</li>
<li>ABAC，执行定义在static文件中的鉴权策略</li>
<li>RBAC，采用RBAC角色来进行鉴权</li>
<li>Node，确保node clients(比如kubelet)只能够访问托管到自身上的k8s资源。<h3 id="Admission-control"><a href="#Admission-control" class="headerlink" title="Admission control"></a>Admission control</h3>从apiserver的角度看，它已经确定了请求是谁以及请求是否能够执行。但是对于kubernetes，系统的其他部分对于能够做什么和不能做什么都有自己的想法。这就是admission controller要做的事情。<br>鉴权侧重于用户是否有权限，而admission controllers是用来确保请求符合期望以及遵守集群规则。amission controller是对象存储到etcd之前的最后一个处理，因此它封装了系统剩余的检查以确定请求不会产生意想不到的后果。<br>admission controllers的逻辑与authenticators和authorizers类似，但是不同之处是：不像authenticator和authorizers链式调用，如果一个admission controller失败，那么整个admission chain会失败。<br>amission controllers比较优秀的设计是专注于提升扩展性。每个controller都作为一个插件放置到<code>plugin/pkg/admission</code>目录下，每个controller都满足一个比较小的接口定义。然后编译到k8s中。<br>admission controllers通常分为这几类，资源管理、安全性、默认设置和引用一致性。下面列出了专注于资源管理的admission controller：</li>
<li>InitialResources：根据过去资源使用情况，设置默认的资源限制</li>
<li>LimitRanger：设置容器资源的request和limit或者为资源设置资源上界。</li>
<li>ResourceQuota：确保集群中资源使用量不会超过配额</li>
</ul>
<h2 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h2><p>apiserver验证了请求后，下一步apiserver反序列化http请求，从http请求中构建runtime objects(类似于kubectl generators的反过程)，然后将objects存储到底层存储中。将这个过程细化如下。<br>首先，apiserver在接受到请求后是怎么知道如何处理呢？这个过程比较复杂。我们首先看下apiserver在启动时都会做什么：</p>
<ol>
<li>当前apiserver启动时，它会创建server chain，是一个组合的调用链。基本上是由多个apiserver组成的。</li>
<li>server chain中有个通用的apiserver，是一个默认的实现</li>
<li>openAPI schema会填充到apiserver的配置中</li>
<li>apiserver遍历所有在openAPI schema中定义的api groups，然后为每个api group都配置一个storage provider，这些storage provider是一个通用的存储抽象。apiserver主要通过与这些storage provider交互来存储和检索数据。</li>
<li>在每个api group中，apiserver会遍历所有的版本，然后为每个http 路径配置rest mapping。这样apiserver就能够将收到的外部请求与对应的处理逻辑关联起来</li>
<li>针对我们上面的例子，apiserver已经注册了post handler。这个handler被委托用来创建资源<br>到这里，apiserver已经知道有哪些http route存在，并且如何将handler跟route进行映射。让我们现在看下http 请求进来后的处理</li>
<li>如果请求跟某个特定的route匹配上，那么就会交给对应的handler进行处理。如果没有匹配上，那么会采用基于url 路径的方式进行匹配。如果针对这个路径也没有匹配上，那么一个not found handler会被调用，然后返回404错误。</li>
<li>针对我们的例子，有一个注册的路由会调用createHandler方法。它首先解码http请求，执行基础的验证。比如确保http提供的json格式复合对应的版本资源。</li>
<li>触发审计以及最后的admission</li>
<li>专用的storage provider将资源存储到etcd中。etcd中资源的key通常是<code>&lt;namespace&gt;/&lt;name&gt;</code>，但是这个格式是可以配置的</li>
<li>创建中的任何错误都会被捕获，最后storage provider会执行get请求来确保资源一定是创建成功的。如果需要，还会调用而外的后处理逻辑。</li>
<li>构造http 响应并返回<br>通过上面的步骤，我们知道apiserver做了很多的步骤。当前deployment已经成功的在etcd中创建了。但是当前deployment还没有被调度<h2 id="Initializers"><a href="#Initializers" class="headerlink" title="Initializers"></a>Initializers</h2>在object存储到etcd之后，apiserver或者调度器并不能立马看到它。直到一系列的initializers执行完毕后，才会看到这个对象。初始化控制器将资源类型和要执行的逻辑进行关联。如果一个资源没有注册初始化控制器，那么初始化阶段会调用，这个资源立马会被apiserver或调度器看到。<br>初始化控制器给我们提供了扩展k8s的能力，比如：</li>
</ol>
<ul>
<li>给pod注入代理sidecar 容器，或者获取特定的注解</li>
<li>向特定的命名空间下的pod注入证书</li>
<li>阻止创建小于20个字符的secret小于<br><code>initializerConfiguration</code>允许你声明哪些资源运行哪些initializers。假设我们想要一个在每个pod创建时都运行的initializer，我们的配置如下：<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">admissionregistration.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">InitializerConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">   <span class="attr">name:</span> <span class="string">custom-pod-initializer</span></span><br><span class="line"><span class="attr">initializers:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">podimage.example.com</span></span><br><span class="line">     <span class="attr">rules:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">         <span class="attr">apiVersions:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">v1</span></span><br><span class="line">         <span class="attr">resources:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">pods</span></span><br></pre></td></tr></table></figure>
上面的InitializerConfiguration会给每个pod的<code>metadata.initializers.pending</code>字段添加<code>podimage.example.com</code>。initializer controller已经提前部署好，initializer会扫描每个新建的pod。当发现pod的<code>metadata.initializers.pending</code>字段不为空时，initializer controller就会执行。执行完后，会将对应的<code>podimage.example.com</code>删除。当所有的初始化器执行完毕并且<code>pending</code>字段为空，则此对象被认为已经初始化完成。<br>可能你已经发现一个问题，如果资源对于apiserver不可见，那么我们这里的初始化控制器怎么处理呢？apiserver暴露了一个<code>includeUninitialized</code>查询参数来返回所有的对象，包括那些还未初始化的对象。</li>
</ul>
<h2 id="Control-loops"><a href="#Control-loops" class="headerlink" title="Control loops"></a>Control loops</h2><h3 id="Deployments-controller"><a href="#Deployments-controller" class="headerlink" title="Deployments controller"></a>Deployments controller</h3><p>到现在这个阶段，deployment已经存储到etcd中并且初始化逻辑已经完成了。接下来就要设置资源拓扑。deployment就是replicasets的集合，而replicaSet就是pod的集合。k8s如何从http 请求中去创建这些对象呢？这就是k8s内置controller需要做的内容。<br>k8s在整个系统中大量使用了”控制器”思想。控制器就是一个异步过程，调谐k8s当前的状态到期望状态。每个控制器有自己的职责，并且由<code>kube-controller-manager</code>组件负责并发运行。下面介绍deployment controller<br>在 deployment存储到etcd并且初始化完成后，那么deployment就能够被kube-apiserver看到。deployment controller能够检测到可用的deployment资源以及对于资源的变更。在我们的例子中，deployment controller通过informer为创建事件注册了一个特定的回调。<br>当deployment可用时，handler开始执行，将对象添加到内部的工作队列中。当开始处理这个对象时，控制器会检查deployment，发现deployment没有关联的ReplicaSet或者Pod记录。这是通过使用标签选择器来查询kube-apiserver来完成的。有趣的是，这个同步过程是状态未知的：调谐新的记录跟调谐旧的记录是一样的工作方式。<br>在意识到相关的ReplcaSet和Pod不存在后，deployment controller会开启scaling process来解析状态。创建一个ReplicaSet资源，给它分配标签选择器，然后给定数字1的版本号。ReplicaSet中的PodSpec是从deployment清单中拷贝而来，类似于其他相关的元数据。有些时候，deployment记录在这个过程后也需要对应的更新(比如，设定了截止日期)<br>更新deployment中的status字段，然后控制器重新进行调谐过程，然后等待deployment达到期望的状态。由于deployment controller仅仅关心创建ReplicaSets,接下来的工作需要由下一个控制器来完成，既ReplicaSet controller。</p>
<h3 id="ReplicaSet-controller"><a href="#ReplicaSet-controller" class="headerlink" title="ReplicaSet controller"></a>ReplicaSet controller</h3><p>在前面的步骤中，Deployments controller创建了ReplicaSet,但是还没有创建Pods。这就是ReplicaSet 控制器发挥作用的时刻。ReplicaSet controller的主要工作就是监视ReplicaSet的生命周期和对应的Pods资源。类似于大多数其他的控制器，它通过在特定事件上触发handler来实现。<br>我们感兴趣的事件是创建。当ReplicaSet被创建后。ReplicaSet controller检查新的replicaSet的状态，然后发现当前的状态跟期望的状态不一致。它试图通过增加属于ReplicaSet的Pod数量来达到目标状态。它以谨慎的方式来创建它们，确保ReplicaSet的数量始终匹配。<br>创建Pods的过程是批量处理的，以<code>SlowStartInitiaBatchSize</code>开始，然后每次都以两倍的数量来启动其他的Pods。这样做的目的是确保当pod创建失败时，避免大量的http 请求到apiserver。如果要失败，可以采用对组件影响最小的方式来进行。<br>k8s通过Owner References(child资源中的一个字段，用来指向父资源的id)来确保对象的引用关系。这样做，不仅能够确保一旦父资源被删除，子资源也会被删除(级联删除)，同时还能够保证父资源不会竞争子资源(想象一下，两个潜在的父资源认为他们拥有同样的子资源)<br>Owner Reference另一个好处是，它是有状态的。如果控制器重启了，那么重启过程中，不会影响到这些资源，因为资源拓扑是独立于controler的。这种对隔离的关注也渗透到控制器本身的设计中：它们不应该操作它们没有明确拥有的资源。相反，控制器应该只操作它们明确拥有的资源。<br>然而，有时候会存在”孤儿”资源，比如下面这些情况：</p>
<ol>
<li>父资源删除，但是子资源没有删除</li>
<li>垃圾回收策略禁止删除子资源<br>如果发生了这种情况，那么控制器会确保这些“孤儿”资源被新的父资源领养。多个父资源能够竞争性的去领养孤儿资源，但是只有一个能够成功。<h3 id="Informers"><a href="#Informers" class="headerlink" title="Informers"></a>Informers</h3>rbac authorizer 或者 deployment controller需要获取集群状态，从而实现相关逻辑。比如以rbac authorizer为例，当请求进入时，authenticator需要将用户的初始状态保存起来以供后续使用。rbac authorizer后续会使用用户的初始表示来获取在etcd中相关的角色和角色绑定关系。控制器应该如何访问和修改这些资源？k8s中提供了informers来实现。<br>informer是一种模式，既允许控制器订阅存储时间以及查询资源列表。informer除了提供一种抽象外，它还封装了大量的工作，比如缓存(缓存很重要，不仅可以减少apiserver连接数，同时还可以较少服务端和客户端的序列化)。informer还提供了线程安全的方式来操作资源。<h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3>在所有的控制器都运行后，当前在etcd中会存在一个deployment，一个ReplicaSet以及三个pod资源。此时，pod的状态是<code>Pending</code>,因为它们还没有被调度。最后的一个控制器是scheduler，它负责调度pod。<br>scheduler是作为控制面的一个标准组件，它的运行机制跟其他的控制器类似。它监听事件，然后尝试将状态调整到期望状态。在这个例子中，调调度器筛选出<code>NodeName</code>为空的pod，然后尝试将它们调度到合适的节点上。<br>为了找到合适的节点，scheduler使用了专门的调度算法。默认的调度算法工作如下：</li>
<li>scheduler启动时，会注册一系列的默认predicates。这些predicates会检查pod是否满足特定的条件，比如：如果PodSpec中明确指定了CPU或RAM资源，如果Node上的资源不满足，那么此Node就会被过滤掉。</li>
<li>一旦选择了一些符合条件的节点，那么接下来priority函数将会给这些节点打分。比如：为了在集群中使得资源均匀分配，那么节点剩余资源较多的节点会得到更高的分数，最终选择一个分数最高的节点作为目标节点。<br>当找到合适节点后，scheduler会创建一个Binding Object，其中名称和UID会匹配对应的pod。Binding Object的ObjectReference字段会包含选择的目标节点。通过post请求会发送给apiserver。<br>当apiserver接受到Binding object后，它会反序列化请求，然后将信息更新到pod对象上：设置pod的NodeName字段，添加相关的注解以及将<code>PodScheduled</code>设置为<code>True</code>.<br>一旦scheudler将pod调度到目标节点后，剩下的工作就交与kubelet来完成了。<blockquote>
<p>注：定制调度器。通过<code>--policy-config-file</code>可以定制predicate和priority函数。我们可以在k8s集群中运行特定的调度器，比如采用deployment运行。如果在PodSpec中指定了<code>schedulerName</code>,那么k8s会将调度过程交给这个调度器执行。</p>
</blockquote>
</li>
</ol>
<h2 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h2><h3 id="Pod-sync"><a href="#Pod-sync" class="headerlink" title="Pod sync"></a>Pod sync</h3><p>让我们总结下上面的过程：</p>
<ol>
<li>HTTP请求经过认证、鉴权以及admission controller阶段；</li>
<li>一个deployment、一个replicaSet、三个pod持久化到etcd中</li>
<li>一系列初始化器运行</li>
<li>最后，每个pod被调度到合适的节点上<br>到这个时候，数据仅仅存在于etcd中。接下来，就需要将pod在worker节点上启动。这个是通过kubelet组件来实现的。<br>kubelet是k8s集群中运行在每个节点上的组件，主要负责管理pod的生命周期。这意味kubelet需要将pod转换成具体的容器、网络等。同时，它也负责处理卷挂载、容器日志、垃圾收集以及其他重要的事情。<br>另一种考虑kubelet的方式是将它看做是一个控制器。kubectl从kube-apiserver每个20秒钟（可以配置）查询pod信息，挑选出<code>NodeName</code>于当前节点名称一致的pod。然后它将pod与本地内部缓存中pod的信息进行比较，如果发现有差异就进行同步。下面来具体看下同步的过程是怎么样的：</li>
<li>如果pod是要进行创建，那么kubelet会注册一些metrics，这些metrics主要给prometheus用于追踪pod的延迟。</li>
<li>kubectl生成PodStatus对象，PodStatus代表了Pod的当前状态(Phase)。pod的状态是pod生命周期的更高一级的抽象。比如<code>Pending</code>，<code>Running</code>,<code>Succeeded</code>,<code>Failed</code>和<code>Unknown</code>。产生这些状态是比较复杂的，让我们深挖一下：<ul>
<li>首先，一系列的<code>PodSyncHandlers</code>会顺序执行。每个handler都会检查pod是否应该在当前节点上。如果任意的handler判断pod不应该在当前节点上，那么pod的phase将会变成<code>PodFailed</code>，并且pod会从此节点上被剔除。比如在Job资源中设置了<code>activeDeadlineSeconds</code>，超过了设置的时间，那么pod就会被剔除。</li>
<li>接下来，pod的phase会由初始化容器以及主容器的状态来决定。因为在这里容器还没有启动，这些容器会被归类为等待。具有等待容器的pod的phase都是<code>Pending</code></li>
<li>最后,Pod Condition会由容器的Condition来决定。因为我们的容器当前还没有被容器运行时创建，所以kubelet会将<code>PodReady</code> condition设置为False</li>
</ul>
</li>
<li>当PodStatus产生后，PodStatus对象会被发送到Pod的status manager中。该管理器的任务是通过apiserver异步更新etcd记录</li>
<li>接下来，将运行一系列准入处理程序，以确保pod具有正确的安全权限。这包括强制的AppArmor profiles 和 NO_NEW_PRIVS。在这个阶段被拒绝的pod将无限期地处于挂起状态。</li>
<li>如果kubelet在启动时指定了<code>cgroups-per-qos</code>参数，那么kubelet将会为pod创建cgroups并且会应用这些资源参数。这是为了实现对pod更好地服务质量(QoS)处理。</li>
<li>给pod创建数据目录。包括pod目录(通常是：<code>/var/run/kubelet/pods/&lt;podID&gt;</code>)，卷目录(<code>&lt;podDir&gt;/volumes</code>)以及插件目录(<code>&lt;podDir&gt;/plugins</code>)</li>
<li>卷管理器(volume manager)等待<code>Spec.Volumes</code>中定义的卷准备好。根据挂载卷的类型，有些pod需要等待更长的时间(比如云或NFS卷)。</li>
<li>在<code>Spec.ImagePullSecrets</code>中定义的secrets资源，会从apiserver中获取。从而后续会注入到容器中</li>
<li>容器运行时开始启动容器<h3 id="CRI-and-pause-containers"><a href="#CRI-and-pause-containers" class="headerlink" title="CRI and pause containers"></a>CRI and pause containers</h3>到现在，大多数工作已经完成了，容器已经准备好启动了。启动容器的部分叫做容器运行时(Container Runtime，比如<code>docker</code>或<code>rkt</code>)。<br>为了增加扩展性，kubelet自从v1.5.0版本以来，提出了CRI(Container Runtime Interface),CRI用于与具体的容器运行时进行交互。总的来说，CRI是一个抽象层。kubelet和容器运行时通过protocal buffers以及对应的gRPC API接口进行交互。CRI带来了很大的好处，如果后续替换下层的容器运行时，核心的k8s代码不需要做任何修改。<br>我们回到部署容器的过程。当pod启动后，kubelet通过RPC启动<code>RunPodSandbox</code>。沙箱是一个CRI术语，用来描述一组容器，在k8s中被称作pod。<br>在我们的例子中，我们使用了docker。在沙箱中首先创建一个”pause”容器。pause容器主要是为了给pod中其他的容器提供服务，提供必要的资源。这些资源包括linux namespace(IPC、网络、PID等)。如果你不熟悉linux中容器如何工作。我们快速说一下。linux内核有命名空间的概念，命名空间主要是隔离专有的资源，比如CPU、内存。然后将这些资源指定给特定的进程，从而保证资源只能被指定的进程使用。Cgroups主要是给linux提供了资源分配的方式。Docker利用了linux命名空间和Cgroups来实现容器。<br>pause容器提供了所有的命名空间，并且允许子容器共享他们。作为同一个网络命名空间的一部分，一个好处是同一个pod中的容器可以通过localhost互相引用。pause容器的第二个角色是，PID命名空间如何工作。进程形成了等级树，最顶层的init进程，负责收割死进程。在pause容器创建后，它被检查点指向磁盘，然后启动。<h3 id="CNI-and-pod-networking"><a href="#CNI-and-pod-networking" class="headerlink" title="CNI and pod networking"></a>CNI and pod networking</h3>pod当前具有了基本的内容：pause容器持有所有的命名空间，从而pod内部的容器可以交流。但是网络如何工作以及如何设置？<br>kubelet将设置网络的工作委托给了CNI(Container Network Interface)插件。CNI的工作方式类似于Container Runtime Interface。简单来说，CNI提供了一种抽象，用于给不同的网络提供者使用不同的网络实现。kubelet与这些注册的CNI插件通过流式json数据进行交流。下面展示了json配置的例子：<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">   <span class="attr">&quot;cniVersion&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.3.1&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bridge&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;bridge&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="attr">&quot;bridge&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cnio0&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="attr">&quot;isGateway&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">   <span class="attr">&quot;isMasq&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">   <span class="attr">&quot;ipam&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;host-local&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;ranges&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">         <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;subnet&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;POD_CIDR&#125;&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br><span class="line">      <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;routes&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;dst&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.0.0.0/0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br><span class="line">   <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
json也为pod提供了特定的额外的元数据，比如通过<code>CNI_ARGS</code>环境变量提供名称和命名空间。<br>接下来发生的事情与具体的CNI插件有关，我们看看<code>bridge</code> CNI插件的工作：</li>
<li>插件首先在root命名空间中设置一个本地的linux bridge，这个bridge为当前host(本机)上的所有容器服务</li>
<li>接下来，插件创建veth pair，其中一端在pause容器，另一端在bridge中。可以将veth pair想象成一个管道，一端连接到容器，另一端连接到root 网络命名空间，从而允许容器和root网络命名空间进行通信。</li>
<li>现在应该给pause容器分配IP地址，并且设置路由。这样做之后pod就有了自己的ip地址。ip地址分配是委托给IPAM，IPAM在json中定义。<ul>
<li>IPAM插件类似于主要的网络插件：通过二进制调用并且有标准化的接口。每种IPAM插件都必须去顶容器的IP/子网，网络和路由，然后将这些信息返回给CNI插件。最常用的IPAM插件是<code>host-local</code>,它从一个预先定义好的地址范围中分配IP地址。它将已经分配的ip地址存储在本地的文件系统中，从而确保在本机上不会重复使用ip地址。</li>
</ul>
</li>
<li>kubelet会指定一个内部的DNS服务器ip地址给CNI插件，保证容器的<code>resolv.conf</code>文件被正确设置。<br>一定这个过程完成，CNI插件会返回json数据给kubelet，表明网络设置的结果。<h3 id="Inter-host-networking"><a href="#Inter-host-networking" class="headerlink" title="Inter-host networking"></a>Inter-host networking</h3>我们现在仅仅说了容器如何同主机进行通信。但是如果pod在不同的主机上，那么pod之间如何通信呢？<br>这通常是基于一种叫做overlay networking的技术来实现，这是一种跨多个主机动态同步路由的方法。一个流行的overlay netwoker实现是Flannel。Flannel的核心作用是在不同节点之间提供IPv4网络。Flannel不会控制容器如何跟主机通信(这是CNI的职责)，而是负责流量在不同主机间的转发。为了实现这个功能，Flannel为主机选择了一个子网，将这个信息存储到etcd中。它保留集群路由的本地表示，并将传出的数据包封装在UDP数据报中，确保它到达正确的主机。<h3 id="Container-startup"><a href="#Container-startup" class="headerlink" title="Container startup"></a>Container startup</h3>所有的网络工作都完成了，接下来就是启动工作容器了。<br>一旦沙箱完成初始化并且仍然是活跃的，那么kubelet将会为其创建工作容器。kubelet首先启动定义在PodSpec中定义的初始化容器，然后启动主容器。主要过程如下：</li>
<li>拉取容器的镜像。PodSpec中定义的secrets用于私有仓库</li>
<li>通过CRI创建容器.填充<code>ContainerConfig</code>结构体(包括启动命令、镜像、标签、挂载、环境变量等)，数据来自于PodSpec。然后通过protobufs协议发送给CRI插件。对于Docker来说，docker会反序列化请求，然后填充到自己的config结构体，然后发送给docker的后台进程。在这个过程中，它将一些元数据标签（如容器类型、日志路径、沙盒id）应用到容器。</li>
<li>然后，它向CPU管理器注册容器，这是1.8中的一个新的alpha功能，通过使用UpdateContainerResources CRI方法将容器分配给本地节点上的CPU集。</li>
<li>容器启动</li>
<li>若定义了post-start hook，则执行这些hook。hooks可以是<code>Exec</code>（在容器中执行特定的命令）或<code>Http</code>（执行一个http请求）。如果PostStart hook需要很长时间运行、或者失败，那么容器将不会到达running状态</li>
</ol>
<h2 id="Wrap-up-总结"><a href="#Wrap-up-总结" class="headerlink" title="Wrap-up(总结)"></a>Wrap-up(总结)</h2><p>到这里，已经产生了三个容器，他们可能运行在一个或者多个工作节点上。所有的网络、卷、secret都已经被kubelet填充，并且通过CRI插件填充到了容器中。</p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
  </entry>
</search>
